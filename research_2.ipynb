{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445bd7d5",
   "metadata": {},
   "source": [
    "# School of Quants hackathon 2025 – Finals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32d546",
   "metadata": {},
   "source": [
    "## Импорты и настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3638b7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "# ЯЧЕЙКА 8 — GRU по risk-последовательности\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6ce1e8",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1508d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('res_2/X_train.csv')\n",
    "y_train = pd.read_csv('res_2/y_train.csv')\n",
    "X_test = pd.read_csv('res_2/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04feef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train.copy()\n",
    "df = df.sort_values(by='id').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7111960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = y_train.set_index('id')['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074ba0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['credit_number_for_user', 'days_since_confirmed', 'maturity_plan',\n",
       "       'maturity_fact', 'credit_limit', 'next_payment_sum', 'sum_left_to_pay',\n",
       "       'current_overdue_debt', 'max_overdue_debt', 'full_credit_cost',\n",
       "       'overdues_5d', 'overdues_5d_30d', 'overdues_30d_60d',\n",
       "       'overdues_60d_90d', 'overdues_90d', 'no_overdues_5d',\n",
       "       'no_overdues_5d_30d', 'no_overdues_30d_60d', 'no_overdues_60d_90d',\n",
       "       'no_overdues_90d', 'enc_paym_0', 'enc_paym_1', 'enc_paym_2',\n",
       "       'enc_paym_3', 'enc_paym_4', 'enc_paym_5', 'enc_paym_6', 'enc_paym_7',\n",
       "       'enc_paym_8', 'enc_paym_9', 'enc_paym_10', 'enc_paym_11', 'enc_paym_12',\n",
       "       'enc_paym_13', 'enc_paym_14', 'enc_paym_15', 'enc_paym_16',\n",
       "       'enc_paym_17', 'enc_paym_18', 'enc_paym_19', 'enc_paym_20',\n",
       "       'enc_paym_21', 'enc_paym_22', 'enc_paym_23', 'enc_paym_24',\n",
       "       'credit_type', 'credit_currency', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57657b",
   "metadata": {},
   "source": [
    "## Исследование данных и анализ признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9f433",
   "metadata": {},
   "source": [
    "### enc_paym_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c139b",
   "metadata": {},
   "source": [
    "#### Анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5150532",
   "metadata": {},
   "source": [
    "Надо однозначно понять, что за статусы платежей представлены, вот динамика платежей по месяцам (`enc_paym_{0..N}` - Статусы ежемесячных платежей за последние N месяцев***):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d2c749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>status_0</th>\n",
       "      <th>status_1</th>\n",
       "      <th>status_2</th>\n",
       "      <th>status_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1695569</td>\n",
       "      <td>53323</td>\n",
       "      <td>3950</td>\n",
       "      <td>74562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1528964</td>\n",
       "      <td>103377</td>\n",
       "      <td>8043</td>\n",
       "      <td>187020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1447139</td>\n",
       "      <td>92128</td>\n",
       "      <td>7369</td>\n",
       "      <td>280768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1374843</td>\n",
       "      <td>87819</td>\n",
       "      <td>7042</td>\n",
       "      <td>357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1302740</td>\n",
       "      <td>82808</td>\n",
       "      <td>6396</td>\n",
       "      <td>435460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1227907</td>\n",
       "      <td>76923</td>\n",
       "      <td>5967</td>\n",
       "      <td>516607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1142545</td>\n",
       "      <td>70554</td>\n",
       "      <td>5145</td>\n",
       "      <td>609160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1050430</td>\n",
       "      <td>65498</td>\n",
       "      <td>4804</td>\n",
       "      <td>706672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>988710</td>\n",
       "      <td>60230</td>\n",
       "      <td>4347</td>\n",
       "      <td>774117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>927778</td>\n",
       "      <td>55380</td>\n",
       "      <td>3935</td>\n",
       "      <td>840311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>858238</td>\n",
       "      <td>50296</td>\n",
       "      <td>3520</td>\n",
       "      <td>915350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>777067</td>\n",
       "      <td>45193</td>\n",
       "      <td>3288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>701885</td>\n",
       "      <td>40580</td>\n",
       "      <td>3117</td>\n",
       "      <td>1081822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>621536</td>\n",
       "      <td>37886</td>\n",
       "      <td>3017</td>\n",
       "      <td>1164965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>581132</td>\n",
       "      <td>36525</td>\n",
       "      <td>2921</td>\n",
       "      <td>1206826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>550258</td>\n",
       "      <td>34864</td>\n",
       "      <td>2868</td>\n",
       "      <td>1239414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>522800</td>\n",
       "      <td>33093</td>\n",
       "      <td>2851</td>\n",
       "      <td>1268660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>496972</td>\n",
       "      <td>31774</td>\n",
       "      <td>2730</td>\n",
       "      <td>1295928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>470208</td>\n",
       "      <td>30164</td>\n",
       "      <td>2737</td>\n",
       "      <td>1324295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>445316</td>\n",
       "      <td>28872</td>\n",
       "      <td>2521</td>\n",
       "      <td>1350695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>424153</td>\n",
       "      <td>27547</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>404982</td>\n",
       "      <td>26168</td>\n",
       "      <td>2394</td>\n",
       "      <td>1393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>385444</td>\n",
       "      <td>25101</td>\n",
       "      <td>2286</td>\n",
       "      <td>1414573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>365429</td>\n",
       "      <td>23665</td>\n",
       "      <td>2050</td>\n",
       "      <td>1436260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>288117</td>\n",
       "      <td>18622</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  status_0  status_1  status_2  status_3\n",
       "0       0   1695569     53323      3950     74562\n",
       "1       1   1528964    103377      8043    187020\n",
       "2       2   1447139     92128      7369    280768\n",
       "3       3   1374843     87819      7042    357700\n",
       "4       4   1302740     82808      6396    435460\n",
       "5       5   1227907     76923      5967    516607\n",
       "6       6   1142545     70554      5145    609160\n",
       "7       7   1050430     65498      4804    706672\n",
       "8       8    988710     60230      4347    774117\n",
       "9       9    927778     55380      3935    840311\n",
       "10     10    858238     50296      3520    915350\n",
       "11     11         0    777067     45193      3288\n",
       "12     12    701885     40580      3117   1081822\n",
       "13     13    621536     37886      3017   1164965\n",
       "14     14    581132     36525      2921   1206826\n",
       "15     15    550258     34864      2868   1239414\n",
       "16     16    522800     33093      2851   1268660\n",
       "17     17    496972     31774      2730   1295928\n",
       "18     18    470208     30164      2737   1324295\n",
       "19     19    445316     28872      2521   1350695\n",
       "20     20         0    424153     27547      2475\n",
       "21     21    404982     26168      2394   1393860\n",
       "22     22    385444     25101      2286   1414573\n",
       "23     23    365429     23665      2050   1436260\n",
       "24     24         0    288117     18622      1741"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "for month in range(0, 25):\n",
    "    payment_counts = X_train.groupby(f'enc_paym_{month}')['id'].count()\n",
    "    month_data = {\n",
    "        'month': month,\n",
    "        'status_0': payment_counts.get(0, 0),\n",
    "        'status_1': payment_counts.get(1, 0),\n",
    "        'status_2': payment_counts.get(2, 0),\n",
    "        'status_3': payment_counts.get(3, 0)\n",
    "    }\n",
    "    all_data.append(month_data)\n",
    "result_df = pd.DataFrame(all_data)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f1480",
   "metadata": {},
   "source": [
    "Можно заметить, что 11, 20, 24ый месяцы отсутствуте значение status_0, но это ОБМАН, по динамике как раз видно, что данные сдвинуты и не хвататет как раз `status_3`. Посмотрим на тестовые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51efb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>status_0</th>\n",
       "      <th>status_1</th>\n",
       "      <th>status_2</th>\n",
       "      <th>status_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1695569</td>\n",
       "      <td>53323</td>\n",
       "      <td>3950</td>\n",
       "      <td>74562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1528964</td>\n",
       "      <td>103377</td>\n",
       "      <td>8043</td>\n",
       "      <td>187020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1447139</td>\n",
       "      <td>92128</td>\n",
       "      <td>7369</td>\n",
       "      <td>280768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1374843</td>\n",
       "      <td>87819</td>\n",
       "      <td>7042</td>\n",
       "      <td>357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1302740</td>\n",
       "      <td>82808</td>\n",
       "      <td>6396</td>\n",
       "      <td>435460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1227907</td>\n",
       "      <td>76923</td>\n",
       "      <td>5967</td>\n",
       "      <td>516607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1142545</td>\n",
       "      <td>70554</td>\n",
       "      <td>5145</td>\n",
       "      <td>609160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1050430</td>\n",
       "      <td>65498</td>\n",
       "      <td>4804</td>\n",
       "      <td>706672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>988710</td>\n",
       "      <td>60230</td>\n",
       "      <td>4347</td>\n",
       "      <td>774117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>927778</td>\n",
       "      <td>55380</td>\n",
       "      <td>3935</td>\n",
       "      <td>840311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>858238</td>\n",
       "      <td>50296</td>\n",
       "      <td>3520</td>\n",
       "      <td>915350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>777067</td>\n",
       "      <td>45193</td>\n",
       "      <td>3288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>701885</td>\n",
       "      <td>40580</td>\n",
       "      <td>3117</td>\n",
       "      <td>1081822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>621536</td>\n",
       "      <td>37886</td>\n",
       "      <td>3017</td>\n",
       "      <td>1164965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>581132</td>\n",
       "      <td>36525</td>\n",
       "      <td>2921</td>\n",
       "      <td>1206826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>550258</td>\n",
       "      <td>34864</td>\n",
       "      <td>2868</td>\n",
       "      <td>1239414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>522800</td>\n",
       "      <td>33093</td>\n",
       "      <td>2851</td>\n",
       "      <td>1268660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>496972</td>\n",
       "      <td>31774</td>\n",
       "      <td>2730</td>\n",
       "      <td>1295928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>470208</td>\n",
       "      <td>30164</td>\n",
       "      <td>2737</td>\n",
       "      <td>1324295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>445316</td>\n",
       "      <td>28872</td>\n",
       "      <td>2521</td>\n",
       "      <td>1350695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>424153</td>\n",
       "      <td>27547</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>404982</td>\n",
       "      <td>26168</td>\n",
       "      <td>2394</td>\n",
       "      <td>1393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>385444</td>\n",
       "      <td>25101</td>\n",
       "      <td>2286</td>\n",
       "      <td>1414573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>365429</td>\n",
       "      <td>23665</td>\n",
       "      <td>2050</td>\n",
       "      <td>1436260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>288117</td>\n",
       "      <td>18622</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  status_0  status_1  status_2  status_3\n",
       "0       0   1695569     53323      3950     74562\n",
       "1       1   1528964    103377      8043    187020\n",
       "2       2   1447139     92128      7369    280768\n",
       "3       3   1374843     87819      7042    357700\n",
       "4       4   1302740     82808      6396    435460\n",
       "5       5   1227907     76923      5967    516607\n",
       "6       6   1142545     70554      5145    609160\n",
       "7       7   1050430     65498      4804    706672\n",
       "8       8    988710     60230      4347    774117\n",
       "9       9    927778     55380      3935    840311\n",
       "10     10    858238     50296      3520    915350\n",
       "11     11         0    777067     45193      3288\n",
       "12     12    701885     40580      3117   1081822\n",
       "13     13    621536     37886      3017   1164965\n",
       "14     14    581132     36525      2921   1206826\n",
       "15     15    550258     34864      2868   1239414\n",
       "16     16    522800     33093      2851   1268660\n",
       "17     17    496972     31774      2730   1295928\n",
       "18     18    470208     30164      2737   1324295\n",
       "19     19    445316     28872      2521   1350695\n",
       "20     20         0    424153     27547      2475\n",
       "21     21    404982     26168      2394   1393860\n",
       "22     22    385444     25101      2286   1414573\n",
       "23     23    365429     23665      2050   1436260\n",
       "24     24         0    288117     18622      1741"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "for month in range(0, 25):\n",
    "    payment_counts = X_train.groupby(f'enc_paym_{month}')['id'].count()\n",
    "    \n",
    "    month_data = {\n",
    "        'month': month,\n",
    "        'status_0': payment_counts.get(0, 0),\n",
    "        'status_1': payment_counts.get(1, 0),\n",
    "        'status_2': payment_counts.get(2, 0),\n",
    "        'status_3': payment_counts.get(3, 0)\n",
    "    }\n",
    "    all_data.append(month_data)\n",
    "result_df = pd.DataFrame(all_data)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e88640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>status_0</th>\n",
       "      <th>status_1</th>\n",
       "      <th>status_2</th>\n",
       "      <th>status_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1695569</td>\n",
       "      <td>53323</td>\n",
       "      <td>3950</td>\n",
       "      <td>74562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1528964</td>\n",
       "      <td>103377</td>\n",
       "      <td>8043</td>\n",
       "      <td>187020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1447139</td>\n",
       "      <td>92128</td>\n",
       "      <td>7369</td>\n",
       "      <td>280768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1374843</td>\n",
       "      <td>87819</td>\n",
       "      <td>7042</td>\n",
       "      <td>357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1302740</td>\n",
       "      <td>82808</td>\n",
       "      <td>6396</td>\n",
       "      <td>435460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1227907</td>\n",
       "      <td>76923</td>\n",
       "      <td>5967</td>\n",
       "      <td>516607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1142545</td>\n",
       "      <td>70554</td>\n",
       "      <td>5145</td>\n",
       "      <td>609160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1050430</td>\n",
       "      <td>65498</td>\n",
       "      <td>4804</td>\n",
       "      <td>706672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>988710</td>\n",
       "      <td>60230</td>\n",
       "      <td>4347</td>\n",
       "      <td>774117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>927778</td>\n",
       "      <td>55380</td>\n",
       "      <td>3935</td>\n",
       "      <td>840311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>858238</td>\n",
       "      <td>50296</td>\n",
       "      <td>3520</td>\n",
       "      <td>915350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>777067</td>\n",
       "      <td>45193</td>\n",
       "      <td>3288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>701885</td>\n",
       "      <td>40580</td>\n",
       "      <td>3117</td>\n",
       "      <td>1081822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>621536</td>\n",
       "      <td>37886</td>\n",
       "      <td>3017</td>\n",
       "      <td>1164965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>581132</td>\n",
       "      <td>36525</td>\n",
       "      <td>2921</td>\n",
       "      <td>1206826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>550258</td>\n",
       "      <td>34864</td>\n",
       "      <td>2868</td>\n",
       "      <td>1239414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>522800</td>\n",
       "      <td>33093</td>\n",
       "      <td>2851</td>\n",
       "      <td>1268660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>496972</td>\n",
       "      <td>31774</td>\n",
       "      <td>2730</td>\n",
       "      <td>1295928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>470208</td>\n",
       "      <td>30164</td>\n",
       "      <td>2737</td>\n",
       "      <td>1324295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>445316</td>\n",
       "      <td>28872</td>\n",
       "      <td>2521</td>\n",
       "      <td>1350695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>424153</td>\n",
       "      <td>27547</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>404982</td>\n",
       "      <td>26168</td>\n",
       "      <td>2394</td>\n",
       "      <td>1393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>385444</td>\n",
       "      <td>25101</td>\n",
       "      <td>2286</td>\n",
       "      <td>1414573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>365429</td>\n",
       "      <td>23665</td>\n",
       "      <td>2050</td>\n",
       "      <td>1436260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>288117</td>\n",
       "      <td>18622</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  status_0  status_1  status_2  status_3\n",
       "0       0   1695569     53323      3950     74562\n",
       "1       1   1528964    103377      8043    187020\n",
       "2       2   1447139     92128      7369    280768\n",
       "3       3   1374843     87819      7042    357700\n",
       "4       4   1302740     82808      6396    435460\n",
       "5       5   1227907     76923      5967    516607\n",
       "6       6   1142545     70554      5145    609160\n",
       "7       7   1050430     65498      4804    706672\n",
       "8       8    988710     60230      4347    774117\n",
       "9       9    927778     55380      3935    840311\n",
       "10     10    858238     50296      3520    915350\n",
       "11     11         0    777067     45193      3288\n",
       "12     12    701885     40580      3117   1081822\n",
       "13     13    621536     37886      3017   1164965\n",
       "14     14    581132     36525      2921   1206826\n",
       "15     15    550258     34864      2868   1239414\n",
       "16     16    522800     33093      2851   1268660\n",
       "17     17    496972     31774      2730   1295928\n",
       "18     18    470208     30164      2737   1324295\n",
       "19     19    445316     28872      2521   1350695\n",
       "20     20         0    424153     27547      2475\n",
       "21     21    404982     26168      2394   1393860\n",
       "22     22    385444     25101      2286   1414573\n",
       "23     23    365429     23665      2050   1436260\n",
       "24     24         0    288117     18622      1741"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "for month in range(0, 25):\n",
    "    payment_counts = X_train.groupby(f'enc_paym_{month}')['id'].count()\n",
    "    \n",
    "    month_data = {\n",
    "        'month': month,\n",
    "        'status_0': payment_counts.get(0, 0),\n",
    "        'status_1': payment_counts.get(1, 0),\n",
    "        'status_2': payment_counts.get(2, 0),\n",
    "        'status_3': payment_counts.get(3, 0)\n",
    "    }\n",
    "    all_data.append(month_data)\n",
    "result_df = pd.DataFrame(all_data)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a284cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сдвигаем определённые месяца\n",
    "map_enc_paym_ = {1:0, 2:1, 3:2, 4:3}\n",
    "\n",
    "df['enc_paym_11'] = df['enc_paym_11'].map(map_enc_paym_)\n",
    "df['enc_paym_20'] = df['enc_paym_20'].map(map_enc_paym_)\n",
    "df['enc_paym_24'] = df['enc_paym_24'].map(map_enc_paym_)\n",
    "\n",
    "X_test['enc_paym_11'] = X_test['enc_paym_11'].map(map_enc_paym_)\n",
    "X_test['enc_paym_20'] = X_test['enc_paym_20'].map(map_enc_paym_)\n",
    "X_test['enc_paym_24'] = X_test['enc_paym_24'].map(map_enc_paym_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054dc90",
   "metadata": {},
   "source": [
    "Так всё же, что это за статусы? Если исходить из простой банковской логики и посчитать распределение дефолтов согласно статусам:\n",
    "|N|default_rate|\n",
    "|----------|----------|\n",
    "|2 |0.125000 |\n",
    "|1| 0.051819 |\n",
    "|3 |0.034540 |\n",
    "|0| 0.028840 |\n",
    "\n",
    "\n",
    "- **Статус 0**: Своевременный платёж (timely paid). Доминирует в недавних месяцах (382k в месяц 1, ~80% активных кредитов), корреляция с target=False (не-дефолт) выше. Это \"заплочено вовремя\".\n",
    "- **Статус 3**: Лёгкая/средняя просрочка (past due 1–60 дней). Редкий (25k–6k, ~5–1%), чаще у дефолтеров (target=True, до 25% в примерах), коррелирует с overdues_5d_30d. Это \"просрочено\" на ранних стадиях.\n",
    "- **Статус 1**: Тяжёлая просрочка (past due 60+ дней или charge-off). Очень редкий (<0.5%, 2k–0.5k), почти только у дефолтеров, коррелирует с overdues_60d_90d/overdues_90d. Это \"сильно просрочено\".\n",
    "- **Статус 2**: Это очень серьёзный маркер дефолта.\n",
    "\n",
    "На основе датасета, идея - создать метрики, учитывающие:\n",
    "- Количество и тяжесть просрочек (1, 2) в последних месяцах.\n",
    "- Последовательности (streaks) или переходы (например, 0→1→2 хуже, чем 1→0).\n",
    "- Веса для recency: недавние месяцы (enc_paym_0–2) важнее, чем enc_paym_3–5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0563cf6",
   "metadata": {},
   "source": [
    "#### Сложные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e68a67",
   "metadata": {},
   "source": [
    "Заменяем случайные веса на осмысленные, которые увеличиваются с увеличением риска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76d633ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_paym_corrected = {\n",
    "    0: 0,  #  → 0 (лучшая ситуация)\n",
    "    3: 1,  #  → 1 (средний риск)\n",
    "    1: 2,  #  → 2 (высокий риск)\n",
    "    2: 3   #  → 3 (максимальный риск)\n",
    "}\n",
    "for month in range(0, 25):\n",
    "    df[f'enc_paym_{month}'] = df[f'enc_paym_{month}'].map(enc_paym_corrected)\n",
    "    X_test[f'enc_paym_{month}'] = X_test[f'enc_paym_{month}'].map(enc_paym_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494f428",
   "metadata": {},
   "source": [
    "#### Взвешенная сумма статусов (дисконтированная по времени)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c536c",
   "metadata": {},
   "source": [
    "$$S=s_0​⋅1+s_1​⋅0.9+s_2​⋅0.8+…$$\n",
    "\n",
    "Смысл: \n",
    "- чем ближе к текущему моменту плохие статусы, тем сильнее они влияют;\n",
    "- штрафы за «старые» косяки постепенно уменьшаются.\n",
    "Это очень информативный признак, потому что модель получит сглаженный показатель уровня риска клиента с учётом динамики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc026fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_status_score(df, w):\n",
    "    df = df.copy()\n",
    "    df['weighted_status_score'] = 0\n",
    "    for month in range(0, 25):\n",
    "        df['weighted_status_score'] += df[f'enc_paym_{month}'] * w[month]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f59544f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weighted_status_score(df, np.flip((np.arange(25) * 1/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b8344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = weighted_status_score(X_test, np.flip((np.arange(25) * 1/25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beccbcff",
   "metadata": {},
   "source": [
    "#### Максимальная длина подряд идущих «плохих» статусов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e684a",
   "metadata": {},
   "source": [
    "Смысл:\n",
    "- Если клиент допустил разовую просрочку, это не так страшно.\n",
    "- Если у него 3–4 месяца подряд delinquent или defaulted, это почти всегда дефолтный сценарий.\n",
    "Такой признак даёт сильный сигнал модели, потому что «устойчивость» плохого поведения предсказывает вероятность дефолта лучше, чем единичные выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cc2dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_run_bad_status(df, bad_statuses={2, 3}):\n",
    "    df = df.copy()\n",
    "    df['longest_run_bad_status'] = 0\n",
    "    df['maxi'] = 0\n",
    "    for month in tqdm(range(0, 25)):\n",
    "        mask = df['maxi'] > df['longest_run_bad_status']\n",
    "        df.loc[mask, 'longest_run_bad_status'] = df.loc[mask, 'maxi']\n",
    "        \n",
    "        # Обновляем maxi для всех строк\n",
    "        df['maxi'] = df.apply(\n",
    "            lambda row: row['maxi'] + 1 if row[f'enc_paym_{month}'] in bad_statuses else 0,\n",
    "            axis=1\n",
    "        )\n",
    "    mask = df['maxi'] > df['longest_run_bad_status']\n",
    "    df.loc[mask, 'longest_run_bad_status'] = df.loc[mask, 'maxi']\n",
    "    return df['longest_run_bad_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2327db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [07:01<00:00, 16.85s/it]\n"
     ]
    }
   ],
   "source": [
    "df['longest_run_bad_status'] = longest_run_bad_status(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7faed6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:16<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "X_test['longest_run_bad_status'] = longest_run_bad_status(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664a528",
   "metadata": {},
   "source": [
    "#### Количество переходов «ухудшения положения»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bce821",
   "metadata": {},
   "source": [
    "Cчитается сколько раз статус ухудшился в истории:\n",
    "- 0 → 1\n",
    "- 1 → 2\n",
    "- 2 → 3\n",
    "\n",
    "Это отражает «тренд»: клиент движется к дефолту или колеблется.\n",
    "Если много ухудшений подряд → клиент явно уходит в риск-зону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e985d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_deterioration_transitions(df):\n",
    "    df = df.copy()\n",
    "    df['deterioration_count'] = 0\n",
    "    for month in range(1, 25):\n",
    "        current_col = f'enc_paym_{month}'\n",
    "        prev_col = f'enc_paym_{month-1}'\n",
    "        \n",
    "        # Определяем условия ухудшения\n",
    "        condition_0_to_1 = (df[prev_col] == 0) & (df[current_col] == 1)\n",
    "        condition_1_to_2 = (df[prev_col] == 1) & (df[current_col] == 2)\n",
    "        condition_2_to_3 = (df[prev_col] == 2) & (df[current_col] == 3)\n",
    "        # Суммируем все случаи ухудшения\n",
    "        deterioration_mask = condition_0_to_1 | condition_1_to_2 | condition_2_to_3\n",
    "        df.loc[deterioration_mask, 'deterioration_count'] += 1\n",
    "    return df['deterioration_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b38f9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deterioration_count'] = count_deterioration_transitions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3910b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['deterioration_count'] = count_deterioration_transitions(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d113490",
   "metadata": {},
   "source": [
    "### credit_number_for_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791ac9c",
   "metadata": {},
   "source": [
    "`credit_number_for_user` - Порядковый номер кредитного продукта в кредитной истории. Большему номеру соответствует продукт с более поздней датой открытия. \n",
    "\n",
    "Этот признак и так хорош, он отражает насколько можно доверять клиенту, ведь, если он брал кредиты ранее и возвращал, то у него хорошая кредитная история и выше шанс отдать деньги."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a361e1a",
   "metadata": {},
   "source": [
    "### days_since_confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70730e64",
   "metadata": {},
   "source": [
    "`days_since_confirmed` - Дней с даты подтверждения информации по кредиту до даты сбора данных*\n",
    "\n",
    "Этот признак я вообше не понимаю, как он связан с дефолтом?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e97ca",
   "metadata": {},
   "source": [
    "### maturity_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2eab1",
   "metadata": {},
   "source": [
    "`maturity_fact` - Фактическое количество дней с даты открытия кредита до даты закрытия*\n",
    "Само по себе знание сколько дней длился кредит важно - чем больше срок кредита, тем выше вероятность дефолта (невыплаты). И наоборот досрочное погашение это круто"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be9260",
   "metadata": {},
   "source": [
    "### maturity_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185aa81",
   "metadata": {},
   "source": [
    "`maturity_plan` - Плановое количество дней с даты открытия кредита до даты закрытия*\n",
    "\n",
    "Само по себе знание сколько дней должен был длился кредит не важно, но понимание того, насколько был превышен ожидаемый срок:\n",
    "\n",
    "Если maturity_ratio больше 1, то срок превышен, если меньше 1, то было досрочное погашение!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "093aed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maturity_ratio(maturity_plan, maturity_fact):\n",
    "    return maturity_plan / (maturity_fact + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1287c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['maturity_ratio'] = maturity_ratio(df['maturity_plan'], df['maturity_fact'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e193ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['maturity_ratio'] = maturity_ratio(X_test['maturity_plan'], X_test['maturity_fact'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ebfe9c",
   "metadata": {},
   "source": [
    "### credit_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40410c87",
   "metadata": {},
   "source": [
    "`credit_limit` - Кредитный лимит. Уже очень крутой признак. Показывает уровень доверия к клиенту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fd092",
   "metadata": {},
   "source": [
    "### next_payment_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed0692",
   "metadata": {},
   "source": [
    "`next_payment_sum` - Сумма следующего платежа по кредиту*. Уже хороший признак. Но его надо превратить в безразмерный:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7a9658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_payment_sum_ratio(next_payment_sum, full_credit_cost):\n",
    "    return next_payment_sum / (full_credit_cost + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59b37c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['next_payment_sum_ratio'] = next_payment_sum_ratio(df['next_payment_sum'], df['full_credit_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "182e54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['next_payment_sum_ratio'] = next_payment_sum_ratio(X_test['next_payment_sum'], X_test['full_credit_cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021eb852",
   "metadata": {},
   "source": [
    "### sum_left_to_pay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ea2f",
   "metadata": {},
   "source": [
    "`sum_left_to_pay` - Оставшаяся невыплаченная сумма кредита*. Уже хороший признак. Но его надо превратить в безразмерный:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cb6f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_left_to_pay_progress(sum_left_to_pay, full_credit_cost):\n",
    "    return 1 - (sum_left_to_pay / (full_credit_cost + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e9969b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sum_left_to_pay_progress'] = sum_left_to_pay_progress(df['sum_left_to_pay'], df['full_credit_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6761b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['sum_left_to_pay_progress'] = sum_left_to_pay_progress(X_test['sum_left_to_pay'], X_test['full_credit_cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7642acc",
   "metadata": {},
   "source": [
    "### current_overdue_debt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a996d",
   "metadata": {},
   "source": [
    "`current_overdue_debt` - Текущая просроченная задолженность*. Абсолютно пустой признак - не нужен"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67256e55",
   "metadata": {},
   "source": [
    "### max_overdue_debt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c7705",
   "metadata": {},
   "source": [
    "`max_overdue_debt` - Максимальная просроченная задолженность*. Можно сделать относительной величиной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38516a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_overdue_debt_ratio(max_overdue_debt, full_credit_cost):\n",
    "    return max_overdue_debt / (full_credit_cost + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3164fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_overdue_debt_ratio'] = max_overdue_debt_ratio(df['max_overdue_debt'], df['full_credit_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b343a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['max_overdue_debt_ratio'] = max_overdue_debt_ratio(X_test['max_overdue_debt'], X_test['full_credit_cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbb701",
   "metadata": {},
   "source": [
    "### full_credit_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9cf52",
   "metadata": {},
   "source": [
    "`full_credit_cost` - Полная стоимость кредита*. Можно сделать относительной от общего кредитного лимита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a79dfad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_credit_cost_ef_rate(full_credit_cost, credit_limit):\n",
    "    return (full_credit_cost / (credit_limit + 1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00b984bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_credit_cost_ef_rate'] = full_credit_cost_ef_rate(df['full_credit_cost'], df['credit_limit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e823d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['full_credit_cost_ef_rate'] = full_credit_cost_ef_rate(X_test['full_credit_cost'], X_test['credit_limit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19119141",
   "metadata": {},
   "source": [
    "### overdues_Xd_Yd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04996990",
   "metadata": {},
   "source": [
    "`overdues_Xd_Yd` - Число просрочек сроком между X дней и Y дней (либо менее 5 дней/более 90 дней)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93dc8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_overdues(df):\n",
    "    df = df.copy()\n",
    "    df[\"total_overdues\"] = (\n",
    "        df[\"overdues_5d\"] + df[\"overdues_5d_30d\"] + df[\"overdues_30d_60d\"] +\n",
    "        df[\"overdues_60d_90d\"] + df[\"overdues_90d\"]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa258568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overdue(df):\n",
    "    df = df.copy()\n",
    "    df[\"has_long_overdue\"] = (df[\"overdues_60d_90d\"] > 0) | (df[\"overdues_90d\"] > 0)\n",
    "    df[\"has_mid_overdue\"] = (df[\"overdues_30d_60d\"] > 0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc41a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overdue_severity_score(df):\n",
    "    df = df.copy()\n",
    "    df[\"overdue_severity_score\"] = (\n",
    "        1*df[\"overdues_5d\"] +\n",
    "        2*df[\"overdues_5d_30d\"] +\n",
    "        4*df[\"overdues_30d_60d\"] +\n",
    "        6*df[\"overdues_60d_90d\"] +\n",
    "        10*df[\"overdues_90d\"]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0152177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overdue_ratio(df):\n",
    "    df = df.copy()\n",
    "    df[\"overdue_ratio\"] = df[\"total_overdues\"] / (df[\"credit_number_for_user\"] + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dc2b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_overdues(df)\n",
    "df = has_overdue(df)\n",
    "df = overdue_severity_score(df)\n",
    "df = overdue_ratio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5ec139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = total_overdues(X_test)\n",
    "X_test = has_overdue(X_test)\n",
    "X_test = overdue_severity_score(X_test)\n",
    "X_test = overdue_ratio(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fcc25b",
   "metadata": {},
   "source": [
    "### no_overdues_Xd_Yd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a622aa",
   "metadata": {},
   "source": [
    "`no_overdues_Xd_Yd` - нет просрочек сроком между X дней и Y дней (либо менее 5 дней/более 90 дней)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44ca704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_clean_history(df):\n",
    "    df = df.copy()\n",
    "    df[\"has_clean_history\"] = (\n",
    "    (df[\"no_overdues_5d\"]==1) &\n",
    "    (df[\"no_overdues_5d_30d\"]==1) &\n",
    "    (df[\"no_overdues_30d_60d\"]==1) &\n",
    "    (df[\"no_overdues_60d_90d\"]==1) &\n",
    "    (df[\"no_overdues_90d\"]==1)\n",
    "    ).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e664d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_overdue_level(df):\n",
    "    df = df.copy()\n",
    "    df[\"max_overdue_level\"] = (\n",
    "        df[[\"overdues_5d\",\"overdues_5d_30d\",\"overdues_30d_60d\",\n",
    "            \"overdues_60d_90d\",\"overdues_90d\"]] > 0\n",
    "    ).idxmax(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11ce3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = has_clean_history(df)\n",
    "df = max_overdue_level(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2b5af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = has_clean_history(X_test)\n",
    "X_test = max_overdue_level(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc329960",
   "metadata": {},
   "source": [
    "### credit_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422b9f4",
   "metadata": {},
   "source": [
    "`credit_type` - Тип кредита***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ee51a",
   "metadata": {},
   "source": [
    "### credit_currency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a786a",
   "metadata": {},
   "source": [
    "`credit_currency` - Валюта кредита**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04834e7f",
   "metadata": {},
   "source": [
    "### другие фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de6a1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_rate_map(s_values: np.ndarray, y_values: np.ndarray, prior: float, smoothing: float = 20.0):\n",
    "    \"\"\"\n",
    "    Строит сглаженную карту риска: value -> P(default|value).\n",
    "    - s_values: массив значений признака на train-части fold'а\n",
    "    - y_values: соответствующий массив 0/1\n",
    "    - prior: глобальная доля дефолтов (сглаживающий приор)\n",
    "    - smoothing: сила сглаживания (чем больше, тем ближе к prior при редких значениях)\n",
    "    Возвращает словарь {значение: риск}\n",
    "    \"\"\"\n",
    "    tmp = pd.DataFrame({'val': s_values, 'y': y_values})\n",
    "    grp = tmp.groupby('val')['y']\n",
    "    mean = grp.mean()\n",
    "    cnt  = grp.size()\n",
    "    # сглаженный риск: (mean*count + prior*smoothing) / (count + smoothing)\n",
    "    risk = (mean*cnt + prior*smoothing) / (cnt + smoothing)\n",
    "    return risk.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dc26d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827404 456852 25\n"
     ]
    }
   ],
   "source": [
    "target = df['target'].astype(int).values\n",
    "\n",
    "enc_cols = [c for c in df.columns if c.startswith('enc_paym_')]\n",
    "enc_cols = sorted(enc_cols, key=lambda s: int(s.split('_')[-1]))  # гарантированно 0..24 по возрастанию\n",
    "\n",
    "overdue_cols = [\n",
    "    'overdues_5d','overdues_5d_30d','overdues_30d_60d','overdues_60d_90d','overdues_90d',\n",
    "    'no_overdues_5d','no_overdues_5d_30d','no_overdues_30d_60d','no_overdues_60d_90d','no_overdues_90d'\n",
    "]\n",
    "\n",
    "starred_cols = [  # поля со звёздочкой из условия (разбиты по интервалам → «категории» в числах)\n",
    "    'days_since_confirmed','maturity_plan','maturity_fact','credit_limit',\n",
    "    'next_payment_sum','sum_left_to_pay','current_overdue_debt','max_overdue_debt','full_credit_cost'\n",
    "]\n",
    "cat_cols = ['credit_type','credit_currency']  # настоящие категории (перекодированные числами)\n",
    "base_num = ['credit_number_for_user']         # числовая, но мы тоже ей присвоим риск-ранг\n",
    "\n",
    "print(len(df), len(X_test), len(enc_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d457d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = list(skf.split(df, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cb8e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oof_target_rate_map(train_series: pd.Series, y: np.ndarray, folds, smoothing: float = 20.0):\n",
    "    \"\"\"\n",
    "    Возвращает:\n",
    "      - oof_risk: массив OOF-рисков для train_series (на валидации каждого фолда считаем по карте, обученной на его train-части)\n",
    "      - full_map: карта риска по всей обучающей части для применения на тесте\n",
    "    \"\"\"\n",
    "    prior = y.mean().item()\n",
    "    oof_risk = np.zeros(len(train_series), dtype=np.float32)\n",
    "\n",
    "    # Проход по фолдам: для каждого валидного куска используем карту, обученную на тренировочном\n",
    "    for tr_idx, vl_idx in folds:\n",
    "        s_tr = train_series.iloc[tr_idx].values\n",
    "        y_tr = y[tr_idx]\n",
    "        s_vl = train_series.iloc[vl_idx].values\n",
    "\n",
    "        risk_map = _fit_rate_map(s_tr, y_tr, prior, smoothing)\n",
    "        # OOF для валидации\n",
    "        oof_risk[vl_idx] = np.array([risk_map.get(v, prior) for v in s_vl], dtype=np.float32)\n",
    "\n",
    "    # Полная карта риска для теста\n",
    "    risk_map_full = _fit_rate_map(train_series.values, y, prior, smoothing)\n",
    "    return oof_risk, risk_map_full\n",
    "\n",
    "def apply_rate_map(series: pd.Series, rate_map: dict, default_rate: float):\n",
    "    \"\"\"Применяем карту риска к Series (неизвестные значения -> default_rate).\"\"\"\n",
    "    return series.map(rate_map).fillna(default_rate).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98e10086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЯЧЕЙКА 3a — строим risk-последовательности (N x 25) для train и test\n",
    "def build_risk_sequence(df_tr: pd.DataFrame, df_te: pd.DataFrame, enc_cols, y: np.ndarray, folds):\n",
    "    \"\"\"\n",
    "    На каждый enc_paym_k строим OOF риск (train) и full-map (test).\n",
    "    Склеиваем по столбцам -> матрица [N, 25] риска, согласованная с порядком enc_cols.\n",
    "    \"\"\"\n",
    "    prior = y.mean().item()\n",
    "    mats_tr = []\n",
    "    mats_te = []\n",
    "\n",
    "    for c in tqdm(enc_cols):\n",
    "        oof, full_map = oof_target_rate_map(df_tr[c], y, folds, smoothing=20.0)\n",
    "        mats_tr.append(oof.reshape(-1, 1))\n",
    "        mats_te.append(apply_rate_map(df_te[c], full_map, prior).values.reshape(-1, 1))\n",
    "\n",
    "    risk_tr = np.concatenate(mats_tr, axis=1).astype(np.float32)  # [N_train, 25]\n",
    "    risk_te = np.concatenate(mats_te, axis=1).astype(np.float32)  # [N_test,  25]\n",
    "    return risk_tr, risk_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f203d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:24<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1827404, 25), (456852, 25))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_seq_tr, risk_seq_te = build_risk_sequence(df, X_test, enc_cols, target, folds)\n",
    "risk_seq_tr.shape, risk_seq_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36ce7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЯЧЕЙКА 3b — агрегаты по risk-последовательности (без тяжёлых циклов)\n",
    "def ema_last_axis(mat: np.ndarray, alpha: float = 0.85):\n",
    "    \"\"\"\n",
    "    Применяет EMA слева направо по оси признаков:\n",
    "    y_t = alpha*y_{t-1} + (1-alpha)*x_t\n",
    "    Возвращает 1 столбец: последний EMA (сильнее учитывает свежие месяцы).\n",
    "    \"\"\"\n",
    "    out = np.zeros(mat.shape[0], dtype=np.float32)\n",
    "    for j in range(mat.shape[1]):\n",
    "        if j == 0:\n",
    "            out = mat[:, j]\n",
    "        else:\n",
    "            out = alpha * out + (1.0 - alpha) * mat[:, j]\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "def build_payment_risk_aggs(risk_tr: np.ndarray, risk_te: np.ndarray):\n",
    "    \"\"\"\n",
    "    Быстрые агрегаты из risk-последовательности (векторно):\n",
    "    - среднее за все 25\n",
    "    - среднее за последние 12, 6\n",
    "    - EMA (последнее значение)\n",
    "    - bad_count_12, bad_count_6 (где bad >= глобальной медианы по train-последовательности)\n",
    "    \"\"\"\n",
    "    # глобальный порог \"плохости\" по train\n",
    "    thr = np.median(risk_tr)\n",
    "\n",
    "    def agg_side(mat: np.ndarray):\n",
    "        feats = {}\n",
    "        feats['risk_mean_25']      = mat.mean(axis=1).astype(np.float32)\n",
    "        feats['risk_mean_last_12'] = mat[:, -12:].mean(axis=1).astype(np.float32)\n",
    "        feats['risk_mean_last_6']  = mat[:, -6:].mean(axis=1).astype(np.float32)\n",
    "        feats['risk_ema']          = ema_last_axis(mat, alpha=0.85)  # последний EMA\n",
    "\n",
    "        bad = (mat >= thr)  # bool\n",
    "        feats['bad_count_12'] = bad[:, -12:].sum(axis=1).astype(np.int16)\n",
    "        feats['bad_count_6']  = bad[:, -6:].sum(axis=1).astype(np.int16)\n",
    "        return pd.DataFrame(feats)\n",
    "\n",
    "    tr_aggs = agg_side(risk_tr)\n",
    "    te_aggs = agg_side(risk_te)\n",
    "    return tr_aggs, te_aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82d9ccf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1827404, 6), (456852, 6))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_pay_aggs, te_pay_aggs = build_payment_risk_aggs(risk_seq_tr, risk_seq_te)\n",
    "tr_pay_aggs.shape, te_pay_aggs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d0f45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЯЧЕЙКА 5 — риск-фичи для starred и base_num\n",
    "def build_risk_features_block(df_tr: pd.DataFrame, df_te: pd.DataFrame, cols, y: np.ndarray, folds):\n",
    "    prior = y.mean().item()\n",
    "    out_tr = {}\n",
    "    out_te = {}\n",
    "\n",
    "    for c in cols:\n",
    "        oof, mp = oof_target_rate_map(df_tr[c], y, folds, smoothing=30.0)\n",
    "        out_tr[f'{c}_risk'] = oof.astype(np.float32)\n",
    "        out_te[f'{c}_risk'] = apply_rate_map(df_te[c], mp, prior).values\n",
    "\n",
    "    return pd.DataFrame(out_tr), pd.DataFrame(out_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b011b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1827404, 10), (456852, 10))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_star, te_star = build_risk_features_block(df, X_test, starred_cols + base_num, target, folds)\n",
    "tr_star.shape, te_star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea681c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЯЧЕЙКА 5b — сглаженное target encoding для категорий (credit_type, credit_currency)\n",
    "def build_smoothed_te(df_tr: pd.DataFrame, df_te: pd.DataFrame, cols, y: np.ndarray, folds, min_count=50, prior=None):\n",
    "    if prior is None: prior = y.mean().item()\n",
    "    out_tr = {}\n",
    "    out_te = {}\n",
    "\n",
    "    for c in cols:\n",
    "        oof_vals = np.zeros(len(df_tr), dtype=np.float32)\n",
    "        for tr_idx, vl_idx in folds:\n",
    "            s_tr = df_tr[c].iloc[tr_idx].values\n",
    "            y_tr = y[tr_idx]\n",
    "            # считаем частоты и средние на train части\n",
    "            tmp = pd.DataFrame({'v': s_tr, 'y': y_tr})\n",
    "            grp = tmp.groupby('v')['y']\n",
    "            mean = grp.mean()\n",
    "            cnt  = grp.size()\n",
    "            # сглаживание к prior при малых cnt\n",
    "            smoothed = (mean*cnt + prior*min_count) / (cnt + min_count)\n",
    "            mp = smoothed.to_dict()\n",
    "            oof_vals[vl_idx] = np.array([mp.get(v, prior) for v in df_tr[c].iloc[vl_idx].values], dtype=np.float32)\n",
    "\n",
    "        # full map для теста\n",
    "        tmp_all = pd.DataFrame({'v': df_tr[c].values, 'y': y})\n",
    "        grp_all = tmp_all.groupby('v')['y']\n",
    "        mean_a = grp_all.mean()\n",
    "        cnt_a  = grp_all.size()\n",
    "        smoothed_a = (mean_a*cnt_a + prior*min_count) / (cnt_a + min_count)\n",
    "        mp_all = smoothed_a.to_dict()\n",
    "\n",
    "        out_tr[f'{c}_te'] = oof_vals\n",
    "        out_te[f'{c}_te'] = df_te[c].map(mp_all).fillna(prior).astype(np.float32).values\n",
    "\n",
    "    return pd.DataFrame(out_tr), pd.DataFrame(out_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44a59e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1827404, 2), (456852, 2))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_cat, te_cat = build_smoothed_te(df, X_test, cat_cols, target, folds, min_count=100)\n",
    "tr_cat.shape, te_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99d5d487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1827404, 32), (456852, 32))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Базовая сборка\n",
    "use_cols_num = [\n",
    "    'maturity_ratio',\n",
    "    'weighted_status_score',\n",
    "    'longest_run_bad_status',\n",
    "    'deterioration_count',\n",
    "    'next_payment_sum_ratio',\n",
    "    'sum_left_to_pay_progress',\n",
    "    'max_overdue_debt_ratio',\n",
    "    'full_credit_cost_ef_rate',\n",
    "    'total_overdues',\n",
    "    'overdue_severity_score',\n",
    "    'overdue_ratio',\n",
    "    'has_clean_history',        # как числовая псевдо-ординальная\n",
    "    # опционально:\n",
    "    # 'credit_number_for_user',\n",
    "]\n",
    "\n",
    "use_cols_cat_raw = ['credit_type', 'credit_currency']  # пометим как категории в CatBoost\n",
    "\n",
    "X_tr = pd.concat(\n",
    "    [tr_pay_aggs, tr_star, tr_cat, df.reset_index()[use_cols_num], df.reset_index()[use_cols_cat_raw]],\n",
    "    axis=1\n",
    ")\n",
    "X_te = pd.concat(\n",
    "    [te_pay_aggs, te_star, te_cat, X_test[use_cols_num], X_test[use_cols_cat_raw]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Если где-то есть NaN/inf — сразу чистим:\n",
    "X_tr = X_tr.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_te = X_te.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "y_tr = target.astype(int)\n",
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6cbcf",
   "metadata": {},
   "source": [
    "## Обучение первичное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "87128b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'credit_number_for_user', \n",
    "    'maturity_fact',\n",
    "    'maturity_ratio',\n",
    "    'credit_limit',\n",
    "    'weighted_status_score',\n",
    "    'longest_run_bad_status',\n",
    "    'deterioration_count',\n",
    "    'next_payment_sum_ratio',\n",
    "    'sum_left_to_pay_progress',\n",
    "    'max_overdue_debt_ratio',\n",
    "    'full_credit_cost_ef_rate',\n",
    "\n",
    "    'total_overdues', 'overdue_severity_score', 'overdue_ratio', 'has_clean_history', \n",
    "    'max_overdue_level',\n",
    "\n",
    "    'credit_type',  \n",
    "    'credit_currency']\n",
    "cat_features = ['credit_type', 'credit_currency', 'max_overdue_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2de79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "x_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "abbbc9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6046038\tbest: 0.6046038 (0)\ttotal: 1.44s\tremaining: 48m 1s\n",
      "100:\ttest: 0.6170486\tbest: 0.6170486 (100)\ttotal: 1m 56s\tremaining: 36m 32s\n",
      "200:\ttest: 0.6183562\tbest: 0.6184386 (194)\ttotal: 3m 32s\tremaining: 31m 39s\n",
      "300:\ttest: 0.6181507\tbest: 0.6186464 (261)\ttotal: 5m 17s\tremaining: 29m 51s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6186464119\n",
      "bestIteration = 261\n",
      "\n",
      "Shrink model to first 262 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x28175c47550>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    depth=11,\n",
    "    learning_rate=0.05,\n",
    "    l2_leaf_reg=7,\n",
    "    bagging_temperature=0.5,\n",
    "    auto_class_weights='Balanced',\n",
    "    eval_metric='AUC',  # Оптимизация по F1\n",
    "    random_seed=42,\n",
    "    verbose=100, \n",
    "    early_stopping_rounds=100,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(\n",
    "    x_train, y_train, eval_set=(x_val, y_val),\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1eef0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, \n",
    "                            classification_report, precision_recall_curve, \n",
    "                            average_precision_score)\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"\n",
    "    Выводит все основные метрики качества для бинарной классификации\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: истинные значения\n",
    "    y_pred: предсказанные классы\n",
    "    y_pred_proba: предсказанные вероятности (для ROC-AUC)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"МЕТРИКИ КАЧЕСТВА МОДЕЛИ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Основные метрики\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    \n",
    "    # ROC-AUC если есть вероятности\n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "            print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "            \n",
    "            # Average Precision Score\n",
    "            avg_precision = average_precision_score(y_true, y_pred_proba)\n",
    "            print(f\"Avg Precision: {avg_precision:.4f}\")\n",
    "        except:\n",
    "            print(\"ROC-AUC: Не удалось вычислить (проверьте y_pred_proba)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(\"MATRIXA SOWMESHENIY (CONFUSION MATRIX)\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Матрица ошибок\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(f\"True Negative (TN):  {tn}\")\n",
    "    print(f\"False Positive (FP): {fp}\")\n",
    "    print(f\"False Negative (FN): {fn}\")\n",
    "    print(f\"True Positive (TP):  {tp}\")\n",
    "    print(f\"\\nМатрица в виде таблицы:\")\n",
    "    print(f\"[[TN {tn}   FP {fp}]\")\n",
    "    print(f\" [FN {fn}   TP {tp}]]\")\n",
    "    \n",
    "    # Дополнительные метрики из матрицы ошибок\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Negative Rate\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n",
    "    \n",
    "    print(f\"\\nSpecificity (TNR): {specificity:.4f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
    "    print(f\"False Negative Rate (FNR): {fnr:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(\"DETALNY OTCHET (CLASSIFICATION REPORT)\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Детальный отчет\n",
    "    print(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'], zero_division=0))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5814cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "МЕТРИКИ КАЧЕСТВА МОДЕЛИ\n",
      "==================================================\n",
      "Accuracy:  0.6806\n",
      "Precision: 0.0502\n",
      "Recall:    0.4787\n",
      "F1-score:  0.0909\n",
      "ROC-AUC:   0.6186\n",
      "Avg Precision: 0.0574\n",
      "\n",
      "------------------------------\n",
      "MATRIXA SOWMESHENIY (CONFUSION MATRIX)\n",
      "------------------------------\n",
      "True Negative (TN):  303613\n",
      "False Positive (FP): 137994\n",
      "False Negative (FN): 7947\n",
      "True Positive (TP):  7297\n",
      "\n",
      "Матрица в виде таблицы:\n",
      "[[TN 303613   FP 137994]\n",
      " [FN 7947   TP 7297]]\n",
      "\n",
      "Specificity (TNR): 0.6875\n",
      "False Positive Rate (FPR): 0.3125\n",
      "False Negative Rate (FNR): 0.5213\n",
      "\n",
      "------------------------------\n",
      "DETALNY OTCHET (CLASSIFICATION REPORT)\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.69      0.81    441607\n",
      "     Class 1       0.05      0.48      0.09     15244\n",
      "\n",
      "    accuracy                           0.68    456851\n",
      "   macro avg       0.51      0.58      0.45    456851\n",
      "weighted avg       0.94      0.68      0.78    456851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_vetrics = evaluate_model(y_val, model.predict(x_val), model.predict_proba(x_val)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11e522cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_status_score</td>\n",
       "      <td>11.235639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sum_left_to_pay_progress</td>\n",
       "      <td>9.909159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>credit_type</td>\n",
       "      <td>8.989772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maturity_ratio</td>\n",
       "      <td>8.400929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>next_payment_sum_ratio</td>\n",
       "      <td>7.903960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maturity_fact</td>\n",
       "      <td>7.837513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_overdue_debt_ratio</td>\n",
       "      <td>7.707635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>full_credit_cost_ef_rate</td>\n",
       "      <td>5.922321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_limit</td>\n",
       "      <td>5.717225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>has_clean_history</td>\n",
       "      <td>5.597286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>overdue_ratio</td>\n",
       "      <td>5.143584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_number_for_user</td>\n",
       "      <td>4.243456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deterioration_count</td>\n",
       "      <td>4.127255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>longest_run_bad_status</td>\n",
       "      <td>2.631007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>credit_currency</td>\n",
       "      <td>1.520815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max_overdue_level</td>\n",
       "      <td>1.233902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overdue_severity_score</td>\n",
       "      <td>0.960336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_overdues</td>\n",
       "      <td>0.918206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance\n",
       "4      weighted_status_score   11.235639\n",
       "8   sum_left_to_pay_progress    9.909159\n",
       "16               credit_type    8.989772\n",
       "2             maturity_ratio    8.400929\n",
       "7     next_payment_sum_ratio    7.903960\n",
       "1              maturity_fact    7.837513\n",
       "9     max_overdue_debt_ratio    7.707635\n",
       "10  full_credit_cost_ef_rate    5.922321\n",
       "3               credit_limit    5.717225\n",
       "14         has_clean_history    5.597286\n",
       "13             overdue_ratio    5.143584\n",
       "0     credit_number_for_user    4.243456\n",
       "6        deterioration_count    4.127255\n",
       "5     longest_run_bad_status    2.631007\n",
       "17           credit_currency    1.520815\n",
       "15         max_overdue_level    1.233902\n",
       "12    overdue_severity_score    0.960336\n",
       "11            total_overdues    0.918206"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.DataFrame({\n",
    "        'feature': x_train.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', key=abs, ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "948e0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.1400 at threshold 0.63\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_proba = model.predict_proba(x_train)[:, 1]\n",
    "\n",
    "# Сетка порогов\n",
    "thresholds = np.linspace(0.01, 0.99, 199)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_train, y_val_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bdd4347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.1052 at threshold 0.59\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_proba = model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "# Сетка порогов\n",
    "thresholds = np.linspace(0.01, 0.99, 199)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904aecb",
   "metadata": {},
   "source": [
    "#### Итоговое обучение и сабмишен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "292b3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tra, x_va, y_tra, y_va = train_test_split(X, y, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4f63e8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6178258\tbest: 0.6178258 (0)\ttotal: 1.75s\tremaining: 58m 26s\n",
      "100:\ttest: 0.6243863\tbest: 0.6276787 (70)\ttotal: 2m 30s\tremaining: 47m 5s\n",
      "200:\ttest: 0.6362800\tbest: 0.6362800 (200)\ttotal: 4m 34s\tremaining: 40m 53s\n",
      "300:\ttest: 0.6396113\tbest: 0.6402932 (295)\ttotal: 6m 37s\tremaining: 37m 23s\n",
      "400:\ttest: 0.6462254\tbest: 0.6485340 (380)\ttotal: 9m 21s\tremaining: 37m 19s\n",
      "500:\ttest: 0.6476671\tbest: 0.6506673 (465)\ttotal: 12m 2s\tremaining: 36m 2s\n",
      "600:\ttest: 0.6579827\tbest: 0.6584015 (599)\ttotal: 14m 45s\tremaining: 34m 21s\n",
      "700:\ttest: 0.6613920\tbest: 0.6614699 (698)\ttotal: 17m 31s\tremaining: 32m 28s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6614699006\n",
      "bestIteration = 698\n",
      "\n",
      "Shrink model to first 699 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x28175c47550>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_itog = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=11,\n",
    "    learning_rate=0.05,\n",
    "    l2_leaf_reg=20,\n",
    "    bagging_temperature=0.5,\n",
    "    auto_class_weights='Balanced',\n",
    "    eval_metric='AUC',  # Оптимизация по F1\n",
    "    random_seed=42,\n",
    "    verbose=100, \n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(\n",
    "    x_tra, y_tra, eval_set=(x_va, y_va)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41692dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 1.99s\tremaining: 19m 53s\n",
      "100:\ttotal: 2m 34s\tremaining: 12m 43s\n",
      "200:\ttotal: 4m 40s\tremaining: 9m 15s\n",
      "300:\ttotal: 6m 50s\tremaining: 6m 47s\n",
      "400:\ttotal: 10m 1s\tremaining: 4m 58s\n",
      "500:\ttotal: 13m 30s\tremaining: 2m 40s\n",
      "599:\ttotal: 17m 1s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2c9c5adf0d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_itog_max = CatBoostClassifier(\n",
    "    iterations=600,\n",
    "    depth=11,\n",
    "    learning_rate=0.05,\n",
    "    l2_leaf_reg=20,\n",
    "    bagging_temperature=0.5,\n",
    "    auto_class_weights='Balanced',\n",
    "    eval_metric='AUC',  # Оптимизация по F1\n",
    "    random_seed=42,\n",
    "    verbose=100, \n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model_itog_max.fit(\n",
    "    df[features], df['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5489691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "МЕТРИКИ КАЧЕСТВА МОДЕЛИ\n",
      "==================================================\n",
      "Accuracy:  0.7104\n",
      "Precision: 0.0659\n",
      "Recall:    0.5941\n",
      "F1-score:  0.1187\n",
      "ROC-AUC:   0.7204\n",
      "Avg Precision: 0.1040\n",
      "\n",
      "------------------------------\n",
      "MATRIXA SOWMESHENIY (CONFUSION MATRIX)\n",
      "------------------------------\n",
      "True Negative (TN):  1262642\n",
      "False Positive (FP): 504798\n",
      "False Negative (FN): 24337\n",
      "True Positive (TP):  35627\n",
      "\n",
      "Матрица в виде таблицы:\n",
      "[[TN 1262642   FP 504798]\n",
      " [FN 24337   TP 35627]]\n",
      "\n",
      "Specificity (TNR): 0.7144\n",
      "False Positive Rate (FPR): 0.2856\n",
      "False Negative Rate (FNR): 0.4059\n",
      "\n",
      "------------------------------\n",
      "DETALNY OTCHET (CLASSIFICATION REPORT)\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.71      0.83   1767440\n",
      "     Class 1       0.07      0.59      0.12     59964\n",
      "\n",
      "    accuracy                           0.71   1827404\n",
      "   macro avg       0.52      0.65      0.47   1827404\n",
      "weighted avg       0.95      0.71      0.80   1827404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_vetrics = evaluate_model(df['target'], model_itog_max.predict(df[features]), model_itog_max.predict_proba(df[features])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d1ea76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model_itog_max.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fb898fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.1710 at threshold 0.63\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_proba = model_itog_max.predict_proba(df[features])[:, 1]\n",
    "\n",
    "# Сетка порогов\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_val_pred, df['target'])\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7ad3635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.1963 at threshold 0.65\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_proba = model.predict_proba(x_tra)[:, 1]\n",
    "\n",
    "# Сетка порогов\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_val_pred, y_tra)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1725b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = model.predict_proba(x_test)[:, 1]\n",
    "test_pred = (proba >= 0.63).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "88995d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpo_test = model_itog_max.predict_proba(X_test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7a1dd5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], shape=(456852,))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e4cae739",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['flag'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "54e2df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['id', 'flag']].set_index('id').to_csv('sub_mission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf0c139",
   "metadata": {},
   "source": [
    "## Мощное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d9865",
   "metadata": {},
   "source": [
    "### credit_type == ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "29002ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diction = {}\n",
    "detph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8bbd0582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_type\n",
       "0     15963.25\n",
       "1      2328.25\n",
       "2     10630.25\n",
       "3    137111.75\n",
       "4    258849.75\n",
       "5     20398.75\n",
       "6      1256.25\n",
       "7     10312.75\n",
       "Name: credit_number_for_user, dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('credit_type')['credit_number_for_user'].count() * 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f578a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "typee = 7\n",
    "df_0 = df[df['credit_type'] == typee]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cb2bd969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5586678\tbest: 0.5586678 (0)\ttotal: 32.3ms\tremaining: 1m 4s\n",
      "100:\ttest: 0.5327881\tbest: 0.5685026 (6)\ttotal: 2.92s\tremaining: 54.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5685026315\n",
      "bestIteration = 6\n",
      "\n",
      "Shrink model to first 7 iterations.\n",
      "==================================================\n",
      "МЕТРИКИ КАЧЕСТВА МОДЕЛИ\n",
      "==================================================\n",
      "Accuracy:  0.7027\n",
      "Precision: 0.0446\n",
      "Recall:    0.4098\n",
      "F1-score:  0.0804\n",
      "ROC-AUC:   0.5685\n",
      "Avg Precision: 0.0423\n",
      "\n",
      "------------------------------\n",
      "MATRIXA SOWMESHENIY (CONFUSION MATRIX)\n",
      "------------------------------\n",
      "True Negative (TN):  7113\n",
      "False Positive (FP): 2873\n",
      "False Negative (FN): 193\n",
      "True Positive (TP):  134\n",
      "\n",
      "Матрица в виде таблицы:\n",
      "[[TN 7113   FP 2873]\n",
      " [FN 193   TP 134]]\n",
      "\n",
      "Specificity (TNR): 0.7123\n",
      "False Positive Rate (FPR): 0.2877\n",
      "False Negative Rate (FNR): 0.5902\n",
      "\n",
      "------------------------------\n",
      "DETALNY OTCHET (CLASSIFICATION REPORT)\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.71      0.82      9986\n",
      "     Class 1       0.04      0.41      0.08       327\n",
      "\n",
      "    accuracy                           0.70     10313\n",
      "   macro avg       0.51      0.56      0.45     10313\n",
      "weighted avg       0.94      0.70      0.80     10313\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>longest_run_bad_status</td>\n",
       "      <td>17.528091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_number_for_user</td>\n",
       "      <td>16.898484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maturity_fact</td>\n",
       "      <td>14.885166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_status_score</td>\n",
       "      <td>12.307858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_limit</td>\n",
       "      <td>8.092802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_overdue_debt_ratio</td>\n",
       "      <td>8.014381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>full_credit_cost_ef_rate</td>\n",
       "      <td>7.521686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sum_left_to_pay_progress</td>\n",
       "      <td>6.358995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maturity_ratio</td>\n",
       "      <td>3.284717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deterioration_count</td>\n",
       "      <td>2.743928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>next_payment_sum_ratio</td>\n",
       "      <td>2.363892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit_currency</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance\n",
       "5     longest_run_bad_status   17.528091\n",
       "0     credit_number_for_user   16.898484\n",
       "1              maturity_fact   14.885166\n",
       "4      weighted_status_score   12.307858\n",
       "3               credit_limit    8.092802\n",
       "9     max_overdue_debt_ratio    8.014381\n",
       "10  full_credit_cost_ef_rate    7.521686\n",
       "8   sum_left_to_pay_progress    6.358995\n",
       "2             maturity_ratio    3.284717\n",
       "6        deterioration_count    2.743928\n",
       "7     next_payment_sum_ratio    2.363892\n",
       "11           credit_currency    0.000000"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'credit_number_for_user', \n",
    "    'maturity_fact',\n",
    "    'maturity_ratio',\n",
    "    'credit_limit',\n",
    "    'weighted_status_score',\n",
    "    'longest_run_bad_status',\n",
    "    'deterioration_count',\n",
    "    'next_payment_sum_ratio',\n",
    "    'sum_left_to_pay_progress',\n",
    "    'max_overdue_debt_ratio',\n",
    "    'full_credit_cost_ef_rate',  \n",
    "    'credit_currency']\n",
    "\n",
    "X = df_0[features]\n",
    "y = df_0['target']\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "x_test = X_test[features]\n",
    "\n",
    "depth = 9\n",
    "model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    depth=depth,\n",
    "    learning_rate=0.07,\n",
    "    l2_leaf_reg=5,\n",
    "    bagging_temperature=0.5,\n",
    "    auto_class_weights='Balanced',\n",
    "    eval_metric='AUC',  # Оптимизация по F1\n",
    "    random_seed=42,\n",
    "    verbose=100, \n",
    "    early_stopping_rounds=100,\n",
    "    cat_features=['credit_currency']\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(\n",
    "    x_train, y_train, eval_set=(x_val, y_val),\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "diction[typee] = evaluate_model(y_val, model.predict(x_val), model.predict_proba(x_val)[:,1])\n",
    "detph[typee] = depth\n",
    "\n",
    "feature_imp = pd.DataFrame({\n",
    "        'feature': x_train.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', key=abs, ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "da6b60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.06322861094645327\n",
      "1 0.1016949152542373\n",
      "2 0.06269020085209982\n",
      "3 0.08201916690388082\n",
      "4 0.07979600017816578\n",
      "5 0.16505293638584742\n",
      "6 0.13020833333333334\n",
      "7 0.08038392321535692\n"
     ]
    }
   ],
   "source": [
    "for k, v in diction.items():\n",
    "    print(k, v['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0008e29",
   "metadata": {},
   "source": [
    "### credit_type == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "64490a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "typee = 4\n",
    "df_4 = df[df['credit_type'] == typee]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4e64ba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------------------------\n",
    "# 0) Reproducibility\n",
    "# -------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "bc49ff84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_number_for_user           0\n",
       "maturity_fact                    0\n",
       "maturity_ratio              100255\n",
       "credit_limit                     0\n",
       "weighted_status_score            0\n",
       "longest_run_bad_status           0\n",
       "deterioration_count              0\n",
       "next_payment_sum_ratio      104816\n",
       "sum_left_to_pay_progress         0\n",
       "max_overdue_debt_ratio      108960\n",
       "full_credit_cost_ef_rate     94592\n",
       "dtype: int64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[features] == np.inf).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "a854ceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\programs\\lang\\python\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[302]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# масштабирование (только по train)\u001b[39;00m\n\u001b[32m     34\u001b[39m scaler = RobustScaler()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m x_tr_sc = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m x_val_sc = scaler.transform(x_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1624\u001b[39m, in \u001b[36mRobustScaler.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m   1606\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the median and quantiles to be used for scaling.\u001b[39;00m\n\u001b[32m   1607\u001b[39m \n\u001b[32m   1608\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1620\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m   1621\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1622\u001b[39m \u001b[38;5;66;03m# at fit, convert sparse matrices to csc for optimized computation of\u001b[39;00m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# the quantiles\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m q_min, q_max = \u001b[38;5;28mself\u001b[39m.quantile_range\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= q_min <= q_max <= \u001b[32m100\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "features = [\n",
    "    'credit_number_for_user', \n",
    "    'maturity_fact',\n",
    "    'maturity_ratio',\n",
    "    'credit_limit',\n",
    "    'weighted_status_score',\n",
    "    'longest_run_bad_status',\n",
    "    'deterioration_count',\n",
    "    'next_payment_sum_ratio',\n",
    "    'sum_left_to_pay_progress',\n",
    "    'max_overdue_debt_ratio',\n",
    "    'full_credit_cost_ef_rate',\n",
    "]\n",
    "\n",
    "# проверим, что все фичи есть в данных\n",
    "missing = [f for f in features if f not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Отсутствуют признаки в X_train: {missing}\\n\"\n",
    "                     f\"Убедись, что они посчитаны и присутствуют до запуска MLP.\")\n",
    "\n",
    "# на всякий случай — заменить NaN/inf\n",
    "df_4[features] = df[features].fillna(0.0)\n",
    "X_test_4[features] = X_test_4[features].fillna(0.0)\n",
    "\n",
    "X = df_4[features].astype(float)\n",
    "y = df_4['target'].astype(int).values\n",
    "\n",
    "# train/val split (стратифицированный)\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# масштабирование (только по train)\n",
    "scaler = RobustScaler()\n",
    "x_tr_sc = scaler.fit_transform(x_tr)\n",
    "x_val_sc = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d551a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) PyTorch Dataset/Dataloader\n",
    "# -------------------------\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = None if y is None else torch.from_numpy(y).float()\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabDataset(x_tr_sc, y_tr)\n",
    "val_ds   = TabDataset(x_val_sc, y_val)\n",
    "# sub_ds   = TabDataset(x_sub_sc, None)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4096, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=8192, shuffle=False, num_workers=0)\n",
    "# sub_loader   = DataLoader(sub_ds,   batch_size=8192, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6a3e4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 3) Model\n",
    "# -------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.20),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.20),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.10),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.10),\n",
    "\n",
    "            nn.Linear(32, 1)  # логит\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # [B]\n",
    "\n",
    "in_dim = len(features)\n",
    "model = MLP(in_dim).to(DEVICE)\n",
    "\n",
    "# -------------------------\n",
    "# 4) Loss (pos_weight) & Optimizer & Scheduler\n",
    "# -------------------------\n",
    "# дисбаланс: pos_weight = N_neg/N_pos\n",
    "pos = y_tr.sum()\n",
    "neg = len(y_tr) - pos\n",
    "pos_weight_value = (neg / max(1, pos))\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight_value, device=DEVICE))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c55d9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 10%|█         | 1/10 [00:25<03:50, 25.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=1.33416 | val_auc=0.56409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 20%|██        | 2/10 [00:51<03:26, 25.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=1.32950 | val_auc=0.56670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 30%|███       | 3/10 [01:16<02:58, 25.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=1.32829 | val_auc=0.57015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 40%|████      | 4/10 [01:42<02:32, 25.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=1.32712 | val_auc=0.57142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 50%|█████     | 5/10 [02:07<02:06, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=1.32686 | val_auc=0.57075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 60%|██████    | 6/10 [02:32<01:41, 25.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=1.32614 | val_auc=0.57508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 70%|███████   | 7/10 [02:59<01:17, 25.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=1.32530 | val_auc=0.57355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 80%|████████  | 8/10 [03:24<00:51, 25.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=1.32493 | val_auc=0.57485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      " 90%|█████████ | 9/10 [03:49<00:25, 25.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=1.32414 | val_auc=0.57607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "100%|██████████| 10/10 [04:15<00:00, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=1.32345 | val_auc=0.57609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 5) Train loop with early stopping\n",
    "# -------------------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_logits, all_y = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            xb, yb = batch\n",
    "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_y.append(yb.detach().cpu().numpy())\n",
    "    logits = np.concatenate(all_logits)\n",
    "    y_true = np.concatenate(all_y)\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    # AUC для контроля, F1 посчитаем с порогом отдельно\n",
    "    auc = roc_auc_score(y_true, probs)\n",
    "    return auc, probs, y_true\n",
    "\n",
    "best_auc = -np.inf\n",
    "best_state = None\n",
    "patience, patience_left = 8, 8\n",
    "EPOCHS = 10\n",
    "scaler_amp = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "for epoch in tqdm(range(1, EPOCHS+1)):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        xb, yb = batch\n",
    "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        scaler_amp.scale(loss).backward()\n",
    "        scaler_amp.step(optimizer)\n",
    "        scaler_amp.update()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    val_auc, val_probs, val_true = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={epoch_loss/len(train_loader):.5f} | val_auc={val_auc:.5f}\")\n",
    "\n",
    "    if val_auc > best_auc + 1e-4:\n",
    "        best_auc = val_auc\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        patience_left = patience\n",
    "    else:\n",
    "        patience_left -= 1\n",
    "        if patience_left == 0:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# restore best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})\n",
    "\n",
    "# -------------------------\n",
    "# 6) Threshold tuning for F1\n",
    "# -------------------------\n",
    "# вычислим ещё раз на валидации лучшие пороги\n",
    "\n",
    "# # (опционально) можно посмотреть и PR-кривую:\n",
    "# # precisions, recalls, thr = precision_recall_curve(val_true, val_probs)\n",
    "\n",
    "# # -------------------------\n",
    "# # 7) Inference on test + submission\n",
    "# # -------------------------\n",
    "# # прогон по test\n",
    "# model.eval()\n",
    "# test_probs_all = []\n",
    "# with torch.no_grad():\n",
    "#     for xb in sub_loader:\n",
    "#         xb = xb.to(DEVICE)\n",
    "#         logits = model(xb)\n",
    "#         probs = torch.sigmoid(logits)\n",
    "#         test_probs_all.append(probs.detach().cpu().numpy())\n",
    "# test_probs = np.concatenate(test_probs_all)\n",
    "\n",
    "# # бинаризация по найденному порогу\n",
    "# test_pred = (test_probs >= best_t).astype(int)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": X_test[\"id\"].values,\n",
    "#     \"flag\": test_pred\n",
    "# })\n",
    "# submission_path = \"submission_mlp_tabular.csv\"\n",
    "# submission.to_csv(submission_path, index=False)\n",
    "# print(\"Saved:\", submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fbf71415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 on VAL = 0.0820 at threshold=0.550\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, val_probs, val_true = evaluate(model, val_loader)\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "best_t, best_f1 = 0.5, 0.0\n",
    "for t in thresholds:\n",
    "    preds = (val_probs >= t).astype(int)\n",
    "    f1 = f1_score(val_true, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = f1, t\n",
    "\n",
    "print(f\"Best F1 on VAL = {best_f1:.4f} at threshold={best_t:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ef163",
   "metadata": {},
   "source": [
    "## Ансамбль моделей с подбором точности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d77814",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21509c1a",
   "metadata": {},
   "source": [
    "#### Модель A (Catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f47573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6045104\tbest: 0.6045104 (0)\ttotal: 670ms\tremaining: 33m 28s\n",
      "50:\ttest: 0.6217217\tbest: 0.6217217 (50)\ttotal: 25s\tremaining: 24m 4s\n",
      "100:\ttest: 0.6252702\tbest: 0.6252702 (100)\ttotal: 51.3s\tremaining: 24m 31s\n",
      "150:\ttest: 0.6267972\tbest: 0.6268309 (148)\ttotal: 1m 15s\tremaining: 23m 53s\n",
      "200:\ttest: 0.6277178\tbest: 0.6277178 (200)\ttotal: 1m 40s\tremaining: 23m 24s\n",
      "250:\ttest: 0.6282214\tbest: 0.6282214 (250)\ttotal: 2m 6s\tremaining: 23m 9s\n",
      "300:\ttest: 0.6285178\tbest: 0.6285226 (290)\ttotal: 2m 33s\tremaining: 22m 53s\n",
      "350:\ttest: 0.6286735\tbest: 0.6288668 (325)\ttotal: 3m\tremaining: 22m 44s\n",
      "400:\ttest: 0.6287140\tbest: 0.6288668 (325)\ttotal: 3m 27s\tremaining: 22m 24s\n",
      "450:\ttest: 0.6288189\tbest: 0.6288668 (325)\ttotal: 3m 51s\tremaining: 21m 48s\n",
      "500:\ttest: 0.6287415\tbest: 0.6289372 (480)\ttotal: 4m 15s\tremaining: 21m 15s\n",
      "550:\ttest: 0.6281765\tbest: 0.6289372 (480)\ttotal: 4m 40s\tremaining: 20m 46s\n",
      "600:\ttest: 0.6278386\tbest: 0.6289372 (480)\ttotal: 5m 5s\tremaining: 20m 18s\n",
      "650:\ttest: 0.6273008\tbest: 0.6289372 (480)\ttotal: 5m 31s\tremaining: 19m 55s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6289371755\n",
      "bestIteration = 480\n",
      "\n",
      "Shrink model to first 481 iterations.\n",
      "0:\ttest: 0.6112057\tbest: 0.6112057 (0)\ttotal: 476ms\tremaining: 23m 47s\n",
      "50:\ttest: 0.6278006\tbest: 0.6278006 (50)\ttotal: 24.3s\tremaining: 23m 27s\n",
      "100:\ttest: 0.6316633\tbest: 0.6316633 (100)\ttotal: 49.7s\tremaining: 23m 46s\n",
      "150:\ttest: 0.6334957\tbest: 0.6335015 (149)\ttotal: 1m 13s\tremaining: 23m 10s\n",
      "200:\ttest: 0.6344746\tbest: 0.6344746 (200)\ttotal: 1m 40s\tremaining: 23m 16s\n",
      "250:\ttest: 0.6344924\tbest: 0.6345523 (230)\ttotal: 2m 6s\tremaining: 23m 5s\n",
      "300:\ttest: 0.6347786\tbest: 0.6348287 (285)\ttotal: 2m 31s\tremaining: 22m 37s\n",
      "350:\ttest: 0.6349301\tbest: 0.6350651 (324)\ttotal: 2m 56s\tremaining: 22m 14s\n",
      "400:\ttest: 0.6344682\tbest: 0.6350651 (324)\ttotal: 3m 20s\tremaining: 21m 41s\n",
      "450:\ttest: 0.6342556\tbest: 0.6350651 (324)\ttotal: 3m 45s\tremaining: 21m 14s\n",
      "500:\ttest: 0.6342162\tbest: 0.6350651 (324)\ttotal: 4m 9s\tremaining: 20m 42s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6350651115\n",
      "bestIteration = 324\n",
      "\n",
      "Shrink model to first 325 iterations.\n",
      "0:\ttest: 0.6030702\tbest: 0.6030702 (0)\ttotal: 543ms\tremaining: 27m 7s\n",
      "50:\ttest: 0.6212886\tbest: 0.6212886 (50)\ttotal: 24.3s\tremaining: 23m 27s\n",
      "100:\ttest: 0.6250651\tbest: 0.6250651 (100)\ttotal: 50.1s\tremaining: 23m 58s\n",
      "150:\ttest: 0.6261111\tbest: 0.6261111 (150)\ttotal: 1m 15s\tremaining: 23m 37s\n",
      "200:\ttest: 0.6264913\tbest: 0.6265693 (182)\ttotal: 1m 42s\tremaining: 23m 45s\n",
      "250:\ttest: 0.6267524\tbest: 0.6268566 (244)\ttotal: 2m 9s\tremaining: 23m 34s\n",
      "300:\ttest: 0.6268609\tbest: 0.6269168 (298)\ttotal: 2m 36s\tremaining: 23m 24s\n",
      "350:\ttest: 0.6268646\tbest: 0.6269168 (298)\ttotal: 3m 2s\tremaining: 22m 55s\n",
      "400:\ttest: 0.6264601\tbest: 0.6269168 (298)\ttotal: 3m 27s\tremaining: 22m 27s\n",
      "450:\ttest: 0.6259941\tbest: 0.6269168 (298)\ttotal: 3m 54s\tremaining: 22m 4s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6269168153\n",
      "bestIteration = 298\n",
      "\n",
      "Shrink model to first 299 iterations.\n",
      "0:\ttest: 0.6041389\tbest: 0.6041389 (0)\ttotal: 496ms\tremaining: 24m 47s\n",
      "50:\ttest: 0.6223165\tbest: 0.6223165 (50)\ttotal: 25.1s\tremaining: 24m 8s\n",
      "100:\ttest: 0.6263563\tbest: 0.6263563 (100)\ttotal: 50.3s\tremaining: 24m 4s\n",
      "150:\ttest: 0.6283259\tbest: 0.6283259 (150)\ttotal: 1m 14s\tremaining: 23m 32s\n",
      "200:\ttest: 0.6292896\tbest: 0.6292936 (199)\ttotal: 1m 39s\tremaining: 23m 4s\n",
      "250:\ttest: 0.6295466\tbest: 0.6295466 (250)\ttotal: 2m 4s\tremaining: 22m 43s\n",
      "300:\ttest: 0.6298154\tbest: 0.6298254 (289)\ttotal: 2m 30s\tremaining: 22m 27s\n",
      "350:\ttest: 0.6299097\tbest: 0.6299522 (344)\ttotal: 2m 54s\tremaining: 21m 57s\n",
      "400:\ttest: 0.6298189\tbest: 0.6300650 (372)\ttotal: 3m 18s\tremaining: 21m 24s\n",
      "450:\ttest: 0.6295911\tbest: 0.6300650 (372)\ttotal: 3m 42s\tremaining: 20m 56s\n",
      "500:\ttest: 0.6296658\tbest: 0.6300650 (372)\ttotal: 4m 7s\tremaining: 20m 37s\n",
      "550:\ttest: 0.6296075\tbest: 0.6300650 (372)\ttotal: 4m 37s\tremaining: 20m 33s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6300649846\n",
      "bestIteration = 372\n",
      "\n",
      "Shrink model to first 373 iterations.\n",
      "0:\ttest: 0.6068149\tbest: 0.6068149 (0)\ttotal: 598ms\tremaining: 29m 52s\n",
      "50:\ttest: 0.6215221\tbest: 0.6215221 (50)\ttotal: 28.4s\tremaining: 27m 19s\n",
      "100:\ttest: 0.6249377\tbest: 0.6249563 (99)\ttotal: 56s\tremaining: 26m 47s\n",
      "150:\ttest: 0.6265113\tbest: 0.6265113 (150)\ttotal: 1m 23s\tremaining: 26m 21s\n",
      "200:\ttest: 0.6271670\tbest: 0.6271670 (200)\ttotal: 1m 53s\tremaining: 26m 23s\n",
      "250:\ttest: 0.6271444\tbest: 0.6273459 (243)\ttotal: 2m 26s\tremaining: 26m 46s\n",
      "300:\ttest: 0.6271002\tbest: 0.6273459 (243)\ttotal: 2m 58s\tremaining: 26m 43s\n",
      "350:\ttest: 0.6266478\tbest: 0.6273459 (243)\ttotal: 3m 24s\tremaining: 25m 44s\n",
      "400:\ttest: 0.6262844\tbest: 0.6273459 (243)\ttotal: 3m 50s\tremaining: 24m 56s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6273458798\n",
      "bestIteration = 243\n",
      "\n",
      "Shrink model to first 244 iterations.\n"
     ]
    }
   ],
   "source": [
    "oof_cb  = np.zeros(len(X_tr), dtype=np.float32)\n",
    "test_cb = np.zeros(len(X_te), dtype=np.float32)\n",
    "models = {}\n",
    "\n",
    "for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
    "    Xtr, Xvl = X_tr.iloc[tr_idx], X_tr.iloc[vl_idx]\n",
    "    ytr, yvl = y_tr[tr_idx],     y_tr[vl_idx]\n",
    "\n",
    "    model_cb = CatBoostClassifier(\n",
    "        iterations=3000,\n",
    "        depth=10,\n",
    "        learning_rate=0.03,\n",
    "        l2_leaf_reg=12,\n",
    "        bagging_temperature=0.4,\n",
    "        auto_class_weights='Balanced',  # важный момент при 3.3% позитивов\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        verbose=50,\n",
    "        early_stopping_rounds=200,\n",
    "        \n",
    "    )\n",
    "    model_cb.fit(Xtr, ytr, eval_set=(Xvl, yvl), use_best_model=True)\n",
    "\n",
    "    models[fold] = model_cb\n",
    "    oof_cb[vl_idx] = model_cb.predict_proba(Xvl)[:, 1]\n",
    "    test_cb       += model_cb.predict_proba(X_te)[:, 1] / skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f3d5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_cb_e  = np.zeros(len(X_tr), dtype=np.float32)\n",
    "for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
    "    Xtr, Xvl = X_tr.iloc[tr_idx], X_tr.iloc[vl_idx]\n",
    "    ytr, yvl = y_tr[tr_idx],     y_tr[vl_idx]\n",
    "\n",
    "    oof_cb_e[vl_idx] = models[fold].predict(Xvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf74a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost OOF AUC: 0.62959\n",
      "CatBoost OOF AUC: 0.09270\n"
     ]
    }
   ],
   "source": [
    "auc_cb = roc_auc_score(y_tr, oof_cb)\n",
    "f1_cb = f1_score(y_tr, oof_cb_e)\n",
    "print(f\"CatBoost OOF AUC: {auc_cb:.5f}\")\n",
    "print(f\"CatBoost OOF AUC: {f1_cb:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf0bdb",
   "metadata": {},
   "source": [
    "#### Модель Лёгкая GRU на risk-последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48859f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDS(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = None if y is None else torch.from_numpy(y.astype(np.float32))\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return (self.X[i], self.y[i]) if self.y is not None else self.X[i]\n",
    "\n",
    "class GRUSimple(nn.Module):\n",
    "    def __init__(self, hidden=64):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=1, hidden_size=hidden, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, 64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):            # x: [B, 25]\n",
    "        x = x.unsqueeze(-1)         # -> [B, 25, 1]\n",
    "        out, _ = self.gru(x)        # -> [B, 25, H]\n",
    "        feat = out[:, -1, :]        # берём последнее скрытое состояние\n",
    "        logit = self.head(feat)     # -> [B, 1]\n",
    "        return logit.squeeze(1)     # -> [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "97cb3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_gru_oof(X, y, Xtest, folds, epochs=5, bs=8192, pos_weight=30.0, lr=2e-3):\n",
    "    oof = np.zeros(len(X), dtype=np.float32)\n",
    "    tpred = np.zeros(len(Xtest), dtype=np.float32)\n",
    "\n",
    "    for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
    "        ds_tr = SeqDS(X[tr_idx], y[tr_idx])\n",
    "        ds_vl = SeqDS(X[vl_idx], y[vl_idx])\n",
    "        ds_te = SeqDS(Xtest, None)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_size=bs, shuffle=True)\n",
    "        dl_vl = DataLoader(ds_vl, batch_size=bs, shuffle=False)\n",
    "        dl_te = DataLoader(ds_te, batch_size=bs, shuffle=False)\n",
    "\n",
    "        model = GRUSimple(hidden=64).to(DEVICE)\n",
    "        crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight, device=DEVICE))\n",
    "        opt  = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "        best_auc, best_state = -1, None\n",
    "        for ep in tqdm(range(epochs)):\n",
    "            # train\n",
    "            model.train()\n",
    "            for xb, yb in dl_tr:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                loss = crit(model(xb), yb)\n",
    "                loss.backward(); opt.step()\n",
    "            # valid\n",
    "            model.eval()\n",
    "            logits, yt = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in dl_vl:\n",
    "                    xb = xb.to(DEVICE)\n",
    "                    lg = model(xb).detach().cpu().numpy()\n",
    "                    logits.append(lg); yt.append(yb.numpy())\n",
    "            p  = 1 / (1 + np.exp(-np.concatenate(logits)))\n",
    "            yt = np.concatenate(yt)\n",
    "            auc = roc_auc_score(yt, p)\n",
    "            print('auc: ', auc)\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "\n",
    "        # restore best\n",
    "        model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()})\n",
    "        # OOF\n",
    "        model.eval()\n",
    "        logits=[]\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_vl:\n",
    "                xb = xb.to(DEVICE)\n",
    "                logits.append(model(xb).detach().cpu().numpy())\n",
    "        oof[vl_idx] = 1/(1+np.exp(-np.concatenate(logits)))\n",
    "        # test\n",
    "        logits=[]\n",
    "        with torch.no_grad():\n",
    "            for xb in dl_te:\n",
    "                xb = xb.to(DEVICE)\n",
    "                logits.append(model(xb).detach().cpu().numpy())\n",
    "        tpred += (1/(1+np.exp(-np.concatenate(logits)))) / len(folds)\n",
    "\n",
    "    return oof, tpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e068cb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [04:39<23:17, 279.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5331281027001792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [10:12<20:43, 310.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.49041007993867813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [14:36<14:28, 289.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5435256411445505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [18:48<09:09, 274.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5506590510301184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [23:22<04:34, 274.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5514856447043527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [27:58<00:00, 279.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5541296732679302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [04:35<22:58, 275.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5441724694485535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [09:09<18:19, 274.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5571701174328637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [13:45<13:45, 275.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5452484111654339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [18:21<09:10, 275.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5593424266052103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [22:52<04:33, 273.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5608492910790548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [27:09<00:00, 271.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.564024205210587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [04:35<22:56, 275.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5387813402125681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [09:10<18:20, 275.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5536234251377548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [13:35<13:32, 270.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5507426070849298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [17:50<08:48, 264.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5500814496862709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [23:13<04:45, 285.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5548812275776493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [28:01<00:00, 280.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5308226187973175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [06:12<31:04, 372.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.4945372119633191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [12:13<24:22, 365.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5153153387383305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [18:09<18:03, 361.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5496171161600252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [23:58<11:53, 356.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5518872407782766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [29:44<05:52, 352.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5468426104291914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [35:44<00:00, 357.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5547404364060662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [05:15<26:16, 315.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5375974116921729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [09:44<19:12, 288.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.533565468375702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [14:28<14:18, 286.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5145364462335472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [18:37<09:03, 271.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5529589760709148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [22:47<04:23, 263.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5547697019793474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [27:41<00:00, 276.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.5593875829078722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oof_gru, test_gru = train_gru_oof(risk_seq_tr, y_tr, risk_seq_te, folds, epochs=6, bs=8192, pos_weight=30.0, lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b999437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU OOF AUC: 0.51149\n"
     ]
    }
   ],
   "source": [
    "auc_gru = roc_auc_score(y_tr, oof_gru)\n",
    "print(f\"GRU OOF AUC: {auc_gru:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289ce18",
   "metadata": {},
   "source": [
    "#### Бленд и подбор порога под F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bf5bc632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF F1(best): 0.1606 @ threshold=0.620\n"
     ]
    }
   ],
   "source": [
    "oof_blend  = oof_cb.copy()\n",
    "test_blend = test_cb.copy()\n",
    "\n",
    "try:\n",
    "    oof_blend  = 0.7*y_val_pred_proba + 0.2*oof_cb + 0.1*oof_gru\n",
    "    test_blend = 0.7*fpo_test+0.2*test_cb + 0.1*test_gru\n",
    "except NameError:\n",
    "    pass  # GRU не считали — используем только CatBoost\n",
    "\n",
    "best_t, best_f1 = 0.5, 0.0\n",
    "for t in np.linspace(0.01, 0.7, 70):\n",
    "    f1 = f1_score(y_tr, (oof_blend >= t).astype(int))\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = f1, t\n",
    "print(f\"OOF F1(best): {best_f1:.4f} @ threshold={best_t:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6daef361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [04:17<00:00, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal coefficients: FPO=0.827, CB=0.100, GRU=0.073\n",
      "Optimal threshold: 0.629\n",
      "OOF F1(best): 0.1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "oof_blend = oof_cb.copy()\n",
    "test_blend = test_cb.copy()\n",
    "\n",
    "try:\n",
    "    best_f1 = 0.0\n",
    "    best_params = {}\n",
    "    f = np.linspace(0.1, 0.9, 12)\n",
    "    \n",
    "    # Перебираем различные комбинации коэффициентов\n",
    "    for i in tqdm(range(0, len(f))):\n",
    "        coef_fpo = f[i]\n",
    "        for coef_cb in np.linspace(0.1, 0.9, 12):\n",
    "            coef_gru = 1.0 - coef_fpo - coef_cb\n",
    "            \n",
    "            # Пропускаем невалидные комбинации\n",
    "            if coef_gru < 0:\n",
    "                continue\n",
    "            \n",
    "            # Создаем блендинг\n",
    "            current_oof = coef_fpo * y_val_pred_proba + coef_cb * oof_cb + coef_gru * oof_gru\n",
    "            \n",
    "            # Оптимизируем порог для этой комбинации коэффициентов\n",
    "            for t in np.linspace(0.01, 0.8, 30):\n",
    "                f1 = f1_score(y_tr, (current_oof >= t).astype(int))\n",
    "                \n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_params = {\n",
    "                        'coef_fpo': coef_fpo,\n",
    "                        'coef_cb': coef_cb,\n",
    "                        'coef_gru': coef_gru,\n",
    "                        'threshold': t\n",
    "                    }\n",
    "    \n",
    "    print(f\"Optimal coefficients: FPO={best_params['coef_fpo']:.3f}, \"\n",
    "          f\"CB={best_params['coef_cb']:.3f}, GRU={best_params['coef_gru']:.3f}\")\n",
    "    print(f\"Optimal threshold: {best_params['threshold']:.3f}\")\n",
    "    print(f\"OOF F1(best): {best_f1:.4f}\")\n",
    "    \n",
    "    # Создаем финальные предсказания\n",
    "    oof_blend = (best_params['coef_fpo'] * y_val_pred_proba + \n",
    "                 best_params['coef_cb'] * oof_cb + \n",
    "                 best_params['coef_gru'] * oof_gru)\n",
    "    \n",
    "    test_blend = (best_params['coef_fpo'] * fpo_test + \n",
    "                  best_params['coef_cb'] * test_cb + \n",
    "                  best_params['coef_gru'] * test_gru)\n",
    "\n",
    "except NameError:\n",
    "    # Если GRU не доступен, оптимизируем только порог\n",
    "    print(\"GRU not available - optimizing threshold only\")\n",
    "    \n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    for t in np.linspace(0.01, 0.7, 70):\n",
    "        f1 = f1_score(y_tr, (oof_blend >= t).astype(int))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    \n",
    "    print(f\"OOF F1(best): {best_f1:.4f} @ threshold={best_t:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8428b783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.1, 0.9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3a07037",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_blend = 0.827*fpo_test+0.1*test_cb + 0.073*test_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "45769882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_soq_final_blend.csv\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'].values,\n",
    "    'flag': (test_blend >= 0.629).astype(int)\n",
    "})\n",
    "submission.to_csv(\"submission_soq_final_blend.csv\", index=False)\n",
    "print(\"Saved: submission_soq_final_blend.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
