{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "445bd7d5",
      "metadata": {
        "id": "445bd7d5"
      },
      "source": [
        "# School of Quants hackathon 2025 – Finals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d32d546",
      "metadata": {
        "id": "4d32d546"
      },
      "source": [
        "## Импорты и настройки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3638b7bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3638b7bb",
        "outputId": "8a6e959b-001d-4f18-c15a-a54e7fa27bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cpu\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "# ЯЧЕЙКА 8 — GRU по risk-последовательности\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6ce1e8",
      "metadata": {
        "id": "2b6ce1e8"
      },
      "source": [
        "## Данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "Q9Tl0vTG4LJT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Tl0vTG4LJT",
        "outputId": "c5fdbb3c-74cb-43b6-e001-283d51cffc0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "ec1508d5",
      "metadata": {
        "id": "ec1508d5"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('res_2/X_train.csv')\n",
        "y_train = pd.read_csv('res_2/y_train.csv')\n",
        "X_test = pd.read_csv('res_2/X_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "04feef4a",
      "metadata": {
        "id": "04feef4a"
      },
      "outputs": [],
      "source": [
        "df = X_train.copy()\n",
        "df = df.sort_values(by='id').set_index('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f7111960",
      "metadata": {
        "id": "f7111960"
      },
      "outputs": [],
      "source": [
        "df['target'] = y_train.set_index('id')['flag']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "074ba0eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "074ba0eb",
        "outputId": "58a4598f-62e8-45b6-924c-90989180421b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['credit_number_for_user', 'days_since_confirmed', 'maturity_plan',\n",
              "       'maturity_fact', 'credit_limit', 'next_payment_sum', 'sum_left_to_pay',\n",
              "       'current_overdue_debt', 'max_overdue_debt', 'full_credit_cost',\n",
              "       'overdues_5d', 'overdues_5d_30d', 'overdues_30d_60d',\n",
              "       'overdues_60d_90d', 'overdues_90d', 'no_overdues_5d',\n",
              "       'no_overdues_5d_30d', 'no_overdues_30d_60d', 'no_overdues_60d_90d',\n",
              "       'no_overdues_90d', 'enc_paym_0', 'enc_paym_1', 'enc_paym_2',\n",
              "       'enc_paym_3', 'enc_paym_4', 'enc_paym_5', 'enc_paym_6', 'enc_paym_7',\n",
              "       'enc_paym_8', 'enc_paym_9', 'enc_paym_10', 'enc_paym_11', 'enc_paym_12',\n",
              "       'enc_paym_13', 'enc_paym_14', 'enc_paym_15', 'enc_paym_16',\n",
              "       'enc_paym_17', 'enc_paym_18', 'enc_paym_19', 'enc_paym_20',\n",
              "       'enc_paym_21', 'enc_paym_22', 'enc_paym_23', 'enc_paym_24',\n",
              "       'credit_type', 'credit_currency', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc57657b",
      "metadata": {
        "id": "cc57657b"
      },
      "source": [
        "## Исследование данных и анализ признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88e9f433",
      "metadata": {
        "id": "88e9f433"
      },
      "source": [
        "### enc_paym_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88c139b",
      "metadata": {
        "id": "b88c139b"
      },
      "source": [
        "#### Анализ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5150532",
      "metadata": {
        "id": "c5150532"
      },
      "source": [
        "Надо однозначно понять, что за статусы платежей представлены, вот динамика платежей по месяцам (`enc_paym_{0..N}` - Статусы ежемесячных платежей за последние N месяцев***):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3d2c749f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3d2c749f",
        "outputId": "82bc9c58-50a0-4881-e51e-9ad0b872b329"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>status_0</th>\n",
              "      <th>status_1</th>\n",
              "      <th>status_2</th>\n",
              "      <th>status_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1695569</td>\n",
              "      <td>53323</td>\n",
              "      <td>3950</td>\n",
              "      <td>74562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1528964</td>\n",
              "      <td>103377</td>\n",
              "      <td>8043</td>\n",
              "      <td>187020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1447139</td>\n",
              "      <td>92128</td>\n",
              "      <td>7369</td>\n",
              "      <td>280768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1374843</td>\n",
              "      <td>87819</td>\n",
              "      <td>7042</td>\n",
              "      <td>357700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1302740</td>\n",
              "      <td>82808</td>\n",
              "      <td>6396</td>\n",
              "      <td>435460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1227907</td>\n",
              "      <td>76923</td>\n",
              "      <td>5967</td>\n",
              "      <td>516607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1142545</td>\n",
              "      <td>70554</td>\n",
              "      <td>5145</td>\n",
              "      <td>609160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1050430</td>\n",
              "      <td>65498</td>\n",
              "      <td>4804</td>\n",
              "      <td>706672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>988710</td>\n",
              "      <td>60230</td>\n",
              "      <td>4347</td>\n",
              "      <td>774117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>927778</td>\n",
              "      <td>55380</td>\n",
              "      <td>3935</td>\n",
              "      <td>840311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>858238</td>\n",
              "      <td>50296</td>\n",
              "      <td>3520</td>\n",
              "      <td>915350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>777067</td>\n",
              "      <td>45193</td>\n",
              "      <td>3288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>701885</td>\n",
              "      <td>40580</td>\n",
              "      <td>3117</td>\n",
              "      <td>1081822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>621536</td>\n",
              "      <td>37886</td>\n",
              "      <td>3017</td>\n",
              "      <td>1164965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>581132</td>\n",
              "      <td>36525</td>\n",
              "      <td>2921</td>\n",
              "      <td>1206826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>550258</td>\n",
              "      <td>34864</td>\n",
              "      <td>2868</td>\n",
              "      <td>1239414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>522800</td>\n",
              "      <td>33093</td>\n",
              "      <td>2851</td>\n",
              "      <td>1268660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>496972</td>\n",
              "      <td>31774</td>\n",
              "      <td>2730</td>\n",
              "      <td>1295928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>470208</td>\n",
              "      <td>30164</td>\n",
              "      <td>2737</td>\n",
              "      <td>1324295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>445316</td>\n",
              "      <td>28872</td>\n",
              "      <td>2521</td>\n",
              "      <td>1350695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>424153</td>\n",
              "      <td>27547</td>\n",
              "      <td>2475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>404982</td>\n",
              "      <td>26168</td>\n",
              "      <td>2394</td>\n",
              "      <td>1393860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>385444</td>\n",
              "      <td>25101</td>\n",
              "      <td>2286</td>\n",
              "      <td>1414573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>365429</td>\n",
              "      <td>23665</td>\n",
              "      <td>2050</td>\n",
              "      <td>1436260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>288117</td>\n",
              "      <td>18622</td>\n",
              "      <td>1741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  status_0  status_1  status_2  status_3\n",
              "0       0   1695569     53323      3950     74562\n",
              "1       1   1528964    103377      8043    187020\n",
              "2       2   1447139     92128      7369    280768\n",
              "3       3   1374843     87819      7042    357700\n",
              "4       4   1302740     82808      6396    435460\n",
              "5       5   1227907     76923      5967    516607\n",
              "6       6   1142545     70554      5145    609160\n",
              "7       7   1050430     65498      4804    706672\n",
              "8       8    988710     60230      4347    774117\n",
              "9       9    927778     55380      3935    840311\n",
              "10     10    858238     50296      3520    915350\n",
              "11     11         0    777067     45193      3288\n",
              "12     12    701885     40580      3117   1081822\n",
              "13     13    621536     37886      3017   1164965\n",
              "14     14    581132     36525      2921   1206826\n",
              "15     15    550258     34864      2868   1239414\n",
              "16     16    522800     33093      2851   1268660\n",
              "17     17    496972     31774      2730   1295928\n",
              "18     18    470208     30164      2737   1324295\n",
              "19     19    445316     28872      2521   1350695\n",
              "20     20         0    424153     27547      2475\n",
              "21     21    404982     26168      2394   1393860\n",
              "22     22    385444     25101      2286   1414573\n",
              "23     23    365429     23665      2050   1436260\n",
              "24     24         0    288117     18622      1741"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data = []\n",
        "for month in range(0, 25):\n",
        "    payment_counts = X_train.groupby(f'enc_paym_{month}')['id'].count()\n",
        "    month_data = {\n",
        "        'month': month,\n",
        "        'status_0': payment_counts.get(0, 0),\n",
        "        'status_1': payment_counts.get(1, 0),\n",
        "        'status_2': payment_counts.get(2, 0),\n",
        "        'status_3': payment_counts.get(3, 0)\n",
        "    }\n",
        "    all_data.append(month_data)\n",
        "result_df = pd.DataFrame(all_data)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "246f1480",
      "metadata": {
        "id": "246f1480"
      },
      "source": [
        "Можно заметить, что 11, 20, 24ый месяцы отсутствуте значение status_0, но это ОБМАН, по динамике как раз видно, что данные сдвинуты и не хвататет как раз `status_3`. Посмотрим на тестовые данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d51efb32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d51efb32",
        "outputId": "03335b70-b1a5-46af-8b00-b4042c1a45b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>status_0</th>\n",
              "      <th>status_1</th>\n",
              "      <th>status_2</th>\n",
              "      <th>status_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1695569</td>\n",
              "      <td>53323</td>\n",
              "      <td>3950</td>\n",
              "      <td>74562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1528964</td>\n",
              "      <td>103377</td>\n",
              "      <td>8043</td>\n",
              "      <td>187020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1447139</td>\n",
              "      <td>92128</td>\n",
              "      <td>7369</td>\n",
              "      <td>280768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1374843</td>\n",
              "      <td>87819</td>\n",
              "      <td>7042</td>\n",
              "      <td>357700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1302740</td>\n",
              "      <td>82808</td>\n",
              "      <td>6396</td>\n",
              "      <td>435460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1227907</td>\n",
              "      <td>76923</td>\n",
              "      <td>5967</td>\n",
              "      <td>516607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1142545</td>\n",
              "      <td>70554</td>\n",
              "      <td>5145</td>\n",
              "      <td>609160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1050430</td>\n",
              "      <td>65498</td>\n",
              "      <td>4804</td>\n",
              "      <td>706672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>988710</td>\n",
              "      <td>60230</td>\n",
              "      <td>4347</td>\n",
              "      <td>774117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>927778</td>\n",
              "      <td>55380</td>\n",
              "      <td>3935</td>\n",
              "      <td>840311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>858238</td>\n",
              "      <td>50296</td>\n",
              "      <td>3520</td>\n",
              "      <td>915350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>777067</td>\n",
              "      <td>45193</td>\n",
              "      <td>3288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>701885</td>\n",
              "      <td>40580</td>\n",
              "      <td>3117</td>\n",
              "      <td>1081822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>621536</td>\n",
              "      <td>37886</td>\n",
              "      <td>3017</td>\n",
              "      <td>1164965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>581132</td>\n",
              "      <td>36525</td>\n",
              "      <td>2921</td>\n",
              "      <td>1206826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>550258</td>\n",
              "      <td>34864</td>\n",
              "      <td>2868</td>\n",
              "      <td>1239414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>522800</td>\n",
              "      <td>33093</td>\n",
              "      <td>2851</td>\n",
              "      <td>1268660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>496972</td>\n",
              "      <td>31774</td>\n",
              "      <td>2730</td>\n",
              "      <td>1295928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>470208</td>\n",
              "      <td>30164</td>\n",
              "      <td>2737</td>\n",
              "      <td>1324295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>445316</td>\n",
              "      <td>28872</td>\n",
              "      <td>2521</td>\n",
              "      <td>1350695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>424153</td>\n",
              "      <td>27547</td>\n",
              "      <td>2475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>404982</td>\n",
              "      <td>26168</td>\n",
              "      <td>2394</td>\n",
              "      <td>1393860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>385444</td>\n",
              "      <td>25101</td>\n",
              "      <td>2286</td>\n",
              "      <td>1414573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>365429</td>\n",
              "      <td>23665</td>\n",
              "      <td>2050</td>\n",
              "      <td>1436260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>288117</td>\n",
              "      <td>18622</td>\n",
              "      <td>1741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  status_0  status_1  status_2  status_3\n",
              "0       0   1695569     53323      3950     74562\n",
              "1       1   1528964    103377      8043    187020\n",
              "2       2   1447139     92128      7369    280768\n",
              "3       3   1374843     87819      7042    357700\n",
              "4       4   1302740     82808      6396    435460\n",
              "5       5   1227907     76923      5967    516607\n",
              "6       6   1142545     70554      5145    609160\n",
              "7       7   1050430     65498      4804    706672\n",
              "8       8    988710     60230      4347    774117\n",
              "9       9    927778     55380      3935    840311\n",
              "10     10    858238     50296      3520    915350\n",
              "11     11         0    777067     45193      3288\n",
              "12     12    701885     40580      3117   1081822\n",
              "13     13    621536     37886      3017   1164965\n",
              "14     14    581132     36525      2921   1206826\n",
              "15     15    550258     34864      2868   1239414\n",
              "16     16    522800     33093      2851   1268660\n",
              "17     17    496972     31774      2730   1295928\n",
              "18     18    470208     30164      2737   1324295\n",
              "19     19    445316     28872      2521   1350695\n",
              "20     20         0    424153     27547      2475\n",
              "21     21    404982     26168      2394   1393860\n",
              "22     22    385444     25101      2286   1414573\n",
              "23     23    365429     23665      2050   1436260\n",
              "24     24         0    288117     18622      1741"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data = []\n",
        "for month in range(0, 25):\n",
        "    payment_counts = X_train.groupby(f'enc_paym_{month}')['id'].count()\n",
        "\n",
        "    month_data = {\n",
        "        'month': month,\n",
        "        'status_0': payment_counts.get(0, 0),\n",
        "        'status_1': payment_counts.get(1, 0),\n",
        "        'status_2': payment_counts.get(2, 0),\n",
        "        'status_3': payment_counts.get(3, 0)\n",
        "    }\n",
        "    all_data.append(month_data)\n",
        "result_df = pd.DataFrame(all_data)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a5e88640",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a5e88640",
        "outputId": "2a0e9847-a2c5-474c-8df6-79537ddbc40c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>status_0</th>\n",
              "      <th>status_1</th>\n",
              "      <th>status_2</th>\n",
              "      <th>status_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1695569</td>\n",
              "      <td>53323</td>\n",
              "      <td>3950</td>\n",
              "      <td>74562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1528964</td>\n",
              "      <td>103377</td>\n",
              "      <td>8043</td>\n",
              "      <td>187020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1447139</td>\n",
              "      <td>92128</td>\n",
              "      <td>7369</td>\n",
              "      <td>280768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1374843</td>\n",
              "      <td>87819</td>\n",
              "      <td>7042</td>\n",
              "      <td>357700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1302740</td>\n",
              "      <td>82808</td>\n",
              "      <td>6396</td>\n",
              "      <td>435460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1227907</td>\n",
              "      <td>76923</td>\n",
              "      <td>5967</td>\n",
              "      <td>516607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1142545</td>\n",
              "      <td>70554</td>\n",
              "      <td>5145</td>\n",
              "      <td>609160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1050430</td>\n",
              "      <td>65498</td>\n",
              "      <td>4804</td>\n",
              "      <td>706672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>988710</td>\n",
              "      <td>60230</td>\n",
              "      <td>4347</td>\n",
              "      <td>774117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>927778</td>\n",
              "      <td>55380</td>\n",
              "      <td>3935</td>\n",
              "      <td>840311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>858238</td>\n",
              "      <td>50296</td>\n",
              "      <td>3520</td>\n",
              "      <td>915350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>777067</td>\n",
              "      <td>45193</td>\n",
              "      <td>3288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>701885</td>\n",
              "      <td>40580</td>\n",
              "      <td>3117</td>\n",
              "      <td>1081822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>621536</td>\n",
              "      <td>37886</td>\n",
              "      <td>3017</td>\n",
              "      <td>1164965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>581132</td>\n",
              "      <td>36525</td>\n",
              "      <td>2921</td>\n",
              "      <td>1206826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>550258</td>\n",
              "      <td>34864</td>\n",
              "      <td>2868</td>\n",
              "      <td>1239414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>522800</td>\n",
              "      <td>33093</td>\n",
              "      <td>2851</td>\n",
              "      <td>1268660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>496972</td>\n",
              "      <td>31774</td>\n",
              "      <td>2730</td>\n",
              "      <td>1295928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>470208</td>\n",
              "      <td>30164</td>\n",
              "      <td>2737</td>\n",
              "      <td>1324295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>445316</td>\n",
              "      <td>28872</td>\n",
              "      <td>2521</td>\n",
              "      <td>1350695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>424153</td>\n",
              "      <td>27547</td>\n",
              "      <td>2475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>404982</td>\n",
              "      <td>26168</td>\n",
              "      <td>2394</td>\n",
              "      <td>1393860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>385444</td>\n",
              "      <td>25101</td>\n",
              "      <td>2286</td>\n",
              "      <td>1414573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>365429</td>\n",
              "      <td>23665</td>\n",
              "      <td>2050</td>\n",
              "      <td>1436260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>288117</td>\n",
              "      <td>18622</td>\n",
              "      <td>1741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  status_0  status_1  status_2  status_3\n",
              "0       0   1695569     53323      3950     74562\n",
              "1       1   1528964    103377      8043    187020\n",
              "2       2   1447139     92128      7369    280768\n",
              "3       3   1374843     87819      7042    357700\n",
              "4       4   1302740     82808      6396    435460\n",
              "5       5   1227907     76923      5967    516607\n",
              "6       6   1142545     70554      5145    609160\n",
              "7       7   1050430     65498      4804    706672\n",
              "8       8    988710     60230      4347    774117\n",
              "9       9    927778     55380      3935    840311\n",
              "10     10    858238     50296      3520    915350\n",
              "11     11         0    777067     45193      3288\n",
              "12     12    701885     40580      3117   1081822\n",
              "13     13    621536     37886      3017   1164965\n",
              "14     14    581132     36525      2921   1206826\n",
              "15     15    550258     34864      2868   1239414\n",
              "16     16    522800     33093      2851   1268660\n",
              "17     17    496972     31774      2730   1295928\n",
              "18     18    470208     30164      2737   1324295\n",
              "19     19    445316     28872      2521   1350695\n",
              "20     20         0    424153     27547      2475\n",
              "21     21    404982     26168      2394   1393860\n",
              "22     22    385444     25101      2286   1414573\n",
              "23     23    365429     23665      2050   1436260\n",
              "24     24         0    288117     18622      1741"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data = []\n",
        "for month in range(0, 25):\n",
        "    payment_counts = X_train.groupby(f'enc_paym_{month}')['id'].count()\n",
        "\n",
        "    month_data = {\n",
        "        'month': month,\n",
        "        'status_0': payment_counts.get(0, 0),\n",
        "        'status_1': payment_counts.get(1, 0),\n",
        "        'status_2': payment_counts.get(2, 0),\n",
        "        'status_3': payment_counts.get(3, 0)\n",
        "    }\n",
        "    all_data.append(month_data)\n",
        "result_df = pd.DataFrame(all_data)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4a284cb8",
      "metadata": {
        "id": "4a284cb8"
      },
      "outputs": [],
      "source": [
        "# Сдвигаем определённые месяца\n",
        "map_enc_paym_ = {1:0, 2:1, 3:2, 4:3}\n",
        "\n",
        "df['enc_paym_11'] = df['enc_paym_11'].map(map_enc_paym_)\n",
        "df['enc_paym_20'] = df['enc_paym_20'].map(map_enc_paym_)\n",
        "df['enc_paym_24'] = df['enc_paym_24'].map(map_enc_paym_)\n",
        "\n",
        "X_test['enc_paym_11'] = X_test['enc_paym_11'].map(map_enc_paym_)\n",
        "X_test['enc_paym_20'] = X_test['enc_paym_20'].map(map_enc_paym_)\n",
        "X_test['enc_paym_24'] = X_test['enc_paym_24'].map(map_enc_paym_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7054dc90",
      "metadata": {
        "id": "7054dc90"
      },
      "source": [
        "Так всё же, что это за статусы? Если исходить из простой банковской логики и посчитать распределение дефолтов согласно статусам:\n",
        "|N|default_rate|\n",
        "|----------|----------|\n",
        "|2 |0.125000 |\n",
        "|1| 0.051819 |\n",
        "|3 |0.034540 |\n",
        "|0| 0.028840 |\n",
        "\n",
        "\n",
        "- **Статус 0**: Своевременный платёж (timely paid). Доминирует в недавних месяцах (382k в месяц 1, ~80% активных кредитов), корреляция с target=False (не-дефолт) выше. Это \"заплочено вовремя\".\n",
        "- **Статус 3**: Лёгкая/средняя просрочка (past due 1–60 дней). Редкий (25k–6k, ~5–1%), чаще у дефолтеров (target=True, до 25% в примерах), коррелирует с overdues_5d_30d. Это \"просрочено\" на ранних стадиях.\n",
        "- **Статус 1**: Тяжёлая просрочка (past due 60+ дней или charge-off). Очень редкий (<0.5%, 2k–0.5k), почти только у дефолтеров, коррелирует с overdues_60d_90d/overdues_90d. Это \"сильно просрочено\".\n",
        "- **Статус 2**: Это очень серьёзный маркер дефолта.\n",
        "\n",
        "На основе датасета, идея - создать метрики, учитывающие:\n",
        "- Количество и тяжесть просрочек (1, 2) в последних месяцах.\n",
        "- Последовательности (streaks) или переходы (например, 0→1→2 хуже, чем 1→0).\n",
        "- Веса для recency: недавние месяцы (enc_paym_0–2) важнее, чем enc_paym_3–5."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0563cf6",
      "metadata": {
        "id": "f0563cf6"
      },
      "source": [
        "#### Сложные признаки"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e68a67",
      "metadata": {
        "id": "b0e68a67"
      },
      "source": [
        "Заменяем случайные веса на осмысленные, которые увеличиваются с увеличением риска:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "76d633ee",
      "metadata": {
        "id": "76d633ee"
      },
      "outputs": [],
      "source": [
        "enc_paym_corrected = {\n",
        "    0: 0,  #  → 0 (лучшая ситуация)\n",
        "    3: 1,  #  → 1 (средний риск)\n",
        "    1: 2,  #  → 2 (высокий риск)\n",
        "    2: 3   #  → 3 (максимальный риск)\n",
        "}\n",
        "for month in range(0, 25):\n",
        "    df[f'enc_paym_{month}'] = df[f'enc_paym_{month}'].map(enc_paym_corrected)\n",
        "    X_test[f'enc_paym_{month}'] = X_test[f'enc_paym_{month}'].map(enc_paym_corrected)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1494f428",
      "metadata": {
        "id": "1494f428"
      },
      "source": [
        "#### Взвешенная сумма статусов (дисконтированная по времени)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91c536c",
      "metadata": {
        "id": "e91c536c"
      },
      "source": [
        "$$S=s_0​⋅1+s_1​⋅0.9+s_2​⋅0.8+…$$\n",
        "\n",
        "Смысл:\n",
        "- чем ближе к текущему моменту плохие статусы, тем сильнее они влияют;\n",
        "- штрафы за «старые» косяки постепенно уменьшаются.\n",
        "Это очень информативный признак, потому что модель получит сглаженный показатель уровня риска клиента с учётом динамики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9fc026fc",
      "metadata": {
        "id": "9fc026fc"
      },
      "outputs": [],
      "source": [
        "def weighted_status_score(df, w):\n",
        "    df = df.copy()\n",
        "    df['weighted_status_score'] = 0\n",
        "    for month in range(0, 25):\n",
        "        df['weighted_status_score'] += df[f'enc_paym_{month}'] * w[month]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f59544f6",
      "metadata": {
        "id": "f59544f6"
      },
      "outputs": [],
      "source": [
        "df = weighted_status_score(df, np.flip((np.arange(25) * 1/25)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "24b8344f",
      "metadata": {
        "id": "24b8344f"
      },
      "outputs": [],
      "source": [
        "X_test = weighted_status_score(X_test, np.flip((np.arange(25) * 1/25)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beccbcff",
      "metadata": {
        "id": "beccbcff"
      },
      "source": [
        "#### Максимальная длина подряд идущих «плохих» статусов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3e684a",
      "metadata": {
        "id": "0b3e684a"
      },
      "source": [
        "Смысл:\n",
        "- Если клиент допустил разовую просрочку, это не так страшно.\n",
        "- Если у него 3–4 месяца подряд delinquent или defaulted, это почти всегда дефолтный сценарий.\n",
        "Такой признак даёт сильный сигнал модели, потому что «устойчивость» плохого поведения предсказывает вероятность дефолта лучше, чем единичные выбросы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1cc2dca7",
      "metadata": {
        "id": "1cc2dca7"
      },
      "outputs": [],
      "source": [
        "def longest_run_bad_status(df, bad_statuses={2, 3}):\n",
        "    df = df.copy()\n",
        "    df['longest_run_bad_status'] = 0\n",
        "    df['maxi'] = 0\n",
        "    for month in tqdm(range(0, 25)):\n",
        "        mask = df['maxi'] > df['longest_run_bad_status']\n",
        "        df.loc[mask, 'longest_run_bad_status'] = df.loc[mask, 'maxi']\n",
        "\n",
        "        # Обновляем maxi для всех строк\n",
        "        df['maxi'] = df.apply(\n",
        "            lambda row: row['maxi'] + 1 if row[f'enc_paym_{month}'] in bad_statuses else 0,\n",
        "            axis=1\n",
        "        )\n",
        "    mask = df['maxi'] > df['longest_run_bad_status']\n",
        "    df.loc[mask, 'longest_run_bad_status'] = df.loc[mask, 'maxi']\n",
        "    return df['longest_run_bad_status']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c2327db7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2327db7",
        "outputId": "4ff8465a-90f1-4f05-b71c-d9f85b0b647d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [05:48<00:00, 13.93s/it]\n"
          ]
        }
      ],
      "source": [
        "df['longest_run_bad_status'] = longest_run_bad_status(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b7faed6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7faed6a",
        "outputId": "ae7edb8f-41cf-47f0-8f22-bfe4ea95bab5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [01:17<00:00,  3.11s/it]\n"
          ]
        }
      ],
      "source": [
        "X_test['longest_run_bad_status'] = longest_run_bad_status(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d664a528",
      "metadata": {
        "id": "d664a528"
      },
      "source": [
        "#### Количество переходов «ухудшения положения»"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96bce821",
      "metadata": {
        "id": "96bce821"
      },
      "source": [
        "Cчитается сколько раз статус ухудшился в истории:\n",
        "- 0 → 1\n",
        "- 1 → 2\n",
        "- 2 → 3\n",
        "\n",
        "Это отражает «тренд»: клиент движется к дефолту или колеблется.\n",
        "Если много ухудшений подряд → клиент явно уходит в риск-зону."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e985d8d8",
      "metadata": {
        "id": "e985d8d8"
      },
      "outputs": [],
      "source": [
        "def count_deterioration_transitions(df):\n",
        "    df = df.copy()\n",
        "    df['deterioration_count'] = 0\n",
        "    for month in range(1, 25):\n",
        "        current_col = f'enc_paym_{month}'\n",
        "        prev_col = f'enc_paym_{month-1}'\n",
        "\n",
        "        # Определяем условия ухудшения\n",
        "        condition_0_to_1 = (df[prev_col] == 0) & (df[current_col] == 1)\n",
        "        condition_1_to_2 = (df[prev_col] == 1) & (df[current_col] == 2)\n",
        "        condition_2_to_3 = (df[prev_col] == 2) & (df[current_col] == 3)\n",
        "        # Суммируем все случаи ухудшения\n",
        "        deterioration_mask = condition_0_to_1 | condition_1_to_2 | condition_2_to_3\n",
        "        df.loc[deterioration_mask, 'deterioration_count'] += 1\n",
        "    return df['deterioration_count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b38f9a3a",
      "metadata": {
        "id": "b38f9a3a"
      },
      "outputs": [],
      "source": [
        "df['deterioration_count'] = count_deterioration_transitions(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3910b6d7",
      "metadata": {
        "id": "3910b6d7"
      },
      "outputs": [],
      "source": [
        "X_test['deterioration_count'] = count_deterioration_transitions(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d113490",
      "metadata": {
        "id": "6d113490"
      },
      "source": [
        "### credit_number_for_user"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7791ac9c",
      "metadata": {
        "id": "7791ac9c"
      },
      "source": [
        "`credit_number_for_user` - Порядковый номер кредитного продукта в кредитной истории. Большему номеру соответствует продукт с более поздней датой открытия.\n",
        "\n",
        "Этот признак и так хорош, он отражает насколько можно доверять клиенту, ведь, если он брал кредиты ранее и возвращал, то у него хорошая кредитная история и выше шанс отдать деньги."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a361e1a",
      "metadata": {
        "id": "4a361e1a"
      },
      "source": [
        "### days_since_confirmed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70730e64",
      "metadata": {
        "id": "70730e64"
      },
      "source": [
        "`days_since_confirmed` - Дней с даты подтверждения информации по кредиту до даты сбора данных*\n",
        "\n",
        "Этот признак я вообше не понимаю, как он связан с дефолтом?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c6e97ca",
      "metadata": {
        "id": "5c6e97ca"
      },
      "source": [
        "### maturity_fact"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27b2eab1",
      "metadata": {
        "id": "27b2eab1"
      },
      "source": [
        "`maturity_fact` - Фактическое количество дней с даты открытия кредита до даты закрытия*\n",
        "Само по себе знание сколько дней длился кредит важно - чем больше срок кредита, тем выше вероятность дефолта (невыплаты). И наоборот досрочное погашение это круто"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99be9260",
      "metadata": {
        "id": "99be9260"
      },
      "source": [
        "### maturity_plan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4185aa81",
      "metadata": {
        "id": "4185aa81"
      },
      "source": [
        "`maturity_plan` - Плановое количество дней с даты открытия кредита до даты закрытия*\n",
        "\n",
        "Само по себе знание сколько дней должен был длился кредит не важно, но понимание того, насколько был превышен ожидаемый срок:\n",
        "\n",
        "Если maturity_ratio больше 1, то срок превышен, если меньше 1, то было досрочное погашение!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "093aed82",
      "metadata": {
        "id": "093aed82"
      },
      "outputs": [],
      "source": [
        "def maturity_ratio(maturity_plan, maturity_fact):\n",
        "    return maturity_plan / (maturity_fact + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1287c1d1",
      "metadata": {
        "id": "1287c1d1"
      },
      "outputs": [],
      "source": [
        "df['maturity_ratio'] = maturity_ratio(df['maturity_plan'], df['maturity_fact'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7e193ad6",
      "metadata": {
        "id": "7e193ad6"
      },
      "outputs": [],
      "source": [
        "X_test['maturity_ratio'] = maturity_ratio(X_test['maturity_plan'], X_test['maturity_fact'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ebfe9c",
      "metadata": {
        "id": "14ebfe9c"
      },
      "source": [
        "### credit_limit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40410c87",
      "metadata": {
        "id": "40410c87"
      },
      "source": [
        "`credit_limit` - Кредитный лимит. Уже очень крутой признак. Показывает уровень доверия к клиенту."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867fd092",
      "metadata": {
        "id": "867fd092"
      },
      "source": [
        "### next_payment_sum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbed0692",
      "metadata": {
        "id": "bbed0692"
      },
      "source": [
        "`next_payment_sum` - Сумма следующего платежа по кредиту*. Уже хороший признак. Но его надо превратить в безразмерный:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d7a9658c",
      "metadata": {
        "id": "d7a9658c"
      },
      "outputs": [],
      "source": [
        "def next_payment_sum_ratio(next_payment_sum, full_credit_cost):\n",
        "    return next_payment_sum / (full_credit_cost + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "59b37c5f",
      "metadata": {
        "id": "59b37c5f"
      },
      "outputs": [],
      "source": [
        "df['next_payment_sum_ratio'] = next_payment_sum_ratio(df['next_payment_sum'], df['full_credit_cost'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "182e54e6",
      "metadata": {
        "id": "182e54e6"
      },
      "outputs": [],
      "source": [
        "X_test['next_payment_sum_ratio'] = next_payment_sum_ratio(X_test['next_payment_sum'], X_test['full_credit_cost'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "021eb852",
      "metadata": {
        "id": "021eb852"
      },
      "source": [
        "### sum_left_to_pay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26b4ea2f",
      "metadata": {
        "id": "26b4ea2f"
      },
      "source": [
        "`sum_left_to_pay` - Оставшаяся невыплаченная сумма кредита*. Уже хороший признак. Но его надо превратить в безразмерный:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7cb6f019",
      "metadata": {
        "id": "7cb6f019"
      },
      "outputs": [],
      "source": [
        "def sum_left_to_pay_progress(sum_left_to_pay, full_credit_cost):\n",
        "    return 1 - (sum_left_to_pay / (full_credit_cost + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5e9969b4",
      "metadata": {
        "id": "5e9969b4"
      },
      "outputs": [],
      "source": [
        "df['sum_left_to_pay_progress'] = sum_left_to_pay_progress(df['sum_left_to_pay'], df['full_credit_cost'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a6761b17",
      "metadata": {
        "id": "a6761b17"
      },
      "outputs": [],
      "source": [
        "X_test['sum_left_to_pay_progress'] = sum_left_to_pay_progress(X_test['sum_left_to_pay'], X_test['full_credit_cost'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7642acc",
      "metadata": {
        "id": "a7642acc"
      },
      "source": [
        "### current_overdue_debt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88a996d",
      "metadata": {
        "id": "d88a996d"
      },
      "source": [
        "`current_overdue_debt` - Текущая просроченная задолженность*. Абсолютно пустой признак - не нужен"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67256e55",
      "metadata": {
        "id": "67256e55"
      },
      "source": [
        "### max_overdue_debt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "650c7705",
      "metadata": {
        "id": "650c7705"
      },
      "source": [
        "`max_overdue_debt` - Максимальная просроченная задолженность*. Можно сделать относительной величиной"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "38516a42",
      "metadata": {
        "id": "38516a42"
      },
      "outputs": [],
      "source": [
        "def max_overdue_debt_ratio(max_overdue_debt, full_credit_cost):\n",
        "    return max_overdue_debt / (full_credit_cost + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3164fd1d",
      "metadata": {
        "id": "3164fd1d"
      },
      "outputs": [],
      "source": [
        "df['max_overdue_debt_ratio'] = max_overdue_debt_ratio(df['max_overdue_debt'], df['full_credit_cost'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b343a963",
      "metadata": {
        "id": "b343a963"
      },
      "outputs": [],
      "source": [
        "X_test['max_overdue_debt_ratio'] = max_overdue_debt_ratio(X_test['max_overdue_debt'], X_test['full_credit_cost'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9dbb701",
      "metadata": {
        "id": "e9dbb701"
      },
      "source": [
        "### full_credit_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16a9cf52",
      "metadata": {
        "id": "16a9cf52"
      },
      "source": [
        "`full_credit_cost` - Полная стоимость кредита*. Можно сделать относительной от общего кредитного лимита"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a79dfad1",
      "metadata": {
        "id": "a79dfad1"
      },
      "outputs": [],
      "source": [
        "def full_credit_cost_ef_rate(full_credit_cost, credit_limit):\n",
        "    return (full_credit_cost / (credit_limit + 1) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "00b984bc",
      "metadata": {
        "id": "00b984bc"
      },
      "outputs": [],
      "source": [
        "df['full_credit_cost_ef_rate'] = full_credit_cost_ef_rate(df['full_credit_cost'], df['credit_limit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "7e823d3f",
      "metadata": {
        "id": "7e823d3f"
      },
      "outputs": [],
      "source": [
        "X_test['full_credit_cost_ef_rate'] = full_credit_cost_ef_rate(X_test['full_credit_cost'], X_test['credit_limit'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19119141",
      "metadata": {
        "id": "19119141"
      },
      "source": [
        "### overdues_Xd_Yd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04996990",
      "metadata": {
        "id": "04996990"
      },
      "source": [
        "`overdues_Xd_Yd` - Число просрочек сроком между X дней и Y дней (либо менее 5 дней/более 90 дней)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "93dc8dc6",
      "metadata": {
        "id": "93dc8dc6"
      },
      "outputs": [],
      "source": [
        "def total_overdues(df):\n",
        "    df = df.copy()\n",
        "    df[\"total_overdues\"] = (\n",
        "        df[\"overdues_5d\"] + df[\"overdues_5d_30d\"] + df[\"overdues_30d_60d\"] +\n",
        "        df[\"overdues_60d_90d\"] + df[\"overdues_90d\"]\n",
        "    )\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "fa258568",
      "metadata": {
        "id": "fa258568"
      },
      "outputs": [],
      "source": [
        "def has_overdue(df):\n",
        "    df = df.copy()\n",
        "    df[\"has_long_overdue\"] = (df[\"overdues_60d_90d\"] > 0) | (df[\"overdues_90d\"] > 0)\n",
        "    df[\"has_mid_overdue\"] = (df[\"overdues_30d_60d\"] > 0).astype(int)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "fc41a867",
      "metadata": {
        "id": "fc41a867"
      },
      "outputs": [],
      "source": [
        "def overdue_severity_score(df):\n",
        "    df = df.copy()\n",
        "    df[\"overdue_severity_score\"] = (\n",
        "        1*df[\"overdues_5d\"] +\n",
        "        2*df[\"overdues_5d_30d\"] +\n",
        "        4*df[\"overdues_30d_60d\"] +\n",
        "        6*df[\"overdues_60d_90d\"] +\n",
        "        10*df[\"overdues_90d\"]\n",
        "    )\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e0152177",
      "metadata": {
        "id": "e0152177"
      },
      "outputs": [],
      "source": [
        "def overdue_ratio(df):\n",
        "    df = df.copy()\n",
        "    df[\"overdue_ratio\"] = df[\"total_overdues\"] / (df[\"credit_number_for_user\"] + 1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4dc2b15c",
      "metadata": {
        "id": "4dc2b15c"
      },
      "outputs": [],
      "source": [
        "df = total_overdues(df)\n",
        "df = has_overdue(df)\n",
        "df = overdue_severity_score(df)\n",
        "df = overdue_ratio(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "b5ec139e",
      "metadata": {
        "id": "b5ec139e"
      },
      "outputs": [],
      "source": [
        "X_test = total_overdues(X_test)\n",
        "X_test = has_overdue(X_test)\n",
        "X_test = overdue_severity_score(X_test)\n",
        "X_test = overdue_ratio(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14fcc25b",
      "metadata": {
        "id": "14fcc25b"
      },
      "source": [
        "### no_overdues_Xd_Yd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a622aa",
      "metadata": {
        "id": "f4a622aa"
      },
      "source": [
        "`no_overdues_Xd_Yd` - нет просрочек сроком между X дней и Y дней (либо менее 5 дней/более 90 дней)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "44ca704d",
      "metadata": {
        "id": "44ca704d"
      },
      "outputs": [],
      "source": [
        "def has_clean_history(df):\n",
        "    df = df.copy()\n",
        "    df[\"has_clean_history\"] = (\n",
        "    (df[\"no_overdues_5d\"]==1) &\n",
        "    (df[\"no_overdues_5d_30d\"]==1) &\n",
        "    (df[\"no_overdues_30d_60d\"]==1) &\n",
        "    (df[\"no_overdues_60d_90d\"]==1) &\n",
        "    (df[\"no_overdues_90d\"]==1)\n",
        "    ).astype(int)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6e664d10",
      "metadata": {
        "id": "6e664d10"
      },
      "outputs": [],
      "source": [
        "def max_overdue_level(df):\n",
        "    df = df.copy()\n",
        "    df[\"max_overdue_level\"] = (\n",
        "        df[[\"overdues_5d\",\"overdues_5d_30d\",\"overdues_30d_60d\",\n",
        "            \"overdues_60d_90d\",\"overdues_90d\"]] > 0\n",
        "    ).idxmax(axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "11ce3947",
      "metadata": {
        "id": "11ce3947"
      },
      "outputs": [],
      "source": [
        "df = has_clean_history(df)\n",
        "df = max_overdue_level(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b2b5af47",
      "metadata": {
        "id": "b2b5af47"
      },
      "outputs": [],
      "source": [
        "X_test = has_clean_history(X_test)\n",
        "X_test = max_overdue_level(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc329960",
      "metadata": {
        "id": "fc329960"
      },
      "source": [
        "### credit_type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7422b9f4",
      "metadata": {
        "id": "7422b9f4"
      },
      "source": [
        "`credit_type` - Тип кредита***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8ee51a",
      "metadata": {
        "id": "dc8ee51a"
      },
      "source": [
        "### credit_currency"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f37a786a",
      "metadata": {
        "id": "f37a786a"
      },
      "source": [
        "`credit_currency` - Валюта кредита**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04834e7f",
      "metadata": {
        "id": "04834e7f"
      },
      "source": [
        "### другие фичи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de6a1ce6",
      "metadata": {
        "id": "de6a1ce6"
      },
      "outputs": [],
      "source": [
        "def _fit_rate_map(s_values: np.ndarray, y_values: np.ndarray, prior: float, smoothing: float = 20.0):\n",
        "    \"\"\"\n",
        "    Строит сглаженную карту риска: value -> P(default|value).\n",
        "    - s_values: массив значений признака на train-части fold'а\n",
        "    - y_values: соответствующий массив 0/1\n",
        "    - prior: глобальная доля дефолтов (сглаживающий приор)\n",
        "    - smoothing: сила сглаживания (чем больше, тем ближе к prior при редких значениях)\n",
        "    Возвращает словарь {значение: риск}\n",
        "    \"\"\"\n",
        "    tmp = pd.DataFrame({'val': s_values, 'y': y_values})\n",
        "    grp = tmp.groupby('val')['y']\n",
        "    mean = grp.mean()\n",
        "    cnt  = grp.size()\n",
        "    # сглаженный риск: (mean*count + prior*smoothing) / (count + smoothing)\n",
        "    risk = (mean*cnt + prior*smoothing) / (cnt + smoothing)\n",
        "    return risk.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "0dc26d20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dc26d20",
        "outputId": "064bb0de-8683-4415-f65f-b067591899a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1827404 456852 25\n"
          ]
        }
      ],
      "source": [
        "target = df['target'].astype(int).values\n",
        "\n",
        "enc_cols = [c for c in df.columns if c.startswith('enc_paym_')]\n",
        "enc_cols = sorted(enc_cols, key=lambda s: int(s.split('_')[-1]))  # гарантированно 0..24 по возрастанию\n",
        "\n",
        "overdue_cols = [\n",
        "    'overdues_5d','overdues_5d_30d','overdues_30d_60d','overdues_60d_90d','overdues_90d',\n",
        "    'no_overdues_5d','no_overdues_5d_30d','no_overdues_30d_60d','no_overdues_60d_90d','no_overdues_90d'\n",
        "]\n",
        "\n",
        "starred_cols = [  # поля со звёздочкой из условия (разбиты по интервалам → «категории» в числах)\n",
        "    'days_since_confirmed','maturity_plan','maturity_fact','credit_limit',\n",
        "    'next_payment_sum','sum_left_to_pay','current_overdue_debt','max_overdue_debt','full_credit_cost'\n",
        "]\n",
        "cat_cols = ['credit_type','credit_currency']  # настоящие категории (перекодированные числами)\n",
        "base_num = ['credit_number_for_user']         # числовая, но мы тоже ей присвоим риск-ранг\n",
        "\n",
        "print(len(df), len(X_test), len(enc_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4d457d0e",
      "metadata": {
        "id": "4d457d0e"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(df, target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "0cb8e821",
      "metadata": {
        "id": "0cb8e821"
      },
      "outputs": [],
      "source": [
        "def oof_target_rate_map(train_series: pd.Series, y: np.ndarray, folds, smoothing: float = 20.0):\n",
        "    \"\"\"\n",
        "    Возвращает:\n",
        "      - oof_risk: массив OOF-рисков для train_series (на валидации каждого фолда считаем по карте, обученной на его train-части)\n",
        "      - full_map: карта риска по всей обучающей части для применения на тесте\n",
        "    \"\"\"\n",
        "    prior = y.mean().item()\n",
        "    oof_risk = np.zeros(len(train_series), dtype=np.float32)\n",
        "\n",
        "    # Проход по фолдам: для каждого валидного куска используем карту, обученную на тренировочном\n",
        "    for tr_idx, vl_idx in folds:\n",
        "        s_tr = train_series.iloc[tr_idx].values\n",
        "        y_tr = y[tr_idx]\n",
        "        s_vl = train_series.iloc[vl_idx].values\n",
        "\n",
        "        risk_map = _fit_rate_map(s_tr, y_tr, prior, smoothing)\n",
        "        # OOF для валидации\n",
        "        oof_risk[vl_idx] = np.array([risk_map.get(v, prior) for v in s_vl], dtype=np.float32)\n",
        "\n",
        "    # Полная карта риска для теста\n",
        "    risk_map_full = _fit_rate_map(train_series.values, y, prior, smoothing)\n",
        "    return oof_risk, risk_map_full\n",
        "\n",
        "def apply_rate_map(series: pd.Series, rate_map: dict, default_rate: float):\n",
        "    \"\"\"Применяем карту риска к Series (неизвестные значения -> default_rate).\"\"\"\n",
        "    return series.map(rate_map).fillna(default_rate).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "98e10086",
      "metadata": {
        "id": "98e10086"
      },
      "outputs": [],
      "source": [
        "# ЯЧЕЙКА 3a — строим risk-последовательности (N x 25) для train и test\n",
        "def build_risk_sequence(df_tr: pd.DataFrame, df_te: pd.DataFrame, enc_cols, y: np.ndarray, folds):\n",
        "    \"\"\"\n",
        "    На каждый enc_paym_k строим OOF риск (train) и full-map (test).\n",
        "    Склеиваем по столбцам -> матрица [N, 25] риска, согласованная с порядком enc_cols.\n",
        "    \"\"\"\n",
        "    prior = y.mean().item()\n",
        "    mats_tr = []\n",
        "    mats_te = []\n",
        "\n",
        "    for c in tqdm(enc_cols):\n",
        "        oof, full_map = oof_target_rate_map(df_tr[c], y, folds, smoothing=20.0)\n",
        "        mats_tr.append(oof.reshape(-1, 1))\n",
        "        mats_te.append(apply_rate_map(df_te[c], full_map, prior).values.reshape(-1, 1))\n",
        "\n",
        "    risk_tr = np.concatenate(mats_tr, axis=1).astype(np.float32)  # [N_train, 25]\n",
        "    risk_te = np.concatenate(mats_te, axis=1).astype(np.float32)  # [N_test,  25]\n",
        "    return risk_tr, risk_te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "2f203d47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f203d47",
        "outputId": "7e7942b1-c1af-4bc0-b5d8-25f9d5b22c30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:22<00:00,  1.12it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((1827404, 25), (456852, 25))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "risk_seq_tr, risk_seq_te = build_risk_sequence(df, X_test, enc_cols, target, folds)\n",
        "risk_seq_tr.shape, risk_seq_te.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "36ce7eea",
      "metadata": {
        "id": "36ce7eea"
      },
      "outputs": [],
      "source": [
        "# ЯЧЕЙКА 3b — агрегаты по risk-последовательности (без тяжёлых циклов)\n",
        "def ema_last_axis(mat: np.ndarray, alpha: float = 0.85):\n",
        "    \"\"\"\n",
        "    Применяет EMA слева направо по оси признаков:\n",
        "    y_t = alpha*y_{t-1} + (1-alpha)*x_t\n",
        "    Возвращает 1 столбец: последний EMA (сильнее учитывает свежие месяцы).\n",
        "    \"\"\"\n",
        "    out = np.zeros(mat.shape[0], dtype=np.float32)\n",
        "    for j in range(mat.shape[1]):\n",
        "        if j == 0:\n",
        "            out = mat[:, j]\n",
        "        else:\n",
        "            out = alpha * out + (1.0 - alpha) * mat[:, j]\n",
        "    return out.astype(np.float32)\n",
        "\n",
        "def build_payment_risk_aggs(risk_tr: np.ndarray, risk_te: np.ndarray):\n",
        "    \"\"\"\n",
        "    Быстрые агрегаты из risk-последовательности (векторно):\n",
        "    - среднее за все 25\n",
        "    - среднее за последние 12, 6\n",
        "    - EMA (последнее значение)\n",
        "    - bad_count_12, bad_count_6 (где bad >= глобальной медианы по train-последовательности)\n",
        "    \"\"\"\n",
        "    # глобальный порог \"плохости\" по train\n",
        "    thr = np.median(risk_tr)\n",
        "\n",
        "    def agg_side(mat: np.ndarray):\n",
        "        feats = {}\n",
        "        feats['risk_mean_25']      = mat.mean(axis=1).astype(np.float32)\n",
        "        feats['risk_mean_last_12'] = mat[:, -12:].mean(axis=1).astype(np.float32)\n",
        "        feats['risk_mean_last_6']  = mat[:, -6:].mean(axis=1).astype(np.float32)\n",
        "        feats['risk_ema']          = ema_last_axis(mat, alpha=0.85)  # последний EMA\n",
        "\n",
        "        bad = (mat >= thr)  # bool\n",
        "        feats['bad_count_12'] = bad[:, -12:].sum(axis=1).astype(np.int16)\n",
        "        feats['bad_count_6']  = bad[:, -6:].sum(axis=1).astype(np.int16)\n",
        "        return pd.DataFrame(feats)\n",
        "\n",
        "    tr_aggs = agg_side(risk_tr)\n",
        "    te_aggs = agg_side(risk_te)\n",
        "    return tr_aggs, te_aggs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "82d9ccf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82d9ccf9",
        "outputId": "08f1aaac-b9e4-431e-fa24-1e4d4196485f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1827404, 6), (456852, 6))"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_pay_aggs, te_pay_aggs = build_payment_risk_aggs(risk_seq_tr, risk_seq_te)\n",
        "tr_pay_aggs.shape, te_pay_aggs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "1d0f45e9",
      "metadata": {
        "id": "1d0f45e9"
      },
      "outputs": [],
      "source": [
        "# ЯЧЕЙКА 5 — риск-фичи для starred и base_num\n",
        "def build_risk_features_block(df_tr: pd.DataFrame, df_te: pd.DataFrame, cols, y: np.ndarray, folds):\n",
        "    prior = y.mean().item()\n",
        "    out_tr = {}\n",
        "    out_te = {}\n",
        "\n",
        "    for c in cols:\n",
        "        oof, mp = oof_target_rate_map(df_tr[c], y, folds, smoothing=30.0)\n",
        "        out_tr[f'{c}_risk'] = oof.astype(np.float32)\n",
        "        out_te[f'{c}_risk'] = apply_rate_map(df_te[c], mp, prior).values\n",
        "\n",
        "    return pd.DataFrame(out_tr), pd.DataFrame(out_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "7b011b14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b011b14",
        "outputId": "b98dd2a1-1ad7-4c90-8bb2-d7ca61581f1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1827404, 10), (456852, 10))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_star, te_star = build_risk_features_block(df, X_test, starred_cols + base_num, target, folds)\n",
        "tr_star.shape, te_star.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "ea681c6b",
      "metadata": {
        "id": "ea681c6b"
      },
      "outputs": [],
      "source": [
        "# ЯЧЕЙКА 5b — сглаженное target encoding для категорий (credit_type, credit_currency)\n",
        "def build_smoothed_te(df_tr: pd.DataFrame, df_te: pd.DataFrame, cols, y: np.ndarray, folds, min_count=50, prior=None):\n",
        "    if prior is None: prior = y.mean().item()\n",
        "    out_tr = {}\n",
        "    out_te = {}\n",
        "\n",
        "    for c in cols:\n",
        "        oof_vals = np.zeros(len(df_tr), dtype=np.float32)\n",
        "        for tr_idx, vl_idx in folds:\n",
        "            s_tr = df_tr[c].iloc[tr_idx].values\n",
        "            y_tr = y[tr_idx]\n",
        "            # считаем частоты и средние на train части\n",
        "            tmp = pd.DataFrame({'v': s_tr, 'y': y_tr})\n",
        "            grp = tmp.groupby('v')['y']\n",
        "            mean = grp.mean()\n",
        "            cnt  = grp.size()\n",
        "            # сглаживание к prior при малых cnt\n",
        "            smoothed = (mean*cnt + prior*min_count) / (cnt + min_count)\n",
        "            mp = smoothed.to_dict()\n",
        "            oof_vals[vl_idx] = np.array([mp.get(v, prior) for v in df_tr[c].iloc[vl_idx].values], dtype=np.float32)\n",
        "\n",
        "        # full map для теста\n",
        "        tmp_all = pd.DataFrame({'v': df_tr[c].values, 'y': y})\n",
        "        grp_all = tmp_all.groupby('v')['y']\n",
        "        mean_a = grp_all.mean()\n",
        "        cnt_a  = grp_all.size()\n",
        "        smoothed_a = (mean_a*cnt_a + prior*min_count) / (cnt_a + min_count)\n",
        "        mp_all = smoothed_a.to_dict()\n",
        "\n",
        "        out_tr[f'{c}_te'] = oof_vals\n",
        "        out_te[f'{c}_te'] = df_te[c].map(mp_all).fillna(prior).astype(np.float32).values\n",
        "\n",
        "    return pd.DataFrame(out_tr), pd.DataFrame(out_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "YuaaBqbY-HVk",
      "metadata": {
        "id": "YuaaBqbY-HVk"
      },
      "outputs": [],
      "source": [
        "def safe_div(a, b):\n",
        "    return np.where(b!=0, a/b, 0.0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "44a59e3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44a59e3b",
        "outputId": "1db8d87a-51b1-4a74-81cb-d0a011fc0b9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1827404, 2), (456852, 2))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_cat, te_cat = build_smoothed_te(df, X_test, cat_cols, target, folds, min_count=100)\n",
        "tr_cat.shape, te_cat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6K-Bk85C-AzA",
      "metadata": {
        "id": "6K-Bk85C-AzA"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "def ema_last_axis(mat, alpha=0.85):\n",
        "    \"\"\"Векторизованная версия EMA с прогресс-баром\"\"\"\n",
        "    out = np.zeros(mat.shape[0], dtype=np.float32)\n",
        "    for j in tqdm(range(mat.shape[1]), desc=\"EMA calculation\", leave=False):\n",
        "        out = alpha * out + (1.0 - alpha) * mat[:, j] if j > 0 else mat[:, 0]\n",
        "    return out.astype(np.float32)\n",
        "\n",
        "def poly_trend_slope_vectorized(mat):\n",
        "    \"\"\"Векторизованная версия расчета наклона тренда\"\"\"\n",
        "    with tqdm(total=6, desc=\"Trend slope calculation\", leave=False) as pbar:\n",
        "        n = mat.shape[1]\n",
        "        t = np.arange(n, dtype=np.float32)\n",
        "        t_mean = t.mean()\n",
        "        pbar.update(1)\n",
        "\n",
        "        # Векторизованные вычисления\n",
        "        x_mean = mat.mean(axis=1, keepdims=True)\n",
        "        pbar.update(1)\n",
        "\n",
        "        t_diff = t - t_mean\n",
        "        x_diff = mat - x_mean\n",
        "        pbar.update(1)\n",
        "\n",
        "        cov = (t_diff * x_diff).mean(axis=1)\n",
        "        pbar.update(1)\n",
        "\n",
        "        t_std = t_diff.std()\n",
        "        x_std = x_diff.std(axis=1)\n",
        "        pbar.update(1)\n",
        "\n",
        "        denom = t_std * x_std + 1e-9\n",
        "        result = (cov / denom).astype(np.float32)\n",
        "        pbar.update(1)\n",
        "\n",
        "    return result\n",
        "\n",
        "def hist_feats_vectorized(mat, bins=10, desc=\"Histogram features\"):\n",
        "    \"\"\"Векторизованная версия гистограммных фич с прогресс-баром\"\"\"\n",
        "    with tqdm(total=4, desc=desc, leave=False) as pbar:\n",
        "        h = np.apply_along_axis(lambda x: np.histogram(x, bins=bins, range=(0.0, 1.0))[0], 1, mat)\n",
        "        pbar.update(1)\n",
        "\n",
        "        h = h.astype(np.float32)\n",
        "        pbar.update(1)\n",
        "\n",
        "        h_sum = h.sum(axis=1, keepdims=True)\n",
        "        pbar.update(1)\n",
        "\n",
        "        dens = np.divide(h, h_sum, out=np.zeros_like(h), where=h_sum != 0)\n",
        "        result = np.concatenate([h, dens], axis=1).astype(np.float32)\n",
        "        pbar.update(1)\n",
        "\n",
        "    return result\n",
        "\n",
        "def safe_div(a, b):\n",
        "    return np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n",
        "\n",
        "def build_payment_aggs(risk_tr, risk_te):\n",
        "    \"\"\"Оптимизированная версия с векторизацией и полным отслеживанием\"\"\"\n",
        "\n",
        "    def side(mat, dataset_name):\n",
        "        F = {}\n",
        "\n",
        "        with tqdm(total=20, desc=f\"Processing {dataset_name} features\") as pbar:\n",
        "            # Предварительные вычисления для оптимизации\n",
        "            mat_mean = mat.mean(axis=1)\n",
        "            mat_std = mat.std(axis=1)\n",
        "            mat_min = mat.min(axis=1)\n",
        "            mat_max = mat.max(axis=1)\n",
        "            pbar.update(4)\n",
        "\n",
        "            # Глобальные окна - векторизованные вычисления\n",
        "            F['mean_25'] = mat_mean.astype(np.float32)\n",
        "            F['std_25'] = mat_std.astype(np.float32)\n",
        "            F['min_25'] = mat_min.astype(np.float32)\n",
        "            F['max_25'] = mat_max.astype(np.float32)\n",
        "            pbar.update(4)\n",
        "\n",
        "            # Квантили вычисляем за один проход\n",
        "            with tqdm(total=1, desc=\"Quantiles calculation\", leave=False) as quant_pbar:\n",
        "                quantiles = np.quantile(mat, [0.10, 0.50, 0.90], axis=1)\n",
        "                F['q10_25'] = quantiles[0].astype(np.float32)\n",
        "                F['q50_25'] = quantiles[1].astype(np.float32)\n",
        "                F['q90_25'] = quantiles[2].astype(np.float32)\n",
        "                quant_pbar.update(1)\n",
        "            pbar.update(1)\n",
        "\n",
        "            # Асимметрия и эксцесс - векторизованные версии\n",
        "            with tqdm(total=2, desc=\"Skewness/Kurtosis\", leave=False) as skew_pbar:\n",
        "                F['skew_25'] = skew(mat, axis=1).astype(np.float32)\n",
        "                skew_pbar.update(1)\n",
        "                F['kurt_25'] = kurtosis(mat, axis=1).astype(np.float32)\n",
        "                skew_pbar.update(1)\n",
        "            pbar.update(1)\n",
        "\n",
        "            # EMA и slope\n",
        "            F['ema_25'] = ema_last_axis(mat, alpha=0.85)\n",
        "            pbar.update(1)\n",
        "\n",
        "            F['slope_25'] = poly_trend_slope_vectorized(mat)\n",
        "            pbar.update(1)\n",
        "\n",
        "            # Последние окна\n",
        "            window_sizes = [12, 6, 3]\n",
        "            for W in tqdm(window_sizes, desc=\"Window processing\", leave=False):\n",
        "                chunk = mat[:, -W:]\n",
        "\n",
        "                chunk_mean = chunk.mean(axis=1)\n",
        "                chunk_std = chunk.std(axis=1)\n",
        "                chunk_min = chunk.min(axis=1)\n",
        "                chunk_max = chunk.max(axis=1)\n",
        "\n",
        "                chunk_quantiles = np.quantile(chunk, [0.10, 0.50, 0.90], axis=1)\n",
        "\n",
        "                F[f'mean_{W}'] = chunk_mean.astype(np.float32)\n",
        "                F[f'std_{W}'] = chunk_std.astype(np.float32)\n",
        "                F[f'min_{W}'] = chunk_min.astype(np.float32)\n",
        "                F[f'max_{W}'] = chunk_max.astype(np.float32)\n",
        "                F[f'q10_{W}'] = chunk_quantiles[0].astype(np.float32)\n",
        "                F[f'q50_{W}'] = chunk_quantiles[1].astype(np.float32)\n",
        "                F[f'q90_{W}'] = chunk_quantiles[2].astype(np.float32)\n",
        "                F[f'ema_{W}'] = ema_last_axis(chunk, alpha=0.85)\n",
        "                F[f'slope_{W}'] = poly_trend_slope_vectorized(chunk)\n",
        "            pbar.update(3)\n",
        "\n",
        "            # Гистограммы\n",
        "            # H25 = hist_feats_vectorized(mat, bins=10, desc=\"H25 histograms\")\n",
        "            # pbar.update(1)\n",
        "\n",
        "            # H12 = hist_feats_vectorized(mat[:, -12:], bins=10, desc=\"H12 histograms\")\n",
        "            # pbar.update(1)\n",
        "\n",
        "            # Создаем DataFrame\n",
        "            with tqdm(total=3, desc=\"Creating DataFrames\", leave=False) as df_pbar:\n",
        "                F_df = pd.DataFrame(F).astype(np.float32)\n",
        "                df_pbar.update(1)\n",
        "\n",
        "                # H25_df = pd.DataFrame(H25, columns=[f'h25_{i}' for i in range(H25.shape[1])])\n",
        "                # df_pbar.update(1)\n",
        "\n",
        "                # H12_df = pd.DataFrame(H12, columns=[f'h12_{i}' for i in range(H12.shape[1])])\n",
        "                # df_pbar.update(1)\n",
        "\n",
        "            result = pd.concat([F_df], axis=1)\n",
        "            pbar.update(1)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # Обработка train и test с прогресс-баром\n",
        "    with tqdm(total=2, desc=\"Overall processing\") as main_pbar:\n",
        "        tr = side(risk_tr, \"train\")\n",
        "        main_pbar.update(1)\n",
        "        main_pbar.set_description(\"Train processing completed\")\n",
        "\n",
        "        te = side(risk_te, \"test\")\n",
        "        main_pbar.update(1)\n",
        "        main_pbar.set_description(\"Test processing completed\")\n",
        "\n",
        "    return tr, te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "bihakb0h-UJ4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bihakb0h-UJ4",
        "outputId": "68baaa00-840b-4ce8-a794-9524574e942c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overall processing:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "Processing train features:  90%|█████████ | 18/20 [06:34<00:43, 21.94s/it]\n",
            "Train processing completed:  50%|█████     | 1/2 [06:34<06:34, 394.97s/it]\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "Processing test features:  90%|█████████ | 18/20 [01:29<00:09,  4.96s/it]\n",
            "Test processing completed: 100%|██████████| 2/2 [08:04<00:00, 242.15s/it] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((1827404, 78), (456852, 78))"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_pay_aggs, te_pay_aggs = build_payment_aggs(risk_seq_tr, risk_seq_te)\n",
        "tr_pay_aggs.shape, te_pay_aggs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BGiPEt3b9PZG",
      "metadata": {
        "id": "BGiPEt3b9PZG"
      },
      "source": [
        "Кросс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "gCDcPAp2-gzN",
      "metadata": {
        "id": "gCDcPAp2-gzN"
      },
      "outputs": [],
      "source": [
        "engineered_from_df = [\n",
        "    'maturity_ratio','weighted_status_score','longest_run_bad_status','deterioration_count',\n",
        "    'next_payment_sum_ratio','sum_left_to_pay_progress','max_overdue_debt_ratio','full_credit_cost_ef_rate',\n",
        "    'total_overdues','overdue_severity_score','overdue_ratio','has_clean_history','max_overdues_level',\n",
        "    'credit_type','credit_currency'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "HCdi0b6_9Rlx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCdi0b6_9Rlx",
        "outputId": "be37d6d7-20d0-48ef-ea2f-770008c420f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:01<00:00,  6.00it/s]\n",
            "100%|██████████| 12/12 [00:00<00:00, 22.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cross feats: 330\n"
          ]
        }
      ],
      "source": [
        "# Подхватим только реально существующие столбцы\n",
        "present_in_train = [c for c in engineered_from_df if c in df.columns]\n",
        "present_in_test  = [c for c in engineered_from_df if c in X_test.columns]\n",
        "assert set(present_in_train)==set(present_in_test)\n",
        "\n",
        "df_num = df[present_in_train].copy()\n",
        "te_num = X_test[present_in_test].copy()\n",
        "\n",
        "# Превратим bool/binary в float32, NaN/inf -> 0\n",
        "df_num = df_num.replace([np.inf, -np.inf], np.nan).fillna(0).astype(np.float32)\n",
        "te_num = te_num.replace([np.inf, -np.inf], np.nan).fillna(0).astype(np.float32)\n",
        "\n",
        "# Выберем базовый набор для кроссов (только числовые, исключим сырьё категорий)\n",
        "cross_base = [c for c in df_num.columns if c not in ['credit_type','credit_currency']]\n",
        "\n",
        "# Ограничим число колонок для кроссов (чтобы память не улетела)\n",
        "# Возьмём топ-15 по корреляции с OOF-риском одной из сильных фич (например, mean_25)\n",
        "tmp_corr = pd.DataFrame({'col': cross_base})\n",
        "tmp_corr['corr'] = [np.corrcoef(df_num[c].values, tr_pay_aggs['mean_25'].values)[0,1] if df_num[c].std()>0 else 0 for c in cross_base]\n",
        "tmp_corr['corr'] = tmp_corr['corr'].fillna(0).abs()\n",
        "top_cross = tmp_corr.sort_values('corr', ascending=False)['col'].head(15).tolist()\n",
        "\n",
        "def make_crosses(A: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Сгенерируем пары признаков (i<j) и вычислим:\n",
        "    - prod, diff, ratio, min, max\n",
        "    Это даёт ~ 5 * C(len(cols),2) фич.\n",
        "    \"\"\"\n",
        "    feats = {}\n",
        "    for i in tqdm(range(len(cols))):\n",
        "        for j in range(i+1, len(cols)):\n",
        "            a, b = cols[i], cols[j]\n",
        "            a_v, b_v = A[a].values, A[b].values\n",
        "            feats[f'{a}__x__{b}'] = (a_v * b_v).astype(np.float32)\n",
        "            feats[f'{a}__m__{b}'] = (a_v - b_v).astype(np.float32)\n",
        "            feats[f'{a}__d__{b}'] = safe_div(a_v, b_v)\n",
        "            feats[f'{a}__mn__{b}'] = np.minimum(a_v, b_v).astype(np.float32)\n",
        "            feats[f'{a}__mx__{b}'] = np.maximum(a_v, b_v).astype(np.float32)\n",
        "    return pd.DataFrame(feats)\n",
        "\n",
        "tr_cross = make_crosses(df_num, top_cross)\n",
        "te_cross = make_crosses(te_num, top_cross)\n",
        "\n",
        "# Контроль памяти\n",
        "print(\"cross feats:\", tr_cross.shape[1])\n",
        "\n",
        "# Финальные блоки фич — пока без объединения\n",
        "for blk in [tr_pay_aggs, tr_star, tr_cat, df_num, tr_cross]:\n",
        "    blk.index = df.index\n",
        "for blk in [te_pay_aggs, te_star, te_cat, te_num, te_cross]:\n",
        "    blk.index = X_test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "ab4fdf2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# tr_pay_aggs.to_csv(f'features/tr_pay_aggs.csv')\n",
        "# tr_star.to_csv(f'features/tr_star.csv') \n",
        "# tr_cat.to_csv(f'features/tr_cat.csv') \n",
        "# df.reset_index()[use_cols_num].to_csv(f'features/df_reset_index_use_cols_num.csv') \n",
        "# df.reset_index()[use_cols_cat_raw].to_csv(f'features/f_reset_index_use_cols_cat_raw.csv') \n",
        "# df_num.to_csv(f'features/df_num.csv') \n",
        "# tr_cross.to_csv(f'features/tr_cross.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52b0a93b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# te_pay_aggs.to_csv(f'features1/te_pay_aggs.csv')\n",
        "# te_star.to_csv(f'features1/te_star.csv') \n",
        "# te_cat.to_csv(f'features1/te_cat.csv') \n",
        "# X_test[use_cols_num].to_csv(f'features1/X_test_use_cols_num.csv') \n",
        "# X_test[use_cols_cat_raw].to_csv(f'features1/X_test_use_cols_cat_raw.csv') \n",
        "# te_num.to_csv(f'features1/te_num.csv') \n",
        "# te_cross.to_csv(f'features1/te_cross.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "396a1520",
      "metadata": {},
      "outputs": [],
      "source": [
        "tr_pay_aggs = pd.read_csv(f'features/tr_pay_aggs.csv')\n",
        "tr_star = pd.read_csv(f'features/tr_star.csv') \n",
        "tr_cat= pd.read_csv(f'features/tr_cat.csv') \n",
        "df_reser_use_cols_nums = pd.read_csv(f'features/df_reset_index_use_cols_num.csv') \n",
        "f_reset_index_use_cols_cat_raw = pd.read_csv(f'features/f_reset_index_use_cols_cat_raw.csv') \n",
        "df_num = pd.read_csv(f'features/df_num.csv') \n",
        "tr_cross = pd.read_csv(f'features/tr_cross.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "115d3755",
      "metadata": {},
      "outputs": [],
      "source": [
        "te_pay_aggs= pd.read_csv(f'features1/te_pay_aggs.csv')\n",
        "te_star= pd.read_csv(f'features1/te_star.csv') \n",
        "te_cat= pd.read_csv(f'features1/te_cat.csv') \n",
        "X_test_use_cols_num= pd.read_csv(f'features1/X_test_use_cols_num.csv') \n",
        "X_test_use_cols_cat_raw= pd.read_csv(f'features1/X_test_use_cols_cat_raw.csv') \n",
        "te_num= pd.read_csv(f'features1/te_num.csv') \n",
        "te_cross= pd.read_csv(f'features1/te_cross.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "22aef76d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Базовая сборка\n",
        "use_cols_num = [\n",
        "    'maturity_ratio',\n",
        "    'weighted_status_score',\n",
        "    'longest_run_bad_status',\n",
        "    'deterioration_count',\n",
        "    'next_payment_sum_ratio',\n",
        "    'sum_left_to_pay_progress',\n",
        "    'max_overdue_debt_ratio',\n",
        "    'full_credit_cost_ef_rate',\n",
        "    'total_overdues',\n",
        "    'overdue_severity_score',\n",
        "    'overdue_ratio',\n",
        "    'has_clean_history',        # как числовая псевдо-ординальная\n",
        "    # опционально:\n",
        "    # 'credit_number_for_user',\n",
        "]\n",
        "\n",
        "use_cols_cat_raw = ['credit_type', 'credit_currency']  # пометим как категории в CatBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d5d487",
      "metadata": {
        "id": "99d5d487"
      },
      "outputs": [],
      "source": [
        "X_tr = pd.concat(\n",
        "    [tr_pay_aggs, tr_star, tr_cat, df_reser_use_cols_nums, f_reset_index_use_cols_cat_raw, df_num, tr_cross],\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aacc0a62",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_te.to_csv('features1/X_te.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c7c3c4ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_te = pd.concat(\n",
        "    [te_pay_aggs, te_star, te_cat, X_test_use_cols_num, X_test_use_cols_cat_raw, te_num, te_cross],\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9e4c4292",
      "metadata": {},
      "outputs": [],
      "source": [
        "target = df['target'].astype(int).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "da9848fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['target'].to_csv('features/target.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eb92b730",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_tr.to_csv('features/X_tr_light.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8b896daa",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_features_clean = ['days_since_confirmed_risk',\n",
        " 'credit_limit_risk',\n",
        " 'full_credit_cost_risk',\n",
        " 'sum_left_to_pay_risk',\n",
        " 'maturity_fact_risk',\n",
        " 'credit_type_te',\n",
        " 'maturity_plan_risk',\n",
        " 'credit_type',\n",
        " 'max_25',\n",
        " 'std_25',\n",
        " 'max_overdue_debt_ratio__d__sum_left_to_pay_progress',\n",
        " 'next_payment_sum_risk',\n",
        " 'kurt_25',\n",
        " 'weighted_status_score__m__maturity_ratio',\n",
        " 'max_overdue_debt_ratio__mn__sum_left_to_pay_progress',\n",
        " 'total_overdues__mn__full_credit_cost_ef_rate',\n",
        " 'sum_left_to_pay_progress__mx__next_payment_sum_ratio',\n",
        " 'weighted_status_score__m__deterioration_count',\n",
        " 'maturity_ratio__x__next_payment_sum_ratio',\n",
        " 'overdue_severity_score__x__overdue_ratio',\n",
        " 'weighted_status_score__mx__longest_run_bad_status',\n",
        " 'overdue_ratio__d__full_credit_cost_ef_rate',\n",
        " 'weighted_status_score__m__sum_left_to_pay_progress',\n",
        " 'full_credit_cost_ef_rate__m__max_overdue_debt_ratio',\n",
        " 'min_12',\n",
        " 'maturity_ratio__d__full_credit_cost_ef_rate',\n",
        " 'deterioration_count__d__maturity_ratio',\n",
        " 'max_overdue_debt_ratio__x__sum_left_to_pay_progress',\n",
        " 'total_overdues__x__sum_left_to_pay_progress',\n",
        " 'overdue_ratio__x__has_clean_history',\n",
        " 'sum_left_to_pay_progress__m__next_payment_sum_ratio',\n",
        " 'credit_number_for_user_risk',\n",
        " 'total_overdues__mn__overdue_ratio',\n",
        " 'overdue_ratio__mn__full_credit_cost_ef_rate',\n",
        " 'deterioration_count__mn__max_overdue_debt_ratio',\n",
        " 'credit_currency_te',\n",
        " 'overdue_ratio__d__has_clean_history',\n",
        " 'overdue_severity_score__d__sum_left_to_pay_progress',\n",
        " 'max_12',\n",
        " 'deterioration_count__mx__overdue_ratio',\n",
        " 'overdue_ratio__mx__sum_left_to_pay_progress',\n",
        " 'longest_run_bad_status__mx__overdue_ratio',\n",
        " 'overdue_ratio__mn__max_overdue_debt_ratio',\n",
        " 'weighted_status_score__mn__total_overdues',\n",
        " 'deterioration_count__mn__maturity_ratio',\n",
        " 'has_clean_history__d__sum_left_to_pay_progress',\n",
        " 'full_credit_cost_ef_rate__m__sum_left_to_pay_progress',\n",
        " 'maturity_ratio__d__next_payment_sum_ratio',\n",
        " 'total_overdues__x__max_overdue_debt_ratio',\n",
        " 'has_clean_history__x__next_payment_sum_ratio',\n",
        " 'maturity_ratio__mx__max_overdue_debt_ratio',\n",
        " 'maturity_ratio__x__max_overdue_debt_ratio',\n",
        " 'deterioration_count__mn__sum_left_to_pay_progress',\n",
        " 'sum_left_to_pay_progress',\n",
        " 'total_overdues__d__next_payment_sum_ratio',\n",
        " 'q50_6',\n",
        " 'overdue_severity_score__mn__next_payment_sum_ratio',\n",
        " 'overdue_ratio__d__next_payment_sum_ratio',\n",
        " 'weighted_status_score__d__maturity_ratio',\n",
        " 'maturity_ratio__mx__sum_left_to_pay_progress',\n",
        " 'overdue_severity_score__x__sum_left_to_pay_progress',\n",
        " 'sum_left_to_pay_progress__x__next_payment_sum_ratio',\n",
        " 'overdue_ratio__mx__max_overdue_debt_ratio',\n",
        " 'max_6',\n",
        " 'maturity_ratio__mn__max_overdue_debt_ratio',\n",
        " 'overdue_severity_score__m__maturity_ratio',\n",
        " 'std_3',\n",
        " 'maturity_ratio__mn__next_payment_sum_ratio',\n",
        " 'total_overdues__m__maturity_ratio',\n",
        " 'maturity_ratio__m__max_overdue_debt_ratio',\n",
        " 'has_clean_history__mx__full_credit_cost_ef_rate',\n",
        " 'overdue_severity_score__mn__overdue_ratio',\n",
        " 'total_overdues__d__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__mx__deterioration_count',\n",
        " 'maturity_ratio',\n",
        " 'total_overdues__d__full_credit_cost_ef_rate',\n",
        " 'weighted_status_score__mn__max_overdue_debt_ratio',\n",
        " 'overdue_severity_score__d__max_overdue_debt_ratio',\n",
        " 'ema_3',\n",
        " 'total_overdues__mn__has_clean_history',\n",
        " 'weighted_status_score__x__overdue_severity_score',\n",
        " 'longest_run_bad_status__mx__sum_left_to_pay_progress',\n",
        " 'overdue_severity_score__d__overdue_ratio',\n",
        " 'maturity_ratio__d__sum_left_to_pay_progress',\n",
        " 'maturity_ratio__d__max_overdue_debt_ratio',\n",
        " 'q90_25',\n",
        " 'q50_3',\n",
        " 'slope_6',\n",
        " 'maturity_ratio__mx__next_payment_sum_ratio',\n",
        " 'q50_12',\n",
        " 'has_clean_history__mx__next_payment_sum_ratio',\n",
        " 'overdue_ratio__mn__sum_left_to_pay_progress',\n",
        " 'max_overdue_debt_ratio__mx__next_payment_sum_ratio',\n",
        " 'total_overdues__mn__next_payment_sum_ratio',\n",
        " 'maturity_ratio__x__sum_left_to_pay_progress',\n",
        " 'maturity_ratio__m__full_credit_cost_ef_rate',\n",
        " 'has_clean_history__x__full_credit_cost_ef_rate',\n",
        " 'has_clean_history__m__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__x__maturity_ratio',\n",
        " 'longest_run_bad_status__mx__maturity_ratio',\n",
        " 'overdue_ratio__x__maturity_ratio',\n",
        " 'weighted_status_score__mx__full_credit_cost_ef_rate',\n",
        " 'overdue_severity_score__d__next_payment_sum_ratio',\n",
        " 'max_overdue_debt_risk',\n",
        " 'deterioration_count__mx__full_credit_cost_ef_rate',\n",
        " 'total_overdues__x__maturity_ratio',\n",
        " 'overdue_ratio__m__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__mx__next_payment_sum_ratio',\n",
        " 'weighted_status_score__mx__overdue_ratio',\n",
        " 'has_clean_history__m__next_payment_sum_ratio',\n",
        " 'weighted_status_score__mn__overdue_ratio',\n",
        " 'overdue_ratio__d__maturity_ratio',\n",
        " 'weighted_status_score__mx__max_overdue_debt_ratio',\n",
        " 'full_credit_cost_ef_rate__d__sum_left_to_pay_progress',\n",
        " 'total_overdues__x__overdue_ratio',\n",
        " 'overdue_severity_score__x__max_overdue_debt_ratio',\n",
        " 'weighted_status_score__m__max_overdue_debt_ratio',\n",
        " 'full_credit_cost_ef_rate__d__next_payment_sum_ratio',\n",
        " 'total_overdues__d__maturity_ratio',\n",
        " 'total_overdues__m__overdue_ratio',\n",
        " 'weighted_status_score__x__overdue_ratio',\n",
        " 'longest_run_bad_status__mx__full_credit_cost_ef_rate',\n",
        " 'full_credit_cost_ef_rate__x__next_payment_sum_ratio',\n",
        " 'weighted_status_score__d__deterioration_count',\n",
        " 'overdue_ratio__mn__next_payment_sum_ratio',\n",
        " 'slope_25',\n",
        " 'overdue_ratio__mx__has_clean_history',\n",
        " 'overdue_severity_score__m__next_payment_sum_ratio',\n",
        " 'longest_run_bad_status__m__overdue_ratio',\n",
        " 'sum_left_to_pay_progress__mn__next_payment_sum_ratio',\n",
        " 'maturity_ratio__m__sum_left_to_pay_progress',\n",
        " 'overdue_ratio__mx__full_credit_cost_ef_rate',\n",
        " 'deterioration_count__x__full_credit_cost_ef_rate',\n",
        " 'total_overdues__mn__max_overdue_debt_ratio',\n",
        " 'longest_run_bad_status__mx__next_payment_sum_ratio',\n",
        " 'min_3',\n",
        " 'weighted_status_score__x__deterioration_count',\n",
        " 'total_overdues__x__full_credit_cost_ef_rate',\n",
        " 'total_overdues__m__full_credit_cost_ef_rate',\n",
        " 'deterioration_count__x__sum_left_to_pay_progress',\n",
        " 'min_25',\n",
        " 'maturity_ratio__mn__full_credit_cost_ef_rate',\n",
        " 'weighted_status_score__d__has_clean_history',\n",
        " 'weighted_status_score__x__longest_run_bad_status',\n",
        " 'ema_12',\n",
        " 'slope_12',\n",
        " 'q90_6',\n",
        " 'deterioration_count__x__overdue_severity_score',\n",
        " 'deterioration_count__mx__maturity_ratio',\n",
        " 'has_clean_history__m__full_credit_cost_ef_rate',\n",
        " 'max_overdue_debt_ratio__mx__sum_left_to_pay_progress',\n",
        " 'max_overdue_debt_ratio__d__next_payment_sum_ratio',\n",
        " 'overdue_severity_score__mn__max_overdue_debt_ratio',\n",
        " 'weighted_status_score__m__total_overdues',\n",
        " 'longest_run_bad_status__m__next_payment_sum_ratio',\n",
        " 'deterioration_count__x__max_overdue_debt_ratio',\n",
        " 'overdue_ratio__m__max_overdue_debt_ratio',\n",
        " 'weighted_status_score__mn__has_clean_history',\n",
        " 'full_credit_cost_ef_rate__mx__sum_left_to_pay_progress',\n",
        " 'max_3',\n",
        " 'overdue_ratio__m__has_clean_history',\n",
        " 'longest_run_bad_status__mx__max_overdue_debt_ratio',\n",
        " 'std_12',\n",
        " 'full_credit_cost_ef_rate__m__next_payment_sum_ratio',\n",
        " 'has_clean_history__x__sum_left_to_pay_progress',\n",
        " 'deterioration_count__m__has_clean_history',\n",
        " 'weighted_status_score__m__longest_run_bad_status',\n",
        " 'weighted_status_score__d__overdue_severity_score',\n",
        " 'full_credit_cost_ef_rate__x__sum_left_to_pay_progress',\n",
        " 'total_overdues__mn__sum_left_to_pay_progress',\n",
        " 'deterioration_count__x__overdue_ratio',\n",
        " 'q90_3',\n",
        " 'q10_12',\n",
        " 'overdue_ratio__x__next_payment_sum_ratio',\n",
        " 'has_clean_history__m__max_overdue_debt_ratio',\n",
        " 'overdue_ratio__d__max_overdue_debt_ratio',\n",
        " 'full_credit_cost_ef_rate__d__max_overdue_debt_ratio',\n",
        " 'total_overdues__x__next_payment_sum_ratio',\n",
        " 'longest_run_bad_status__mn__overdue_ratio',\n",
        " 'weighted_status_score__d__max_overdue_debt_ratio',\n",
        " 'overdue_severity_score__mn__maturity_ratio',\n",
        " 'longest_run_bad_status__m__maturity_ratio',\n",
        " 'overdue_severity_score__m__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__mn__overdue_severity_score',\n",
        " 'has_clean_history__mn__full_credit_cost_ef_rate',\n",
        " 'max_overdue_debt_ratio__m__next_payment_sum_ratio',\n",
        " 'deterioration_count__x__next_payment_sum_ratio',\n",
        " 'overdue_ratio',\n",
        " 'full_credit_cost_ef_rate__mn__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__mn__sum_left_to_pay_progress',\n",
        " 'maturity_ratio__m__next_payment_sum_ratio',\n",
        " 'overdue_severity_score__mn__full_credit_cost_ef_rate',\n",
        " 'full_credit_cost_ef_rate__mx__next_payment_sum_ratio',\n",
        " 'weighted_status_score__mn__maturity_ratio',\n",
        " 'weighted_status_score__x__total_overdues',\n",
        " 'overdue_ratio__mx__next_payment_sum_ratio',\n",
        " 'overdue_severity_score__m__overdue_ratio',\n",
        " 'has_clean_history__mn__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__m__overdue_ratio',\n",
        " 'maturity_ratio__mx__has_clean_history',\n",
        " 'full_credit_cost_ef_rate__mx__max_overdue_debt_ratio',\n",
        " 'weighted_status_score__d__next_payment_sum_ratio',\n",
        " 'deterioration_count__m__max_overdue_debt_ratio',\n",
        " 'std_6',\n",
        " 'weighted_status_score__d__overdue_ratio',\n",
        " 'weighted_status_score',\n",
        " 'deterioration_count__d__longest_run_bad_status',\n",
        " 'has_clean_history__mn__next_payment_sum_ratio',\n",
        " 'weighted_status_score__mn__full_credit_cost_ef_rate',\n",
        " 'overdue_severity_score__x__maturity_ratio',\n",
        " 'total_overdues__m__sum_left_to_pay_progress',\n",
        " 'deterioration_count__m__maturity_ratio',\n",
        " 'overdue_severity_score__x__next_payment_sum_ratio',\n",
        " 'longest_run_bad_status__mx__has_clean_history',\n",
        " 'has_clean_history__d__max_overdue_debt_ratio',\n",
        " 'longest_run_bad_status__m__sum_left_to_pay_progress',\n",
        " 'deterioration_count__m__longest_run_bad_status',\n",
        " 'maturity_ratio__mn__has_clean_history',\n",
        " 'q10_25',\n",
        " 'longest_run_bad_status__mn__overdue_severity_score',\n",
        " 'overdue_ratio__mn__maturity_ratio',\n",
        " 'weighted_status_score__x__has_clean_history',\n",
        " 'overdue_severity_score__mx__has_clean_history',\n",
        " 'total_overdues__d__overdue_ratio',\n",
        " 'q50_25',\n",
        " 'longest_run_bad_status__mn__full_credit_cost_ef_rate',\n",
        " 'overdue_ratio__x__max_overdue_debt_ratio',\n",
        " 'has_clean_history__d__next_payment_sum_ratio',\n",
        " 'has_clean_history__x__max_overdue_debt_ratio',\n",
        " 'mean_3',\n",
        " 'weighted_status_score__m__full_credit_cost_ef_rate',\n",
        " 'weighted_status_score__m__next_payment_sum_ratio',\n",
        " 'has_clean_history',\n",
        " 'deterioration_count__mx__has_clean_history',\n",
        " 'has_clean_history__mx__max_overdue_debt_ratio',\n",
        " 'deterioration_count__d__next_payment_sum_ratio',\n",
        " 'overdue_severity_score__d__full_credit_cost_ef_rate',\n",
        " 'maturity_ratio__m__has_clean_history',\n",
        " 'longest_run_bad_status__x__max_overdue_debt_ratio',\n",
        " 'overdue_ratio__mn__has_clean_history',\n",
        " 'total_overdues__m__has_clean_history',\n",
        " 'weighted_status_score__x__next_payment_sum_ratio',\n",
        " 'deterioration_count__d__full_credit_cost_ef_rate',\n",
        " 'slope_3',\n",
        " 'longest_run_bad_status__m__full_credit_cost_ef_rate',\n",
        " 'total_overdues__d__has_clean_history',\n",
        " 'deterioration_count__mx__next_payment_sum_ratio',\n",
        " 'deterioration_count__x__maturity_ratio',\n",
        " 'deterioration_count__d__sum_left_to_pay_progress',\n",
        " 'ema_25',\n",
        " 'max_overdue_debt_ratio__x__next_payment_sum_ratio',\n",
        " 'overdue_ratio__d__sum_left_to_pay_progress',\n",
        " 'overdue_ratio__m__maturity_ratio',\n",
        " 'min_6',\n",
        " 'overdue_severity_score__m__full_credit_cost_ef_rate',\n",
        " 'overdue_ratio__mx__maturity_ratio',\n",
        " 'full_credit_cost_ef_rate__x__max_overdue_debt_ratio',\n",
        " 'weighted_status_score__mx__has_clean_history',\n",
        " 'deterioration_count__m__next_payment_sum_ratio',\n",
        " 'has_clean_history__d__full_credit_cost_ef_rate',\n",
        " 'maturity_ratio__d__has_clean_history',\n",
        " 'deterioration_count__d__overdue_ratio',\n",
        " 'overdue_severity_score__mn__sum_left_to_pay_progress',\n",
        " 'overdue_ratio__x__full_credit_cost_ef_rate',\n",
        " 'skew_25',\n",
        " 'max_overdue_debt_ratio',\n",
        " 'weighted_status_score__d__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__m__overdue_severity_score',\n",
        " 'total_overdues__m__max_overdue_debt_ratio',\n",
        " 'total_overdues__mx__full_credit_cost_ef_rate',\n",
        " 'weighted_status_score__m__has_clean_history',\n",
        " 'has_clean_history__mx__sum_left_to_pay_progress',\n",
        " 'overdue_severity_score__mx__sum_left_to_pay_progress',\n",
        " 'mean_25',\n",
        " 'longest_run_bad_status__d__maturity_ratio',\n",
        " 'weighted_status_score__mn__longest_run_bad_status',\n",
        " 'overdue_severity_score__d__maturity_ratio',\n",
        " 'full_credit_cost_ef_rate',\n",
        " 'weighted_status_score__d__longest_run_bad_status',\n",
        " 'overdue_ratio__x__sum_left_to_pay_progress',\n",
        " 'max_overdue_debt_ratio__mn__next_payment_sum_ratio',\n",
        " 'weighted_status_score__d__total_overdues',\n",
        " 'mean_6',\n",
        " 'overdue_severity_score__x__full_credit_cost_ef_rate',\n",
        " 'longest_run_bad_status',\n",
        " 'sum_left_to_pay_progress__d__next_payment_sum_ratio',\n",
        " 'deterioration_count__d__overdue_severity_score',\n",
        " 'maturity_ratio__x__full_credit_cost_ef_rate',\n",
        " 'deterioration_count__d__total_overdues',\n",
        " 'ema_6',\n",
        " 'full_credit_cost_ef_rate__mn__next_payment_sum_ratio',\n",
        " 'weighted_status_score__x__full_credit_cost_ef_rate',\n",
        " 'overdue_severity_score__x__has_clean_history',\n",
        " 'deterioration_count__m__full_credit_cost_ef_rate',\n",
        " 'deterioration_count__mx__overdue_severity_score',\n",
        " 'longest_run_bad_status__d__overdue_ratio',\n",
        " 'has_clean_history__mn__max_overdue_debt_ratio',\n",
        " 'deterioration_count__m__overdue_ratio',\n",
        " 'maturity_ratio__mx__full_credit_cost_ef_rate',\n",
        " 'full_credit_cost_ef_rate__mn__max_overdue_debt_ratio',\n",
        " 'deterioration_count__x__longest_run_bad_status',\n",
        " 'total_overdues__mx__sum_left_to_pay_progress',\n",
        " 'weighted_status_score__mx__maturity_ratio',\n",
        " 'deterioration_count__mn__has_clean_history',\n",
        " 'total_overdues__mn__maturity_ratio',\n",
        " 'longest_run_bad_status__x__overdue_ratio',\n",
        " 'weighted_status_score__mx__sum_left_to_pay_progress',\n",
        " 'longest_run_bad_status__d__full_credit_cost_ef_rate',\n",
        " 'longest_run_bad_status__mn__next_payment_sum_ratio',\n",
        " 'maturity_ratio__x__has_clean_history',\n",
        " 'deterioration_count__mn__next_payment_sum_ratio',\n",
        " 'longest_run_bad_status__m__max_overdue_debt_ratio',\n",
        " 'longest_run_bad_status__mx__total_overdues',\n",
        " 'total_overdues',\n",
        " 'q10_3',\n",
        " 'weighted_status_score__mn__deterioration_count',\n",
        " 'longest_run_bad_status__m__overdue_severity_score',\n",
        " 'q90_12',\n",
        " 'credit_currency',\n",
        " 'max_overdue_debt_ratio__m__sum_left_to_pay_progress',\n",
        " 'longest_run_bad_status__m__has_clean_history',\n",
        " 'weighted_status_score__x__max_overdue_debt_ratio',\n",
        " 'total_overdues__mx__has_clean_history',\n",
        " 'mean_12',\n",
        " 'weighted_status_score__mn__next_payment_sum_ratio',\n",
        " 'longest_run_bad_status__d__overdue_severity_score',\n",
        " 'deterioration_count__m__overdue_severity_score',\n",
        " 'longest_run_bad_status__x__full_credit_cost_ef_rate',\n",
        " 'deterioration_count__d__max_overdue_debt_ratio',\n",
        " 'weighted_status_score__x__sum_left_to_pay_progress',\n",
        " 'longest_run_bad_status__x__maturity_ratio',\n",
        " 'longest_run_bad_status__mn__total_overdues',\n",
        " 'longest_run_bad_status__x__total_overdues',\n",
        " 'overdue_severity_score__mx__overdue_ratio',\n",
        " 'q10_6',\n",
        " 'deterioration_count__m__sum_left_to_pay_progress',\n",
        " 'total_overdues__x__overdue_severity_score',\n",
        " 'longest_run_bad_status__mn__maturity_ratio',\n",
        " 'overdue_ratio__m__next_payment_sum_ratio',\n",
        " 'total_overdues__d__max_overdue_debt_ratio',\n",
        " 'longest_run_bad_status__d__next_payment_sum_ratio',\n",
        " 'longest_run_bad_status__m__total_overdues',\n",
        " 'longest_run_bad_status__x__next_payment_sum_ratio',\n",
        " 'deterioration_count__mn__overdue_severity_score',\n",
        " 'longest_run_bad_status__d__max_overdue_debt_ratio',\n",
        " 'deterioration_count__x__has_clean_history',\n",
        " 'overdue_severity_score__m__max_overdue_debt_ratio',\n",
        " 'total_overdues__m__overdue_severity_score',\n",
        " 'total_overdues__mx__maturity_ratio',\n",
        " 'total_overdues__mn__overdue_severity_score',\n",
        " 'overdue_severity_score__mx__full_credit_cost_ef_rate',\n",
        " 'total_overdues__mx__next_payment_sum_ratio',\n",
        " 'longest_run_bad_status__x__overdue_severity_score',\n",
        " 'deterioration_count__mn__overdue_ratio',\n",
        " 'weighted_status_score__d__full_credit_cost_ef_rate',\n",
        " 'total_overdues__d__overdue_severity_score',\n",
        " 'overdue_ratio__m__full_credit_cost_ef_rate',\n",
        " 'longest_run_bad_status__mx__overdue_severity_score',\n",
        " 'longest_run_bad_status__x__sum_left_to_pay_progress',\n",
        " 'total_overdues__m__next_payment_sum_ratio',\n",
        " 'weighted_status_score__mx__total_overdues',\n",
        " 'overdue_severity_score',\n",
        " 'maturity_ratio__mn__sum_left_to_pay_progress',\n",
        " 'deterioration_count__mx__total_overdues',\n",
        " 'total_overdues__mx__overdue_severity_score',\n",
        " 'longest_run_bad_status__mn__sum_left_to_pay_progress',\n",
        " 'total_overdues__mx__max_overdue_debt_ratio',\n",
        " 'longest_run_bad_status__d__sum_left_to_pay_progress',\n",
        " 'deterioration_count',\n",
        " 'overdue_severity_score__mx__maturity_ratio',\n",
        " 'deterioration_count__d__has_clean_history',\n",
        " 'h12_16',\n",
        " 'h12_15',\n",
        " 'h12_14',\n",
        " 'h12_13',\n",
        " 'h25_6',\n",
        " 'h25_7',\n",
        " 'h25_8']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ff4a7cdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_tr = pd.read_csv('features/X_tr.csv')[top_features_clean].astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee936472",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_tr.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29e67672",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_te = pd.read_csv('features1/X_te.csv')[top_features_clean].astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8f84fd11",
      "metadata": {},
      "outputs": [],
      "source": [
        "target = pd.read_csv('features/target.csv')['target'].astype(int).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5b1bf3f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1827404 entries, 0 to 1827403\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Dtype\n",
            "---  ------  -----\n",
            " 0   id      int64\n",
            " 1   target  bool \n",
            "dtypes: bool(1), int64(1)\n",
            "memory usage: 15.7 MB\n"
          ]
        }
      ],
      "source": [
        "pd.read_csv('features/target.csv').info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "04bc0319",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(y_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b004c01e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{np.int64(0), np.int64(1)}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(y_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "24da7023",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1827404, 378), (456852, 378))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_tr = pd.read_csv('features/target.csv')['target'].astype(int).values.astype(int)\n",
        "X_tr.shape, X_te.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55a001e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Если где-то есть NaN/inf — сразу чистим:\n",
        "X_tr = X_tr.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_te = X_te.replace([np.inf, -np.inf], np.nan).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9f9aeb02",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del X_tr\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "854b29fa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>days_since_confirmed_risk</th>\n",
              "      <th>credit_limit_risk</th>\n",
              "      <th>full_credit_cost_risk</th>\n",
              "      <th>sum_left_to_pay_risk</th>\n",
              "      <th>maturity_fact_risk</th>\n",
              "      <th>credit_type_te</th>\n",
              "      <th>maturity_plan_risk</th>\n",
              "      <th>credit_type</th>\n",
              "      <th>max_25</th>\n",
              "      <th>std_25</th>\n",
              "      <th>...</th>\n",
              "      <th>deterioration_count</th>\n",
              "      <th>overdue_severity_score__mx__maturity_ratio</th>\n",
              "      <th>deterioration_count__d__has_clean_history</th>\n",
              "      <th>h12_16</th>\n",
              "      <th>h12_15</th>\n",
              "      <th>h12_14</th>\n",
              "      <th>h12_13</th>\n",
              "      <th>h25_6</th>\n",
              "      <th>h25_7</th>\n",
              "      <th>h25_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.036442</td>\n",
              "      <td>0.035327</td>\n",
              "      <td>0.034828</td>\n",
              "      <td>0.031592</td>\n",
              "      <td>0.031765</td>\n",
              "      <td>0.069495</td>\n",
              "      <td>0.030992</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.047831</td>\n",
              "      <td>0.005730</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.033437</td>\n",
              "      <td>0.031628</td>\n",
              "      <td>0.034834</td>\n",
              "      <td>0.031667</td>\n",
              "      <td>0.030732</td>\n",
              "      <td>0.031906</td>\n",
              "      <td>0.030417</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.037585</td>\n",
              "      <td>0.002770</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.033437</td>\n",
              "      <td>0.032114</td>\n",
              "      <td>0.035352</td>\n",
              "      <td>0.031667</td>\n",
              "      <td>0.038862</td>\n",
              "      <td>0.031906</td>\n",
              "      <td>0.035473</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.043827</td>\n",
              "      <td>0.003179</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.037797</td>\n",
              "      <td>0.032976</td>\n",
              "      <td>0.034167</td>\n",
              "      <td>0.031592</td>\n",
              "      <td>0.034909</td>\n",
              "      <td>0.031392</td>\n",
              "      <td>0.036833</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.046522</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.028799</td>\n",
              "      <td>0.040180</td>\n",
              "      <td>0.034167</td>\n",
              "      <td>0.031592</td>\n",
              "      <td>0.029911</td>\n",
              "      <td>0.031392</td>\n",
              "      <td>0.025565</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.048816</td>\n",
              "      <td>0.004078</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827399</th>\n",
              "      <td>0.028598</td>\n",
              "      <td>0.032039</td>\n",
              "      <td>0.029464</td>\n",
              "      <td>0.031667</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>0.031354</td>\n",
              "      <td>0.036625</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.041704</td>\n",
              "      <td>0.002938</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827400</th>\n",
              "      <td>0.028799</td>\n",
              "      <td>0.035327</td>\n",
              "      <td>0.037589</td>\n",
              "      <td>0.031592</td>\n",
              "      <td>0.059022</td>\n",
              "      <td>0.031867</td>\n",
              "      <td>0.036833</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.046522</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827401</th>\n",
              "      <td>0.028598</td>\n",
              "      <td>0.032114</td>\n",
              "      <td>0.024460</td>\n",
              "      <td>0.031667</td>\n",
              "      <td>0.031163</td>\n",
              "      <td>0.031906</td>\n",
              "      <td>0.030634</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.034486</td>\n",
              "      <td>0.002623</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827402</th>\n",
              "      <td>0.029256</td>\n",
              "      <td>0.030438</td>\n",
              "      <td>0.030119</td>\n",
              "      <td>0.044242</td>\n",
              "      <td>0.034640</td>\n",
              "      <td>0.031518</td>\n",
              "      <td>0.036958</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.046808</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827403</th>\n",
              "      <td>0.028598</td>\n",
              "      <td>0.031713</td>\n",
              "      <td>0.034141</td>\n",
              "      <td>0.031667</td>\n",
              "      <td>0.030732</td>\n",
              "      <td>0.031906</td>\n",
              "      <td>0.036625</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.045357</td>\n",
              "      <td>0.003842</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1827404 rows × 378 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         days_since_confirmed_risk  credit_limit_risk  full_credit_cost_risk  \\\n",
              "0                         0.036442           0.035327               0.034828   \n",
              "1                         0.033437           0.031628               0.034834   \n",
              "2                         0.033437           0.032114               0.035352   \n",
              "3                         0.037797           0.032976               0.034167   \n",
              "4                         0.028799           0.040180               0.034167   \n",
              "...                            ...                ...                    ...   \n",
              "1827399                   0.028598           0.032039               0.029464   \n",
              "1827400                   0.028799           0.035327               0.037589   \n",
              "1827401                   0.028598           0.032114               0.024460   \n",
              "1827402                   0.029256           0.030438               0.030119   \n",
              "1827403                   0.028598           0.031713               0.034141   \n",
              "\n",
              "         sum_left_to_pay_risk  maturity_fact_risk  credit_type_te  \\\n",
              "0                    0.031592            0.031765        0.069495   \n",
              "1                    0.031667            0.030732        0.031906   \n",
              "2                    0.031667            0.038862        0.031906   \n",
              "3                    0.031592            0.034909        0.031392   \n",
              "4                    0.031592            0.029911        0.031392   \n",
              "...                       ...                 ...             ...   \n",
              "1827399              0.031667            0.029100        0.031354   \n",
              "1827400              0.031592            0.059022        0.031867   \n",
              "1827401              0.031667            0.031163        0.031906   \n",
              "1827402              0.044242            0.034640        0.031518   \n",
              "1827403              0.031667            0.030732        0.031906   \n",
              "\n",
              "         maturity_plan_risk  credit_type    max_25    std_25  ...  \\\n",
              "0                  0.030992          5.0  0.047831  0.005730  ...   \n",
              "1                  0.030417          4.0  0.037585  0.002770  ...   \n",
              "2                  0.035473          4.0  0.043827  0.003179  ...   \n",
              "3                  0.036833          3.0  0.046522  0.003494  ...   \n",
              "4                  0.025565          3.0  0.048816  0.004078  ...   \n",
              "...                     ...          ...       ...       ...  ...   \n",
              "1827399            0.036625          3.0  0.041704  0.002938  ...   \n",
              "1827400            0.036833          4.0  0.046522  0.003494  ...   \n",
              "1827401            0.030634          4.0  0.034486  0.002623  ...   \n",
              "1827402            0.036958          3.0  0.046808  0.006300  ...   \n",
              "1827403            0.036625          4.0  0.045357  0.003842  ...   \n",
              "\n",
              "         deterioration_count  overdue_severity_score__mx__maturity_ratio  \\\n",
              "0                        1.0                                       162.0   \n",
              "1                        1.0                                       162.0   \n",
              "2                        1.0                                       162.0   \n",
              "3                        1.0                                       162.0   \n",
              "4                        1.0                                       162.0   \n",
              "...                      ...                                         ...   \n",
              "1827399                  1.0                                       162.0   \n",
              "1827400                  1.0                                       162.0   \n",
              "1827401                  1.0                                       162.0   \n",
              "1827402                  1.0                                       162.0   \n",
              "1827403                  1.0                                       162.0   \n",
              "\n",
              "         deterioration_count__d__has_clean_history  h12_16  h12_15  h12_14  \\\n",
              "0                                              0.0     0.0     0.0     0.0   \n",
              "1                                              1.0     0.0     0.0     0.0   \n",
              "2                                              1.0     0.0     0.0     0.0   \n",
              "3                                              1.0     0.0     0.0     0.0   \n",
              "4                                              1.0     0.0     0.0     0.0   \n",
              "...                                            ...     ...     ...     ...   \n",
              "1827399                                        1.0     0.0     0.0     0.0   \n",
              "1827400                                        1.0     0.0     0.0     0.0   \n",
              "1827401                                        1.0     0.0     0.0     0.0   \n",
              "1827402                                        0.0     0.0     0.0     0.0   \n",
              "1827403                                        0.0     0.0     0.0     0.0   \n",
              "\n",
              "         h12_13  h25_6  h25_7  h25_8  \n",
              "0           0.0    0.0    0.0    0.0  \n",
              "1           0.0    0.0    0.0    0.0  \n",
              "2           0.0    0.0    0.0    0.0  \n",
              "3           0.0    0.0    0.0    0.0  \n",
              "4           0.0    0.0    0.0    0.0  \n",
              "...         ...    ...    ...    ...  \n",
              "1827399     0.0    0.0    0.0    0.0  \n",
              "1827400     0.0    0.0    0.0    0.0  \n",
              "1827401     0.0    0.0    0.0    0.0  \n",
              "1827402     0.0    0.0    0.0    0.0  \n",
              "1827403     0.0    0.0    0.0    0.0  \n",
              "\n",
              "[1827404 rows x 378 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd6cbcf",
      "metadata": {
        "id": "6bd6cbcf"
      },
      "source": [
        "## Обучение первичное"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87128b58",
      "metadata": {
        "id": "87128b58"
      },
      "outputs": [],
      "source": [
        "features = [\n",
        "    'credit_number_for_user',\n",
        "    'maturity_fact',\n",
        "    'maturity_ratio',\n",
        "    'credit_limit',\n",
        "    'weighted_status_score',\n",
        "    'longest_run_bad_status',\n",
        "    'deterioration_count',\n",
        "    'next_payment_sum_ratio',\n",
        "    'sum_left_to_pay_progress',\n",
        "    'max_overdue_debt_ratio',\n",
        "    'full_credit_cost_ef_rate',\n",
        "\n",
        "    'total_overdues', 'overdue_severity_score', 'overdue_ratio', 'has_clean_history',\n",
        "    'max_overdue_level',\n",
        "\n",
        "    'credit_type',\n",
        "    'credit_currency']\n",
        "cat_features = ['credit_type', 'credit_currency', 'max_overdue_level']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2de79d7",
      "metadata": {
        "id": "d2de79d7"
      },
      "outputs": [],
      "source": [
        "X = df[features]\n",
        "y = df['target']\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "x_test = X_test[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abbbc9da",
      "metadata": {
        "id": "abbbc9da",
        "outputId": "02c9e198-1ca6-462a-9a0c-f76824f7d261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\ttest: 0.6046038\tbest: 0.6046038 (0)\ttotal: 1.44s\tremaining: 48m 1s\n",
            "100:\ttest: 0.6170486\tbest: 0.6170486 (100)\ttotal: 1m 56s\tremaining: 36m 32s\n",
            "200:\ttest: 0.6183562\tbest: 0.6184386 (194)\ttotal: 3m 32s\tremaining: 31m 39s\n",
            "300:\ttest: 0.6181507\tbest: 0.6186464 (261)\ttotal: 5m 17s\tremaining: 29m 51s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.6186464119\n",
            "bestIteration = 261\n",
            "\n",
            "Shrink model to first 262 iterations.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x28175c47550>"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CatBoostClassifier(\n",
        "    iterations=2000,\n",
        "    depth=11,\n",
        "    learning_rate=0.05,\n",
        "    l2_leaf_reg=7,\n",
        "    bagging_temperature=0.5,\n",
        "    auto_class_weights='Balanced',\n",
        "    eval_metric='AUC',  # Оптимизация по F1\n",
        "    random_seed=42,\n",
        "    verbose=100,\n",
        "    early_stopping_rounds=100,\n",
        "    cat_features=cat_features\n",
        ")\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(\n",
        "    x_train, y_train, eval_set=(x_val, y_val),\n",
        "    early_stopping_rounds=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a1eef0dc",
      "metadata": {
        "id": "a1eef0dc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, roc_auc_score, confusion_matrix,\n",
        "                            classification_report, precision_recall_curve,\n",
        "                            average_precision_score)\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba=None):\n",
        "    \"\"\"\n",
        "    Выводит все основные метрики качества для бинарной классификации\n",
        "\n",
        "    Parameters:\n",
        "    y_true: истинные значения\n",
        "    y_pred: предсказанные классы\n",
        "    y_pred_proba: предсказанные вероятности (для ROC-AUC)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"МЕТРИКИ КАЧЕСТВА МОДЕЛИ\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Основные метрики\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-score:  {f1:.4f}\")\n",
        "\n",
        "    # ROC-AUC если есть вероятности\n",
        "    if y_pred_proba is not None:\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "            print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "            # Average Precision Score\n",
        "            avg_precision = average_precision_score(y_true, y_pred_proba)\n",
        "            print(f\"Avg Precision: {avg_precision:.4f}\")\n",
        "        except:\n",
        "            print(\"ROC-AUC: Не удалось вычислить (проверьте y_pred_proba)\")\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 30)\n",
        "    print(\"MATRIXA SOWMESHENIY (CONFUSION MATRIX)\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Матрица ошибок\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(f\"True Negative (TN):  {tn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"True Positive (TP):  {tp}\")\n",
        "    print(f\"\\nМатрица в виде таблицы:\")\n",
        "    print(f\"[[TN {tn}   FP {fp}]\")\n",
        "    print(f\" [FN {fn}   TP {tp}]]\")\n",
        "\n",
        "    # Дополнительные метрики из матрицы ошибок\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Negative Rate\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n",
        "\n",
        "    print(f\"\\nSpecificity (TNR): {specificity:.4f}\")\n",
        "    print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
        "    print(f\"False Negative Rate (FNR): {fnr:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 30)\n",
        "    print(\"DETALNY OTCHET (CLASSIFICATION REPORT)\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Детальный отчет\n",
        "    print(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'], zero_division=0))\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc,\n",
        "        'confusion_matrix': cm,\n",
        "        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "43d131ad",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0}"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(X_test['current_overdue_debt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "9c2038ea",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.10887171561051003"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pr = 0.06\n",
        "re = 0.587\n",
        "\n",
        "(2 *pr*re)/(pr+re)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5814cc69",
      "metadata": {
        "id": "5814cc69",
        "outputId": "fb099ac1-c370-4d22-8e52-dc0cde29d583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "МЕТРИКИ КАЧЕСТВА МОДЕЛИ\n",
            "==================================================\n",
            "Accuracy:  0.6806\n",
            "Precision: 0.0502\n",
            "Recall:    0.4787\n",
            "F1-score:  0.0909\n",
            "ROC-AUC:   0.6186\n",
            "Avg Precision: 0.0574\n",
            "\n",
            "------------------------------\n",
            "MATRIXA SOWMESHENIY (CONFUSION MATRIX)\n",
            "------------------------------\n",
            "True Negative (TN):  303613\n",
            "False Positive (FP): 137994\n",
            "False Negative (FN): 7947\n",
            "True Positive (TP):  7297\n",
            "\n",
            "Матрица в виде таблицы:\n",
            "[[TN 303613   FP 137994]\n",
            " [FN 7947   TP 7297]]\n",
            "\n",
            "Specificity (TNR): 0.6875\n",
            "False Positive Rate (FPR): 0.3125\n",
            "False Negative Rate (FNR): 0.5213\n",
            "\n",
            "------------------------------\n",
            "DETALNY OTCHET (CLASSIFICATION REPORT)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.97      0.69      0.81    441607\n",
            "     Class 1       0.05      0.48      0.09     15244\n",
            "\n",
            "    accuracy                           0.68    456851\n",
            "   macro avg       0.51      0.58      0.45    456851\n",
            "weighted avg       0.94      0.68      0.78    456851\n",
            "\n"
          ]
        }
      ],
      "source": [
        "base_vetrics = evaluate_model(y_val, model.predict(x_val), model.predict_proba(x_val)[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e522cd",
      "metadata": {
        "id": "11e522cd",
        "outputId": "2be90213-c1e7-429e-c7dc-61b6d5a1e145"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>weighted_status_score</td>\n",
              "      <td>11.235639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sum_left_to_pay_progress</td>\n",
              "      <td>9.909159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>credit_type</td>\n",
              "      <td>8.989772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maturity_ratio</td>\n",
              "      <td>8.400929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>next_payment_sum_ratio</td>\n",
              "      <td>7.903960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maturity_fact</td>\n",
              "      <td>7.837513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>max_overdue_debt_ratio</td>\n",
              "      <td>7.707635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>full_credit_cost_ef_rate</td>\n",
              "      <td>5.922321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>credit_limit</td>\n",
              "      <td>5.717225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>has_clean_history</td>\n",
              "      <td>5.597286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>overdue_ratio</td>\n",
              "      <td>5.143584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>credit_number_for_user</td>\n",
              "      <td>4.243456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>deterioration_count</td>\n",
              "      <td>4.127255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>longest_run_bad_status</td>\n",
              "      <td>2.631007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>credit_currency</td>\n",
              "      <td>1.520815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>max_overdue_level</td>\n",
              "      <td>1.233902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>overdue_severity_score</td>\n",
              "      <td>0.960336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>total_overdues</td>\n",
              "      <td>0.918206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     feature  importance\n",
              "4      weighted_status_score   11.235639\n",
              "8   sum_left_to_pay_progress    9.909159\n",
              "16               credit_type    8.989772\n",
              "2             maturity_ratio    8.400929\n",
              "7     next_payment_sum_ratio    7.903960\n",
              "1              maturity_fact    7.837513\n",
              "9     max_overdue_debt_ratio    7.707635\n",
              "10  full_credit_cost_ef_rate    5.922321\n",
              "3               credit_limit    5.717225\n",
              "14         has_clean_history    5.597286\n",
              "13             overdue_ratio    5.143584\n",
              "0     credit_number_for_user    4.243456\n",
              "6        deterioration_count    4.127255\n",
              "5     longest_run_bad_status    2.631007\n",
              "17           credit_currency    1.520815\n",
              "15         max_overdue_level    1.233902\n",
              "12    overdue_severity_score    0.960336\n",
              "11            total_overdues    0.918206"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_imp = pd.DataFrame({\n",
        "        'feature': x_train.columns,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', key=abs, ascending=False)\n",
        "feature_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948e0d82",
      "metadata": {
        "id": "948e0d82",
        "outputId": "8b829928-871e-45b5-f26e-f11c8f4a7bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1: 0.1400 at threshold 0.63\n"
          ]
        }
      ],
      "source": [
        "y_val_pred_proba = model.predict_proba(x_train)[:, 1]\n",
        "\n",
        "# Сетка порогов\n",
        "thresholds = np.linspace(0.01, 0.99, 199)\n",
        "\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
        "    f1 = f1_score(y_train, y_val_pred)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = t\n",
        "\n",
        "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd4347e",
      "metadata": {
        "id": "bdd4347e",
        "outputId": "ef902f20-840d-4072-cce7-982cb537fa52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1: 0.1052 at threshold 0.59\n"
          ]
        }
      ],
      "source": [
        "y_val_pred_proba = model.predict_proba(x_val)[:, 1]\n",
        "\n",
        "# Сетка порогов\n",
        "thresholds = np.linspace(0.01, 0.99, 199)\n",
        "\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
        "    f1 = f1_score(y_val, y_val_pred)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = t\n",
        "\n",
        "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e904aecb",
      "metadata": {
        "id": "e904aecb"
      },
      "source": [
        "#### Итоговое обучение и сабмишен"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "292b3da6",
      "metadata": {
        "id": "292b3da6"
      },
      "outputs": [],
      "source": [
        "x_tra, x_va, y_tra, y_va = train_test_split(X, y, test_size=0.001, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f63e8e1",
      "metadata": {
        "id": "4f63e8e1",
        "outputId": "f4f0e9d3-9280-4c70-f3bd-cf39ca7a7b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\ttest: 0.6178258\tbest: 0.6178258 (0)\ttotal: 1.75s\tremaining: 58m 26s\n",
            "100:\ttest: 0.6243863\tbest: 0.6276787 (70)\ttotal: 2m 30s\tremaining: 47m 5s\n",
            "200:\ttest: 0.6362800\tbest: 0.6362800 (200)\ttotal: 4m 34s\tremaining: 40m 53s\n",
            "300:\ttest: 0.6396113\tbest: 0.6402932 (295)\ttotal: 6m 37s\tremaining: 37m 23s\n",
            "400:\ttest: 0.6462254\tbest: 0.6485340 (380)\ttotal: 9m 21s\tremaining: 37m 19s\n",
            "500:\ttest: 0.6476671\tbest: 0.6506673 (465)\ttotal: 12m 2s\tremaining: 36m 2s\n",
            "600:\ttest: 0.6579827\tbest: 0.6584015 (599)\ttotal: 14m 45s\tremaining: 34m 21s\n",
            "700:\ttest: 0.6613920\tbest: 0.6614699 (698)\ttotal: 17m 31s\tremaining: 32m 28s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.6614699006\n",
            "bestIteration = 698\n",
            "\n",
            "Shrink model to first 699 iterations.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x28175c47550>"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_itog = CatBoostClassifier(\n",
        "    iterations=500,\n",
        "    depth=11,\n",
        "    learning_rate=0.05,\n",
        "    l2_leaf_reg=20,\n",
        "    bagging_temperature=0.5,\n",
        "    auto_class_weights='Balanced',\n",
        "    eval_metric='AUC',  # Оптимизация по F1\n",
        "    random_seed=42,\n",
        "    verbose=100,\n",
        "    cat_features=cat_features\n",
        ")\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(\n",
        "    x_tra, y_tra, eval_set=(x_va, y_va)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41692dcc",
      "metadata": {
        "id": "41692dcc"
      },
      "outputs": [],
      "source": [
        "model_itog_max = CatBoostClassifier(\n",
        "    iterations=00,\n",
        "    depth=11,\n",
        "    learning_rate=0.05,\n",
        "    l2_leaf_reg=20,\n",
        "    bagging_temperature=0.5,\n",
        "    auto_class_weights='Balanced',\n",
        "    eval_metric='AUC',  # Оптимизация по F1\n",
        "    random_seed=42,\n",
        "    verbose=100,\n",
        "    cat_features=cat_features\n",
        ")\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(\n",
        "    df[features], df['target']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5489691c",
      "metadata": {
        "id": "5489691c",
        "outputId": "9cfc8d62-1a45-49d7-ce61-c23360e62763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "МЕТРИКИ КАЧЕСТВА МОДЕЛИ\n",
            "==================================================\n",
            "Accuracy:  0.7194\n",
            "Precision: 0.0617\n",
            "Recall:    0.5517\n",
            "F1-score:  0.1109\n",
            "ROC-AUC:   0.6615\n",
            "Avg Precision: 0.1048\n",
            "\n",
            "------------------------------\n",
            "MATRIXA SOWMESHENIY (CONFUSION MATRIX)\n",
            "------------------------------\n",
            "True Negative (TN):  1283\n",
            "False Positive (FP): 487\n",
            "False Negative (FN): 26\n",
            "True Positive (TP):  32\n",
            "\n",
            "Матрица в виде таблицы:\n",
            "[[TN 1283   FP 487]\n",
            " [FN 26   TP 32]]\n",
            "\n",
            "Specificity (TNR): 0.7249\n",
            "False Positive Rate (FPR): 0.2751\n",
            "False Negative Rate (FNR): 0.4483\n",
            "\n",
            "------------------------------\n",
            "DETALNY OTCHET (CLASSIFICATION REPORT)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.98      0.72      0.83      1770\n",
            "     Class 1       0.06      0.55      0.11        58\n",
            "\n",
            "    accuracy                           0.72      1828\n",
            "   macro avg       0.52      0.64      0.47      1828\n",
            "weighted avg       0.95      0.72      0.81      1828\n",
            "\n"
          ]
        }
      ],
      "source": [
        "base_vetrics = evaluate_model(y_va, model.predict(x_va), model.predict_proba(x_va)[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ea76f2",
      "metadata": {
        "id": "d1ea76f2"
      },
      "outputs": [],
      "source": [
        "test_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb898fda",
      "metadata": {
        "id": "fb898fda",
        "outputId": "73205428-6de5-4407-8a2b-424b4b78fd06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1: 0.1159 at threshold 0.74\n"
          ]
        }
      ],
      "source": [
        "y_val_pred_proba = model.predict_proba(x_va)[:, 1]\n",
        "\n",
        "# Сетка порогов\n",
        "thresholds = np.linspace(0.01, 0.99, 99)\n",
        "\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
        "    f1 = f1_score(y_val_pred, y_va)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = t\n",
        "\n",
        "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad3635d",
      "metadata": {
        "id": "7ad3635d",
        "outputId": "b08004d5-e886-4106-a74b-3b695edbea53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1: 0.1963 at threshold 0.65\n"
          ]
        }
      ],
      "source": [
        "y_val_pred_proba = model.predict_proba(x_tra)[:, 1]\n",
        "\n",
        "# Сетка порогов\n",
        "thresholds = np.linspace(0.01, 0.99, 99)\n",
        "\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_val_pred = (y_val_pred_proba >= t).astype(int)\n",
        "    f1 = f1_score(y_val_pred, y_tra)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = t\n",
        "\n",
        "print(f\"Best F1: {best_f1:.4f} at threshold {best_threshold:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d1725b7",
      "metadata": {
        "id": "6d1725b7"
      },
      "outputs": [],
      "source": [
        "proba = model.predict_proba(x_test)[:, 1]\n",
        "test_pred = (proba >= 0.74).astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1dd5e4",
      "metadata": {
        "id": "7a1dd5e4",
        "outputId": "660a9ddd-d4e7-4c38-b361-da9ac47255b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([False, False, False, ..., False, False, False], shape=(456852,))"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4cae739",
      "metadata": {
        "id": "e4cae739"
      },
      "outputs": [],
      "source": [
        "X_test['flag'] = test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e2df75",
      "metadata": {
        "id": "54e2df75"
      },
      "outputs": [],
      "source": [
        "X_test[['id', 'flag']].set_index('id').to_csv('sub_mission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf0c139",
      "metadata": {
        "id": "dbf0c139"
      },
      "source": [
        "## Мощное обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f03d9865",
      "metadata": {
        "id": "f03d9865"
      },
      "source": [
        "### credit_type == ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29002ee3",
      "metadata": {
        "id": "29002ee3"
      },
      "outputs": [],
      "source": [
        "diction = {}\n",
        "detph = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbd0582",
      "metadata": {
        "id": "8bbd0582",
        "outputId": "988b1afb-e7ff-4a63-e7ff-5db03cac4019"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "credit_type\n",
              "0     15963.25\n",
              "1      2328.25\n",
              "2     10630.25\n",
              "3    137111.75\n",
              "4    258849.75\n",
              "5     20398.75\n",
              "6      1256.25\n",
              "7     10312.75\n",
              "Name: credit_number_for_user, dtype: float64"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby('credit_type')['credit_number_for_user'].count() * 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f578a33b",
      "metadata": {
        "id": "f578a33b"
      },
      "outputs": [],
      "source": [
        "typee = 7\n",
        "df_0 = df[df['credit_type'] == typee]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2bd969",
      "metadata": {
        "id": "cb2bd969",
        "outputId": "6666842d-4b28-4493-d26b-1ff00907815b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\ttest: 0.5586678\tbest: 0.5586678 (0)\ttotal: 32.3ms\tremaining: 1m 4s\n",
            "100:\ttest: 0.5327881\tbest: 0.5685026 (6)\ttotal: 2.92s\tremaining: 54.9s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.5685026315\n",
            "bestIteration = 6\n",
            "\n",
            "Shrink model to first 7 iterations.\n",
            "==================================================\n",
            "МЕТРИКИ КАЧЕСТВА МОДЕЛИ\n",
            "==================================================\n",
            "Accuracy:  0.7027\n",
            "Precision: 0.0446\n",
            "Recall:    0.4098\n",
            "F1-score:  0.0804\n",
            "ROC-AUC:   0.5685\n",
            "Avg Precision: 0.0423\n",
            "\n",
            "------------------------------\n",
            "MATRIXA SOWMESHENIY (CONFUSION MATRIX)\n",
            "------------------------------\n",
            "True Negative (TN):  7113\n",
            "False Positive (FP): 2873\n",
            "False Negative (FN): 193\n",
            "True Positive (TP):  134\n",
            "\n",
            "Матрица в виде таблицы:\n",
            "[[TN 7113   FP 2873]\n",
            " [FN 193   TP 134]]\n",
            "\n",
            "Specificity (TNR): 0.7123\n",
            "False Positive Rate (FPR): 0.2877\n",
            "False Negative Rate (FNR): 0.5902\n",
            "\n",
            "------------------------------\n",
            "DETALNY OTCHET (CLASSIFICATION REPORT)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.97      0.71      0.82      9986\n",
            "     Class 1       0.04      0.41      0.08       327\n",
            "\n",
            "    accuracy                           0.70     10313\n",
            "   macro avg       0.51      0.56      0.45     10313\n",
            "weighted avg       0.94      0.70      0.80     10313\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>longest_run_bad_status</td>\n",
              "      <td>17.528091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>credit_number_for_user</td>\n",
              "      <td>16.898484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maturity_fact</td>\n",
              "      <td>14.885166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>weighted_status_score</td>\n",
              "      <td>12.307858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>credit_limit</td>\n",
              "      <td>8.092802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>max_overdue_debt_ratio</td>\n",
              "      <td>8.014381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>full_credit_cost_ef_rate</td>\n",
              "      <td>7.521686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sum_left_to_pay_progress</td>\n",
              "      <td>6.358995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maturity_ratio</td>\n",
              "      <td>3.284717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>deterioration_count</td>\n",
              "      <td>2.743928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>next_payment_sum_ratio</td>\n",
              "      <td>2.363892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>credit_currency</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     feature  importance\n",
              "5     longest_run_bad_status   17.528091\n",
              "0     credit_number_for_user   16.898484\n",
              "1              maturity_fact   14.885166\n",
              "4      weighted_status_score   12.307858\n",
              "3               credit_limit    8.092802\n",
              "9     max_overdue_debt_ratio    8.014381\n",
              "10  full_credit_cost_ef_rate    7.521686\n",
              "8   sum_left_to_pay_progress    6.358995\n",
              "2             maturity_ratio    3.284717\n",
              "6        deterioration_count    2.743928\n",
              "7     next_payment_sum_ratio    2.363892\n",
              "11           credit_currency    0.000000"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = [\n",
        "    'credit_number_for_user',\n",
        "    'maturity_fact',\n",
        "    'maturity_ratio',\n",
        "    'credit_limit',\n",
        "    'weighted_status_score',\n",
        "    'longest_run_bad_status',\n",
        "    'deterioration_count',\n",
        "    'next_payment_sum_ratio',\n",
        "    'sum_left_to_pay_progress',\n",
        "    'max_overdue_debt_ratio',\n",
        "    'full_credit_cost_ef_rate',\n",
        "    'credit_currency']\n",
        "\n",
        "X = df_0[features]\n",
        "y = df_0['target']\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "x_test = X_test[features]\n",
        "\n",
        "depth = 9\n",
        "model = CatBoostClassifier(\n",
        "    iterations=2000,\n",
        "    depth=depth,\n",
        "    learning_rate=0.07,\n",
        "    l2_leaf_reg=5,\n",
        "    bagging_temperature=0.5,\n",
        "    auto_class_weights='Balanced',\n",
        "    eval_metric='AUC',  # Оптимизация по F1\n",
        "    random_seed=42,\n",
        "    verbose=100,\n",
        "    early_stopping_rounds=100,\n",
        "    cat_features=['credit_currency']\n",
        ")\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(\n",
        "    x_train, y_train, eval_set=(x_val, y_val),\n",
        "    early_stopping_rounds=100\n",
        ")\n",
        "\n",
        "diction[typee] = evaluate_model(y_val, model.predict(x_val), model.predict_proba(x_val)[:,1])\n",
        "detph[typee] = depth\n",
        "\n",
        "feature_imp = pd.DataFrame({\n",
        "        'feature': x_train.columns,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', key=abs, ascending=False)\n",
        "feature_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da6b60cf",
      "metadata": {
        "id": "da6b60cf",
        "outputId": "cabdb630-c750-45fa-9fb9-fef7ad26603b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.06322861094645327\n",
            "1 0.1016949152542373\n",
            "2 0.06269020085209982\n",
            "3 0.08201916690388082\n",
            "4 0.07979600017816578\n",
            "5 0.16505293638584742\n",
            "6 0.13020833333333334\n",
            "7 0.08038392321535692\n"
          ]
        }
      ],
      "source": [
        "for k, v in diction.items():\n",
        "    print(k, v['f1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0008e29",
      "metadata": {
        "id": "f0008e29"
      },
      "source": [
        "### credit_type == 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64490a91",
      "metadata": {
        "id": "64490a91"
      },
      "outputs": [],
      "source": [
        "typee = 4\n",
        "df_4 = df[df['credit_type'] == typee]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e64ba1d",
      "metadata": {
        "id": "4e64ba1d",
        "outputId": "fd154348-a30a-4153-8df2-d20c10ec25e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# -------------------------\n",
        "# 0) Reproducibility\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc49ff84",
      "metadata": {
        "id": "bc49ff84",
        "outputId": "d32c3056-4a7d-4322-e15d-6cb54af049ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "credit_number_for_user           0\n",
              "maturity_fact                    0\n",
              "maturity_ratio              100255\n",
              "credit_limit                     0\n",
              "weighted_status_score            0\n",
              "longest_run_bad_status           0\n",
              "deterioration_count              0\n",
              "next_payment_sum_ratio      104816\n",
              "sum_left_to_pay_progress         0\n",
              "max_overdue_debt_ratio      108960\n",
              "full_credit_cost_ef_rate     94592\n",
              "dtype: int64"
            ]
          },
          "execution_count": 305,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df[features] == np.inf).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a854ceeb",
      "metadata": {
        "id": "a854ceeb",
        "outputId": "713e8783-207d-420b-d346-2bfcf69991b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\work\\programs\\lang\\python\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input X contains infinity or a value too large for dtype('float64').",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[302]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# масштабирование (только по train)\u001b[39;00m\n\u001b[32m     34\u001b[39m scaler = RobustScaler()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m x_tr_sc = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m x_val_sc = scaler.transform(x_val)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1624\u001b[39m, in \u001b[36mRobustScaler.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m   1606\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the median and quantiles to be used for scaling.\u001b[39;00m\n\u001b[32m   1607\u001b[39m \n\u001b[32m   1608\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1620\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m   1621\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1622\u001b[39m \u001b[38;5;66;03m# at fit, convert sparse matrices to csc for optimized computation of\u001b[39;00m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# the quantiles\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m q_min, q_max = \u001b[38;5;28mself\u001b[39m.quantile_range\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= q_min <= q_max <= \u001b[32m100\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
            "\u001b[31mValueError\u001b[39m: Input X contains infinity or a value too large for dtype('float64')."
          ]
        }
      ],
      "source": [
        "\n",
        "features = [\n",
        "    'credit_number_for_user',\n",
        "    'maturity_fact',\n",
        "    'maturity_ratio',\n",
        "    'credit_limit',\n",
        "    'weighted_status_score',\n",
        "    'longest_run_bad_status',\n",
        "    'deterioration_count',\n",
        "    'next_payment_sum_ratio',\n",
        "    'sum_left_to_pay_progress',\n",
        "    'max_overdue_debt_ratio',\n",
        "    'full_credit_cost_ef_rate',\n",
        "]\n",
        "\n",
        "# проверим, что все фичи есть в данных\n",
        "missing = [f for f in features if f not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Отсутствуют признаки в X_train: {missing}\\n\"\n",
        "                     f\"Убедись, что они посчитаны и присутствуют до запуска MLP.\")\n",
        "\n",
        "# на всякий случай — заменить NaN/inf\n",
        "df_4[features] = df[features].fillna(0.0)\n",
        "X_test_4[features] = X_test_4[features].fillna(0.0)\n",
        "\n",
        "X = df_4[features].astype(float)\n",
        "y = df_4['target'].astype(int).values\n",
        "\n",
        "# train/val split (стратифицированный)\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "# масштабирование (только по train)\n",
        "scaler = RobustScaler()\n",
        "x_tr_sc = scaler.fit_transform(x_tr)\n",
        "x_val_sc = scaler.transform(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d551a6",
      "metadata": {
        "id": "08d551a6"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# 2) PyTorch Dataset/Dataloader\n",
        "# -------------------------\n",
        "class TabDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.y = None if y is None else torch.from_numpy(y).float()\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.X[idx]\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = TabDataset(x_tr_sc, y_tr)\n",
        "val_ds   = TabDataset(x_val_sc, y_val)\n",
        "# sub_ds   = TabDataset(x_sub_sc, None)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4096, shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=8192, shuffle=False, num_workers=0)\n",
        "# sub_loader   = DataLoader(sub_ds,   batch_size=8192, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3e4743",
      "metadata": {
        "id": "6a3e4743"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------------\n",
        "# 3) Model\n",
        "# -------------------------\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.20),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.20),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.10),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.10),\n",
        "\n",
        "            nn.Linear(32, 1)  # логит\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)  # [B]\n",
        "\n",
        "in_dim = len(features)\n",
        "model = MLP(in_dim).to(DEVICE)\n",
        "\n",
        "# -------------------------\n",
        "# 4) Loss (pos_weight) & Optimizer & Scheduler\n",
        "# -------------------------\n",
        "# дисбаланс: pos_weight = N_neg/N_pos\n",
        "pos = y_tr.sum()\n",
        "neg = len(y_tr) - pos\n",
        "pos_weight_value = (neg / max(1, pos))\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight_value, device=DEVICE))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c55d9d95",
      "metadata": {
        "id": "c55d9d95",
        "outputId": "fb902904-5ea1-421b-8e0d-b4fd4c3e2a7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler_amp = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 10%|█         | 1/10 [00:25<03:50, 25.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | train_loss=1.33416 | val_auc=0.56409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 20%|██        | 2/10 [00:51<03:26, 25.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02 | train_loss=1.32950 | val_auc=0.56670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 30%|███       | 3/10 [01:16<02:58, 25.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03 | train_loss=1.32829 | val_auc=0.57015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 40%|████      | 4/10 [01:42<02:32, 25.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04 | train_loss=1.32712 | val_auc=0.57142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 50%|█████     | 5/10 [02:07<02:06, 25.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05 | train_loss=1.32686 | val_auc=0.57075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 60%|██████    | 6/10 [02:32<01:41, 25.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06 | train_loss=1.32614 | val_auc=0.57508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 70%|███████   | 7/10 [02:59<01:17, 25.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07 | train_loss=1.32530 | val_auc=0.57355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 80%|████████  | 8/10 [03:24<00:51, 25.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08 | train_loss=1.32493 | val_auc=0.57485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            " 90%|█████████ | 9/10 [03:49<00:25, 25.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09 | train_loss=1.32414 | val_auc=0.57607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\AppData\\Local\\Temp\\ipykernel_6068\\943996942.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            "100%|██████████| 10/10 [04:15<00:00, 25.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | train_loss=1.32345 | val_auc=0.57609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -------------------------\n",
        "# 5) Train loop with early stopping\n",
        "# -------------------------\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_logits, all_y = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            xb, yb = batch\n",
        "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "            logits = model(xb)\n",
        "            all_logits.append(logits.detach().cpu().numpy())\n",
        "            all_y.append(yb.detach().cpu().numpy())\n",
        "    logits = np.concatenate(all_logits)\n",
        "    y_true = np.concatenate(all_y)\n",
        "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
        "    # AUC для контроля, F1 посчитаем с порогом отдельно\n",
        "    auc = roc_auc_score(y_true, probs)\n",
        "    return auc, probs, y_true\n",
        "\n",
        "best_auc = -np.inf\n",
        "best_state = None\n",
        "patience, patience_left = 8, 8\n",
        "EPOCHS = 10\n",
        "scaler_amp = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "for epoch in tqdm(range(1, EPOCHS+1)):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        xb, yb = batch\n",
        "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "        scaler_amp.scale(loss).backward()\n",
        "        scaler_amp.step(optimizer)\n",
        "        scaler_amp.update()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    val_auc, val_probs, val_true = evaluate(model, val_loader)\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={epoch_loss/len(train_loader):.5f} | val_auc={val_auc:.5f}\")\n",
        "\n",
        "    if val_auc > best_auc + 1e-4:\n",
        "        best_auc = val_auc\n",
        "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        patience_left = patience\n",
        "    else:\n",
        "        patience_left -= 1\n",
        "        if patience_left == 0:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "# restore best\n",
        "if best_state is not None:\n",
        "    model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})\n",
        "\n",
        "# -------------------------\n",
        "# 6) Threshold tuning for F1\n",
        "# -------------------------\n",
        "# вычислим ещё раз на валидации лучшие пороги\n",
        "\n",
        "# # (опционально) можно посмотреть и PR-кривую:\n",
        "# # precisions, recalls, thr = precision_recall_curve(val_true, val_probs)\n",
        "\n",
        "# # -------------------------\n",
        "# # 7) Inference on test + submission\n",
        "# # -------------------------\n",
        "# # прогон по test\n",
        "# model.eval()\n",
        "# test_probs_all = []\n",
        "# with torch.no_grad():\n",
        "#     for xb in sub_loader:\n",
        "#         xb = xb.to(DEVICE)\n",
        "#         logits = model(xb)\n",
        "#         probs = torch.sigmoid(logits)\n",
        "#         test_probs_all.append(probs.detach().cpu().numpy())\n",
        "# test_probs = np.concatenate(test_probs_all)\n",
        "\n",
        "# # бинаризация по найденному порогу\n",
        "# test_pred = (test_probs >= best_t).astype(int)\n",
        "\n",
        "# submission = pd.DataFrame({\n",
        "#     \"id\": X_test[\"id\"].values,\n",
        "#     \"flag\": test_pred\n",
        "# })\n",
        "# submission_path = \"submission_mlp_tabular.csv\"\n",
        "# submission.to_csv(submission_path, index=False)\n",
        "# print(\"Saved:\", submission_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf71415",
      "metadata": {
        "id": "fbf71415",
        "outputId": "d47b5b60-e5ea-4ad2-d4f9-24f364ff29cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1 on VAL = 0.0820 at threshold=0.550\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "_, val_probs, val_true = evaluate(model, val_loader)\n",
        "\n",
        "thresholds = np.linspace(0.01, 0.99, 99)\n",
        "best_t, best_f1 = 0.5, 0.0\n",
        "for t in thresholds:\n",
        "    preds = (val_probs >= t).astype(int)\n",
        "    f1 = f1_score(val_true, preds)\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_t = f1, t\n",
        "\n",
        "print(f\"Best F1 on VAL = {best_f1:.4f} at threshold={best_t:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2ef163",
      "metadata": {
        "id": "cf2ef163"
      },
      "source": [
        "## Ансамбль моделей с подбором точности"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d77814",
      "metadata": {
        "id": "24d77814"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21509c1a",
      "metadata": {
        "id": "21509c1a"
      },
      "source": [
        "#### Модель A (Catboost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f47573c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f47573c",
        "outputId": "c6698e0b-b90b-42e0-f472-1a082e20cd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\ttest: 0.6045104\tbest: 0.6045104 (0)\ttotal: 2.06s\tremaining: 1h 42m 56s\n",
            "50:\ttest: 0.6217217\tbest: 0.6217217 (50)\ttotal: 52.4s\tremaining: 50m 27s\n",
            "100:\ttest: 0.6252702\tbest: 0.6252702 (100)\ttotal: 1m 43s\tremaining: 49m 40s\n",
            "150:\ttest: 0.6270390\tbest: 0.6270390 (150)\ttotal: 2m 33s\tremaining: 48m 7s\n",
            "200:\ttest: 0.6282392\tbest: 0.6282392 (200)\ttotal: 3m 21s\tremaining: 46m 39s\n",
            "250:\ttest: 0.6286820\tbest: 0.6286830 (248)\ttotal: 4m 11s\tremaining: 45m 52s\n",
            "300:\ttest: 0.6288116\tbest: 0.6289138 (287)\ttotal: 5m\tremaining: 44m 58s\n",
            "350:\ttest: 0.6292577\tbest: 0.6293020 (349)\ttotal: 5m 48s\tremaining: 43m 53s\n",
            "400:\ttest: 0.6293799\tbest: 0.6294236 (397)\ttotal: 6m 38s\tremaining: 43m\n",
            "450:\ttest: 0.6293790\tbest: 0.6294236 (397)\ttotal: 7m 26s\tremaining: 42m 1s\n",
            "500:\ttest: 0.6292565\tbest: 0.6294236 (397)\ttotal: 8m 15s\tremaining: 41m 12s\n",
            "550:\ttest: 0.6288378\tbest: 0.6294236 (397)\ttotal: 9m 4s\tremaining: 40m 20s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 0.6294236467\n",
            "bestIteration = 397\n",
            "\n",
            "Shrink model to first 398 iterations.\n",
            "0:\ttest: 0.6112057\tbest: 0.6112057 (0)\ttotal: 865ms\tremaining: 43m 13s\n",
            "50:\ttest: 0.6278006\tbest: 0.6278006 (50)\ttotal: 50.4s\tremaining: 48m 36s\n",
            "100:\ttest: 0.6316633\tbest: 0.6316633 (100)\ttotal: 1m 38s\tremaining: 47m 10s\n",
            "150:\ttest: 0.6334957\tbest: 0.6335015 (149)\ttotal: 2m 27s\tremaining: 46m 26s\n",
            "200:\ttest: 0.6344746\tbest: 0.6344746 (200)\ttotal: 3m 15s\tremaining: 45m 21s\n",
            "250:\ttest: 0.6344924\tbest: 0.6345523 (230)\ttotal: 4m 4s\tremaining: 44m 40s\n",
            "300:\ttest: 0.6347786\tbest: 0.6348287 (285)\ttotal: 4m 53s\tremaining: 43m 53s\n",
            "350:\ttest: 0.6349301\tbest: 0.6350651 (324)\ttotal: 5m 42s\tremaining: 43m 3s\n",
            "400:\ttest: 0.6344682\tbest: 0.6350651 (324)\ttotal: 6m 31s\tremaining: 42m 18s\n",
            "450:\ttest: 0.6342556\tbest: 0.6350651 (324)\ttotal: 7m 19s\tremaining: 41m 24s\n",
            "500:\ttest: 0.6342162\tbest: 0.6350651 (324)\ttotal: 8m 8s\tremaining: 40m 39s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 0.6350651115\n",
            "bestIteration = 324\n",
            "\n",
            "Shrink model to first 325 iterations.\n",
            "0:\ttest: 0.6030702\tbest: 0.6030702 (0)\ttotal: 876ms\tremaining: 43m 47s\n",
            "50:\ttest: 0.6212886\tbest: 0.6212886 (50)\ttotal: 49.2s\tremaining: 47m 23s\n",
            "100:\ttest: 0.6250651\tbest: 0.6250651 (100)\ttotal: 1m 38s\tremaining: 47m 15s\n",
            "150:\ttest: 0.6261111\tbest: 0.6261111 (150)\ttotal: 2m 28s\tremaining: 46m 40s\n",
            "200:\ttest: 0.6264913\tbest: 0.6265693 (182)\ttotal: 3m 16s\tremaining: 45m 39s\n",
            "250:\ttest: 0.6267524\tbest: 0.6268566 (244)\ttotal: 4m 6s\tremaining: 44m 57s\n",
            "300:\ttest: 0.6268609\tbest: 0.6269168 (298)\ttotal: 4m 54s\tremaining: 43m 57s\n",
            "350:\ttest: 0.6268646\tbest: 0.6269168 (298)\ttotal: 5m 43s\tremaining: 43m 12s\n",
            "400:\ttest: 0.6264601\tbest: 0.6269168 (298)\ttotal: 6m 33s\tremaining: 42m 27s\n",
            "450:\ttest: 0.6259941\tbest: 0.6269168 (298)\ttotal: 7m 21s\tremaining: 41m 32s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 0.6269168153\n",
            "bestIteration = 298\n",
            "\n",
            "Shrink model to first 299 iterations.\n",
            "0:\ttest: 0.6041389\tbest: 0.6041389 (0)\ttotal: 886ms\tremaining: 44m 17s\n",
            "50:\ttest: 0.6223165\tbest: 0.6223165 (50)\ttotal: 50.8s\tremaining: 48m 57s\n",
            "100:\ttest: 0.6263563\tbest: 0.6263563 (100)\ttotal: 1m 39s\tremaining: 47m 44s\n",
            "150:\ttest: 0.6283259\tbest: 0.6283259 (150)\ttotal: 2m 29s\tremaining: 46m 54s\n",
            "200:\ttest: 0.6292896\tbest: 0.6292936 (199)\ttotal: 3m 17s\tremaining: 45m 50s\n",
            "250:\ttest: 0.6295466\tbest: 0.6295466 (250)\ttotal: 4m 7s\tremaining: 45m 9s\n",
            "300:\ttest: 0.6298154\tbest: 0.6298254 (289)\ttotal: 4m 57s\tremaining: 44m 24s\n",
            "350:\ttest: 0.6299097\tbest: 0.6299522 (344)\ttotal: 5m 45s\tremaining: 43m 27s\n",
            "400:\ttest: 0.6298189\tbest: 0.6300650 (372)\ttotal: 6m 35s\tremaining: 42m 42s\n",
            "450:\ttest: 0.6295911\tbest: 0.6300650 (372)\ttotal: 7m 24s\tremaining: 41m 51s\n",
            "500:\ttest: 0.6296658\tbest: 0.6300650 (372)\ttotal: 8m 13s\tremaining: 41m 1s\n",
            "550:\ttest: 0.6296075\tbest: 0.6300650 (372)\ttotal: 9m 3s\tremaining: 40m 15s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 0.6300649846\n",
            "bestIteration = 372\n",
            "\n",
            "Shrink model to first 373 iterations.\n",
            "0:\ttest: 0.6068149\tbest: 0.6068149 (0)\ttotal: 859ms\tremaining: 42m 56s\n",
            "50:\ttest: 0.6215221\tbest: 0.6215221 (50)\ttotal: 48.4s\tremaining: 46m 38s\n",
            "100:\ttest: 0.6249377\tbest: 0.6249563 (99)\ttotal: 1m 37s\tremaining: 46m 32s\n",
            "150:\ttest: 0.6265113\tbest: 0.6265113 (150)\ttotal: 2m 25s\tremaining: 45m 42s\n",
            "200:\ttest: 0.6271670\tbest: 0.6271670 (200)\ttotal: 3m 13s\tremaining: 44m 54s\n",
            "250:\ttest: 0.6271444\tbest: 0.6273459 (243)\ttotal: 4m 1s\tremaining: 44m 10s\n",
            "300:\ttest: 0.6271002\tbest: 0.6273459 (243)\ttotal: 4m 49s\tremaining: 43m 13s\n",
            "350:\ttest: 0.6266478\tbest: 0.6273459 (243)\ttotal: 5m 38s\tremaining: 42m 31s\n",
            "400:\ttest: 0.6262844\tbest: 0.6273459 (243)\ttotal: 6m 25s\tremaining: 41m 38s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 0.6273458798\n",
            "bestIteration = 243\n",
            "\n",
            "Shrink model to first 244 iterations.\n"
          ]
        }
      ],
      "source": [
        "oof_cb  = np.zeros(len(X_tr), dtype=np.float32)\n",
        "test_cb = np.zeros(len(X_te), dtype=np.float32)\n",
        "models = {}\n",
        "\n",
        "for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
        "    Xtr, Xvl = X_tr.iloc[tr_idx], X_tr.iloc[vl_idx]\n",
        "    ytr, yvl = y_tr[tr_idx],     y_tr[vl_idx]\n",
        "\n",
        "    model_cb = CatBoostClassifier(\n",
        "        iterations=3000,\n",
        "        depth=10,\n",
        "        learning_rate=0.03,\n",
        "        l2_leaf_reg=12,\n",
        "        bagging_temperature=0.4,\n",
        "        auto_class_weights='Balanced',  # важный момент при 3.3% позитивов\n",
        "        eval_metric='AUC',\n",
        "        random_seed=42,\n",
        "        verbose=50,\n",
        "        early_stopping_rounds=200,\n",
        "\n",
        "    )\n",
        "    model_cb.fit(Xtr, ytr, eval_set=(Xvl, yvl), use_best_model=True)\n",
        "\n",
        "    models[fold] = model_cb\n",
        "    oof_cb[vl_idx] = model_cb.predict_proba(Xvl)[:, 1]\n",
        "    test_cb       += model_cb.predict_proba(X_te)[:, 1] / skf.n_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f3d5e22",
      "metadata": {
        "id": "8f3d5e22"
      },
      "outputs": [],
      "source": [
        "oof_cb_e  = np.zeros(len(X_tr), dtype=np.float32)\n",
        "for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
        "    Xtr, Xvl = X_tr.iloc[tr_idx], X_tr.iloc[vl_idx]\n",
        "    ytr, yvl = y_tr[tr_idx],     y_tr[vl_idx]\n",
        "\n",
        "    oof_cb_e[vl_idx] = models[fold].predict(Xvl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf74a15f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf74a15f",
        "outputId": "c50df3fb-6d4c-4837-cc59-5e46e69dfa75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost OOF AUC: 0.62969\n",
            "CatBoost OOF AUC: 0.09242\n"
          ]
        }
      ],
      "source": [
        "auc_cb = roc_auc_score(y_tr, oof_cb)\n",
        "f1_cb = f1_score(y_tr, oof_cb_e)\n",
        "print(f\"CatBoost OOF AUC: {auc_cb:.5f}\")\n",
        "print(f\"CatBoost OOF AUC: {f1_cb:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdcf0bdb",
      "metadata": {
        "id": "bdcf0bdb"
      },
      "source": [
        "#### Модель Лёгкая GRU на risk-последовательности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48859f32",
      "metadata": {
        "id": "48859f32"
      },
      "outputs": [],
      "source": [
        "class SeqDS(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = torch.from_numpy(X.astype(np.float32))\n",
        "        self.y = None if y is None else torch.from_numpy(y.astype(np.float32))\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i):\n",
        "        return (self.X[i], self.y[i]) if self.y is not None else self.X[i]\n",
        "\n",
        "class GRUSimple(nn.Module):\n",
        "    def __init__(self, hidden=64):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(input_size=1, hidden_size=hidden, num_layers=2, batch_first=True, dropout=0.1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(hidden, 64), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):            # x: [B, 25]\n",
        "        x = x.unsqueeze(-1)         # -> [B, 25, 1]\n",
        "        out, _ = self.gru(x)        # -> [B, 25, H]\n",
        "        feat = out[:, -1, :]        # берём последнее скрытое состояние\n",
        "        logit = self.head(feat)     # -> [B, 1]\n",
        "        return logit.squeeze(1)     # -> [B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97cb3e1e",
      "metadata": {
        "id": "97cb3e1e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_gru_oof(X, y, Xtest, folds, epochs=5, bs=8192, pos_weight=30.0, lr=2e-3):\n",
        "    oof = np.zeros(len(X), dtype=np.float32)\n",
        "    tpred = np.zeros(len(Xtest), dtype=np.float32)\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
        "        ds_tr = SeqDS(X[tr_idx], y[tr_idx])\n",
        "        ds_vl = SeqDS(X[vl_idx], y[vl_idx])\n",
        "        ds_te = SeqDS(Xtest, None)\n",
        "\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=bs, shuffle=True)\n",
        "        dl_vl = DataLoader(ds_vl, batch_size=bs, shuffle=False)\n",
        "        dl_te = DataLoader(ds_te, batch_size=bs, shuffle=False)\n",
        "\n",
        "        model = GRUSimple(hidden=64).to(DEVICE)\n",
        "        crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight, device=DEVICE))\n",
        "        opt  = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "        best_auc, best_state = -1, None\n",
        "        for ep in tqdm(range(epochs)):\n",
        "            # train\n",
        "            model.train()\n",
        "            for xb, yb in dl_tr:\n",
        "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                loss = crit(model(xb), yb)\n",
        "                loss.backward(); opt.step()\n",
        "            # valid\n",
        "            model.eval()\n",
        "            logits, yt = [], []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in dl_vl:\n",
        "                    xb = xb.to(DEVICE)\n",
        "                    lg = model(xb).detach().cpu().numpy()\n",
        "                    logits.append(lg); yt.append(yb.numpy())\n",
        "            p  = 1 / (1 + np.exp(-np.concatenate(logits)))\n",
        "            yt = np.concatenate(yt)\n",
        "            auc = roc_auc_score(yt, p)\n",
        "            print('auc: ', auc)\n",
        "            if auc > best_auc:\n",
        "                best_auc = auc\n",
        "                best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "        # restore best\n",
        "        model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()})\n",
        "        # OOF\n",
        "        model.eval()\n",
        "        logits=[]\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dl_vl:\n",
        "                xb = xb.to(DEVICE)\n",
        "                logits.append(model(xb).detach().cpu().numpy())\n",
        "        oof[vl_idx] = 1/(1+np.exp(-np.concatenate(logits)))\n",
        "        # test\n",
        "        logits=[]\n",
        "        with torch.no_grad():\n",
        "            for xb in dl_te:\n",
        "                xb = xb.to(DEVICE)\n",
        "                logits.append(model(xb).detach().cpu().numpy())\n",
        "        tpred += (1/(1+np.exp(-np.concatenate(logits)))) / len(folds)\n",
        "\n",
        "    return oof, tpred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e068cb9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e068cb9d",
        "outputId": "49b301ef-ef88-45dd-8b7d-68e4ba3bcea8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:20<03:01, 20.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5448132653868698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:39<02:38, 19.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5311316110345211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:00<02:20, 20.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5531873686131482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:19<01:59, 19.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5549074713817976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:39<01:39, 19.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5566238254904868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:59<01:19, 19.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5587478612305072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [02:19<00:59, 19.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5617406570542861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [02:39<00:39, 19.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5600456704489001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [02:58<00:19, 19.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5595705706117914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [03:18<00:00, 19.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5592571126289064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [00:20<03:01, 20.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5355539200738294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:39<02:37, 19.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5425713336778037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:59<02:19, 19.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5551699821933274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:19<01:58, 19.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5577740190749482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:38<01:38, 19.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5588613788486939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:58<01:19, 19.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5611135957843044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [02:18<00:59, 19.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5634886663695995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [02:38<00:39, 19.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5658665892577034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [02:57<00:19, 19.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5721471884376614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [03:18<00:00, 19.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5723954858553728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [00:20<03:02, 20.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5272246875430122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:39<02:36, 19.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.53367665841613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:59<02:18, 19.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.54992276604653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:18<01:58, 19.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5555955866038408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:38<01:38, 19.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5572265981943275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:58<01:19, 19.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5075715733212469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [02:17<00:58, 19.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5587356300833521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [02:37<00:39, 19.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5606500192080847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [02:56<00:19, 19.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.4404313642222964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [03:16<00:00, 19.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5594337451129523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [00:20<03:01, 20.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5249995947286259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:39<02:36, 19.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5352099607082692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:59<02:19, 19.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5543081676980742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:19<01:59, 19.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5582351207618965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:39<01:39, 19.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.559918974611463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:59<01:19, 19.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5602546196747361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [02:18<00:59, 19.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.562788147333708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [02:38<00:39, 19.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5638551708866413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [02:58<00:19, 19.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5661346008715407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [03:18<00:00, 19.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5678605082603955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [00:20<03:02, 20.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5405854232630216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:39<02:36, 19.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5538089903709853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:59<02:19, 19.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5575015978851395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:19<01:58, 19.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5607100572753552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:38<01:38, 19.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5621521457356247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:58<01:19, 19.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5659252425723955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [02:18<00:58, 19.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.42989065423264416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [02:38<00:39, 19.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.4321305830052229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [02:57<00:19, 19.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.5694318632324534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [03:17<00:00, 19.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc:  0.572552969934361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "oof_gru, test_gru = train_gru_oof(risk_seq_tr, y_tr, risk_seq_te, folds, epochs=10, bs=8192, pos_weight=30.0, lr=2e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b999437c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b999437c",
        "outputId": "038a493c-9d66-427a-d8b5-2c145b048e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRU OOF AUC: 0.51479\n"
          ]
        }
      ],
      "source": [
        "auc_gru = roc_auc_score(y_tr, oof_gru)\n",
        "print(f\"GRU OOF AUC: {auc_gru:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0289ce18",
      "metadata": {
        "id": "0289ce18"
      },
      "source": [
        "#### Бленд и подбор порога под F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf5bc632",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf5bc632",
        "outputId": "4f39ca99-cda7-44c0-e23e-b61e4e82f97f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OOF F1(best): 0.1093 @ threshold=0.558\n"
          ]
        }
      ],
      "source": [
        "oof_blend  = oof_cb.copy()\n",
        "test_blend = test_cb.copy()\n",
        "\n",
        "try:\n",
        "    oof_blend  = 0.6*oof_cb + 0.4*oof_gru\n",
        "    test_blend = 0.6*test_cb + 0.4*test_gru\n",
        "except NameError:\n",
        "    pass  # GRU не считали — используем только CatBoost\n",
        "\n",
        "best_t, best_f1 = 0.5, 0.0\n",
        "for t in np.linspace(0.01, 0.7, 40):\n",
        "    f1 = f1_score(y_tr, (oof_blend >= t).astype(int))\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_t = f1, t\n",
        "print(f\"OOF F1(best): {best_f1:.4f} @ threshold={best_t:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6AyH2t32LCbl",
      "metadata": {
        "id": "6AyH2t32LCbl"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "    'id': X_test['id'].values,\n",
        "    'flag': (test_blend >= best_t).astype(int)\n",
        "})\n",
        "submission.to_csv(\"submission_soq_final_blend.csv\", index=False)\n",
        "print(\"Saved: submission_soq_final_blend.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8fb556",
      "metadata": {},
      "source": [
        "## Много фичей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f36cfd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b3cac497",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\ttest: 0.5989733\tbest: 0.5989733 (0)\ttotal: 6.4s\tremaining: 4h 26m 39s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     10\u001b[39m ytr_, yvl_ = y_tr[tr_idx], y_tr[vl_idx]\n\u001b[32m     12\u001b[39m model_cb = CatBoostClassifier(\n\u001b[32m     13\u001b[39m     iterations=\u001b[32m2500\u001b[39m,\n\u001b[32m     14\u001b[39m     depth=\u001b[32m12\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     early_stopping_rounds=\u001b[32m200\u001b[39m\n\u001b[32m     23\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mmodel_cb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myvl_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m models[fold] = model_cb\n\u001b[32m     26\u001b[39m oof_cb[vl_idx] = model_cb.predict_proba(Xvl)[:, \u001b[32m1\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "import os, gc, math, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "oof_cb  = np.zeros(len(X_tr), dtype=np.float32)\n",
        "test_cb = np.zeros(len(X_te), dtype=np.float32)\n",
        "models = {}\n",
        "for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
        "    Xtr, Xvl = X_tr.iloc[tr_idx], X_tr.iloc[vl_idx]\n",
        "    ytr_, yvl_ = y_tr[tr_idx], y_tr[vl_idx]\n",
        "\n",
        "    model_cb = CatBoostClassifier(\n",
        "        iterations=2500,\n",
        "        depth=12,\n",
        "        learning_rate=0.04,\n",
        "        l2_leaf_reg=12,\n",
        "        bagging_temperature=0.5,\n",
        "        auto_class_weights='Balanced',\n",
        "        eval_metric='AUC',\n",
        "        random_seed=42,\n",
        "        verbose=20,\n",
        "        early_stopping_rounds=200\n",
        "    )\n",
        "    model_cb.fit(Xtr, ytr_, eval_set=(Xvl, yvl_), use_best_model=True)\n",
        "    models[fold] = model_cb\n",
        "    oof_cb[vl_idx] = model_cb.predict_proba(Xvl)[:, 1]\n",
        "    test_cb       += model_cb.predict_proba(X_te)[:, 1] / skf.n_splits\n",
        "\n",
        "auc_cb = roc_auc_score(y_tr, oof_cb)\n",
        "print(f\"CatBoost OOF AUC: {auc_cb:.5f}\")\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2749ee9",
      "metadata": {},
      "outputs": [],
      "source": [
        "f1 = pd.read_csv('models/features_1.csv')\n",
        "f2 = pd.read_csv('models/features_2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2c76253a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected features: 378\n"
          ]
        }
      ],
      "source": [
        "# 2) Нормализация и блендинг важностей\n",
        "def normalize_minmax(s):\n",
        "    s = s.astype(float); m, M = s.min(), s.max()\n",
        "    return (s - m) / (M - m + 1e-12) if M > m else s*0\n",
        "\n",
        "def normalize_l1(s):\n",
        "    s = s.astype(float).clip(lower=0); S = s.sum()\n",
        "    return s / S if S > 0 else s\n",
        "\n",
        "f1['imp_minmax'] = normalize_minmax(f1['importance'])\n",
        "f2['imp_minmax'] = normalize_minmax(f2['importance'])\n",
        "f1['imp_l1']     = normalize_l1(f1['importance'])\n",
        "f2['imp_l1']     = normalize_l1(f2['importance'])\n",
        "\n",
        "blend = f1.merge(f2[['feature','imp_minmax','imp_l1']], on='feature', how='outer', suffixes=('_1','_2')).fillna(0.0)\n",
        "# blended score = усреднение minmax и l1 между запусками\n",
        "blend['score'] = 0.5*(0.5*(blend['imp_minmax_1']+blend['imp_minmax_2']) + 0.5*(blend['imp_l1_1']+blend['imp_l1_2']))\n",
        "\n",
        "TOP_K = 400  # можно 300–600; 400 — хороший старт\n",
        "blend_sorted = blend.sort_values('score', ascending=False).reset_index(drop=True)\n",
        "top_features = blend_sorted.head(TOP_K)['feature'].tolist()\n",
        "\n",
        "# 3) Чистим мусор (Unnamed, id, явные дубликаты с суффиксами .1/.2 ...)\n",
        "def clean_feature_list(feats):\n",
        "    cleaned, seen = [], set()\n",
        "    for s in map(str, feats):\n",
        "        if s.lower().startswith('unnamed'): continue\n",
        "        if s == 'id' or s.startswith('id.'): continue\n",
        "        if s.endswith(('.1','.2','.3','.4')): continue\n",
        "        if s not in seen:\n",
        "            cleaned.append(s); seen.add(s)\n",
        "    return cleaned\n",
        "\n",
        "top_features_clean = clean_feature_list(top_features)\n",
        "print(\"Selected features:\", len(top_features_clean))\n",
        "# При использовании ОБЯЗАТЕЛЬНО пересечь со своими текущими колонками X_tr:\n",
        "# top_features_clean = [c for c in top_features_clean if c in X_tr.columns]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876efad6",
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'values'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_tr = \u001b[43my_tr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\n",
            "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ],
      "source": [
        "y_tr = y_tr.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "48018d7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.00001, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "39108323",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6065944\ttotal: 11s\tremaining: 40m 13s\n",
            "20:\tlearn: 0.6425812\ttotal: 3m 23s\tremaining: 32m 10s\n",
            "40:\tlearn: 0.6607436\ttotal: 6m 41s\tremaining: 29m 10s\n",
            "60:\tlearn: 0.6754747\ttotal: 9m 47s\tremaining: 25m 32s\n",
            "80:\tlearn: 0.6860088\ttotal: 13m\tremaining: 22m 19s\n",
            "100:\tlearn: 0.6926854\ttotal: 15m 53s\tremaining: 18m 43s\n",
            "120:\tlearn: 0.7033047\ttotal: 18m 52s\tremaining: 15m 26s\n",
            "140:\tlearn: 0.7120634\ttotal: 21m 58s\tremaining: 12m 18s\n",
            "160:\tlearn: 0.7189710\ttotal: 24m 56s\tremaining: 9m 8s\n",
            "180:\tlearn: 0.7273515\ttotal: 28m 2s\tremaining: 6m 2s\n",
            "200:\tlearn: 0.7338458\ttotal: 31m 7s\tremaining: 2m 56s\n",
            "219:\tlearn: 0.7407929\ttotal: 33m 52s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x2def1c27110>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "depth = 13\n",
        "model_p = CatBoostClassifier(\n",
        "    iterations=220,\n",
        "    depth=depth,\n",
        "    learning_rate=0.05,\n",
        "    l2_leaf_reg=13,\n",
        "    bagging_temperature=0.5,\n",
        "    auto_class_weights='Balanced',\n",
        "    eval_metric='Precision',  # Оптимизация по F1\n",
        "    random_seed=42,\n",
        "    verbose=20\n",
        ")\n",
        "\n",
        "# Обучение модели\n",
        "model_p.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "b2506986",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_p.save_model('models/model_5.cbm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "04604a91",
      "metadata": {},
      "outputs": [
        {
          "ename": "CatBoostError",
          "evalue": "There is no trained model to use predict(). Use fit() to train model. Then use this method.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mCatBoostError\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m evaluate_model(y_train, \u001b[43mmodel_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m, model_p.predict_proba(x_train)[:,\u001b[32m1\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\catboost\\core.py:5307\u001b[39m, in \u001b[36mCatBoostClassifier.predict\u001b[39m\u001b[34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[39m\n\u001b[32m   5250\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, prediction_type=\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m, ntree_start=\u001b[32m0\u001b[39m, ntree_end=\u001b[32m0\u001b[39m, thread_count=-\u001b[32m1\u001b[39m, verbose=\u001b[38;5;28;01mNone\u001b[39;00m, task_type=\u001b[33m\"\u001b[39m\u001b[33mCPU\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   5251\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5252\u001b[39m \u001b[33;03m    Predict with data.\u001b[39;00m\n\u001b[32m   5253\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5305\u001b[39m \u001b[33;03m              with log probability for every class for each object.\u001b[39;00m\n\u001b[32m   5306\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\catboost\\core.py:2620\u001b[39m, in \u001b[36mCatBoost._predict\u001b[39m\u001b[34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[39m\n\u001b[32m   2618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2619\u001b[39m     verbose = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2620\u001b[39m data, data_is_single_object = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_predict_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_method_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2621\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_prediction_type(prediction_type)\n\u001b[32m   2623\u001b[39m predictions = \u001b[38;5;28mself\u001b[39m._base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\catboost\\core.py:2596\u001b[39m, in \u001b[36mCatBoost._process_predict_input_data\u001b[39m\u001b[34m(self, data, parent_method_name, thread_count, label)\u001b[39m\n\u001b[32m   2594\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_predict_input_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, parent_method_name, thread_count, label=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2595\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fitted() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tree_count_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2596\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError((\u001b[33m\"\u001b[39m\u001b[33mThere is no trained model to use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m(). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2597\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33mUse fit() to train model. Then use this method.\u001b[39m\u001b[33m\"\u001b[39m).format(parent_method_name))\n\u001b[32m   2598\u001b[39m     is_single_object = _is_data_single_object(data)\n\u001b[32m   2599\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Pool):\n",
            "\u001b[31mCatBoostError\u001b[39m: There is no trained model to use predict(). Use fit() to train model. Then use this method."
          ]
        }
      ],
      "source": [
        "evaluate_model(y_train, model_p.predict(x_train), model_p.predict_proba(x_train)[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "3475d610",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>days_since_confirmed_risk</td>\n",
              "      <td>4.784701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>credit_limit_risk</td>\n",
              "      <td>3.071058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>full_credit_cost_risk</td>\n",
              "      <td>3.050712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sum_left_to_pay_risk</td>\n",
              "      <td>2.602537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>credit_type_te</td>\n",
              "      <td>2.498753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>maturity_fact_risk</td>\n",
              "      <td>2.133988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>credit_type</td>\n",
              "      <td>2.112325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>maturity_plan_risk</td>\n",
              "      <td>2.093736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>credit_number_for_user_risk</td>\n",
              "      <td>1.522420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>max_25</td>\n",
              "      <td>1.379320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>next_payment_sum_risk</td>\n",
              "      <td>0.958713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>credit_currency_te</td>\n",
              "      <td>0.716053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>full_credit_cost_ef_rate__m__sum_left_to_pay_p...</td>\n",
              "      <td>0.711971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>overdue_severity_score__d__maturity_ratio</td>\n",
              "      <td>0.667199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>full_credit_cost_ef_rate__d__next_payment_sum_...</td>\n",
              "      <td>0.652167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>sum_left_to_pay_progress__mx__next_payment_sum...</td>\n",
              "      <td>0.618419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>overdue_severity_score__d__next_payment_sum_ratio</td>\n",
              "      <td>0.602171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>max_overdue_debt_risk</td>\n",
              "      <td>0.588815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>weighted_status_score__x__full_credit_cost_ef_...</td>\n",
              "      <td>0.562623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>full_credit_cost_ef_rate__mx__next_payment_sum...</td>\n",
              "      <td>0.538074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>max_overdue_debt_ratio__mx__sum_left_to_pay_pr...</td>\n",
              "      <td>0.537758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>overdue_ratio__m__full_credit_cost_ef_rate</td>\n",
              "      <td>0.528405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>skew_25</td>\n",
              "      <td>0.520063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>overdue_ratio__d__has_clean_history</td>\n",
              "      <td>0.508085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>deterioration_count__d__maturity_ratio</td>\n",
              "      <td>0.506882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>std_25</td>\n",
              "      <td>0.499456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>std_6</td>\n",
              "      <td>0.494405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>q50_6</td>\n",
              "      <td>0.482337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>overdue_ratio__d__full_credit_cost_ef_rate</td>\n",
              "      <td>0.472172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>maturity_ratio__x__max_overdue_debt_ratio</td>\n",
              "      <td>0.468376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>maturity_ratio__mn__next_payment_sum_ratio</td>\n",
              "      <td>0.467295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>full_credit_cost_ef_rate__d__sum_left_to_pay_p...</td>\n",
              "      <td>0.462657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>weighted_status_score__x__maturity_ratio</td>\n",
              "      <td>0.461422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>maturity_ratio__d__next_payment_sum_ratio</td>\n",
              "      <td>0.460995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>max_overdue_debt_ratio__d__sum_left_to_pay_pro...</td>\n",
              "      <td>0.456299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>overdue_severity_score__d__full_credit_cost_ef...</td>\n",
              "      <td>0.443512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>q10_3</td>\n",
              "      <td>0.443239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>overdue_severity_score__x__overdue_ratio</td>\n",
              "      <td>0.441854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>weighted_status_score__d__deterioration_count</td>\n",
              "      <td>0.440564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>has_clean_history__mx__full_credit_cost_ef_rate</td>\n",
              "      <td>0.438812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>q90_6</td>\n",
              "      <td>0.438395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>deterioration_count__m__maturity_ratio</td>\n",
              "      <td>0.431554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>overdue_ratio__mn__full_credit_cost_ef_rate</td>\n",
              "      <td>0.427995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>has_clean_history__x__next_payment_sum_ratio</td>\n",
              "      <td>0.426395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>max_overdue_debt_ratio__mn__sum_left_to_pay_pr...</td>\n",
              "      <td>0.416297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>q90_25</td>\n",
              "      <td>0.415097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>has_clean_history__mn__max_overdue_debt_ratio</td>\n",
              "      <td>0.414411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>deterioration_count__mn__maturity_ratio</td>\n",
              "      <td>0.414228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>overdue_ratio__mx__next_payment_sum_ratio</td>\n",
              "      <td>0.413745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>overdue_ratio__m__next_payment_sum_ratio</td>\n",
              "      <td>0.410448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               feature  importance\n",
              "0                            days_since_confirmed_risk    4.784701\n",
              "1                                    credit_limit_risk    3.071058\n",
              "2                                full_credit_cost_risk    3.050712\n",
              "3                                 sum_left_to_pay_risk    2.602537\n",
              "5                                       credit_type_te    2.498753\n",
              "4                                   maturity_fact_risk    2.133988\n",
              "7                                          credit_type    2.112325\n",
              "6                                   maturity_plan_risk    2.093736\n",
              "31                         credit_number_for_user_risk    1.522420\n",
              "8                                               max_25    1.379320\n",
              "11                               next_payment_sum_risk    0.958713\n",
              "35                                  credit_currency_te    0.716053\n",
              "46   full_credit_cost_ef_rate__m__sum_left_to_pay_p...    0.711971\n",
              "276          overdue_severity_score__d__maturity_ratio    0.667199\n",
              "117  full_credit_cost_ef_rate__d__next_payment_sum_...    0.652167\n",
              "16   sum_left_to_pay_progress__mx__next_payment_sum...    0.618419\n",
              "102  overdue_severity_score__d__next_payment_sum_ratio    0.602171\n",
              "103                              max_overdue_debt_risk    0.588815\n",
              "291  weighted_status_score__x__full_credit_cost_ef_...    0.562623\n",
              "192  full_credit_cost_ef_rate__mx__next_payment_sum...    0.538074\n",
              "150  max_overdue_debt_ratio__mx__sum_left_to_pay_pr...    0.537758\n",
              "356         overdue_ratio__m__full_credit_cost_ef_rate    0.528405\n",
              "264                                            skew_25    0.520063\n",
              "36                 overdue_ratio__d__has_clean_history    0.508085\n",
              "26              deterioration_count__d__maturity_ratio    0.506882\n",
              "9                                               std_25    0.499456\n",
              "203                                              std_6    0.494405\n",
              "55                                               q50_6    0.482337\n",
              "21          overdue_ratio__d__full_credit_cost_ef_rate    0.472172\n",
              "51           maturity_ratio__x__max_overdue_debt_ratio    0.468376\n",
              "67          maturity_ratio__mn__next_payment_sum_ratio    0.467295\n",
              "113  full_credit_cost_ef_rate__d__sum_left_to_pay_p...    0.462657\n",
              "98            weighted_status_score__x__maturity_ratio    0.461422\n",
              "47           maturity_ratio__d__next_payment_sum_ratio    0.460995\n",
              "10   max_overdue_debt_ratio__d__sum_left_to_pay_pro...    0.456299\n",
              "236  overdue_severity_score__d__full_credit_cost_ef...    0.443512\n",
              "314                                              q10_3    0.443239\n",
              "19            overdue_severity_score__x__overdue_ratio    0.441854\n",
              "123      weighted_status_score__d__deterioration_count    0.440564\n",
              "70     has_clean_history__mx__full_credit_cost_ef_rate    0.438812\n",
              "146                                              q90_6    0.438395\n",
              "211             deterioration_count__m__maturity_ratio    0.431554\n",
              "33         overdue_ratio__mn__full_credit_cost_ef_rate    0.427995\n",
              "49        has_clean_history__x__next_payment_sum_ratio    0.426395\n",
              "14   max_overdue_debt_ratio__mn__sum_left_to_pay_pr...    0.416297\n",
              "85                                              q90_25    0.415097\n",
              "296      has_clean_history__mn__max_overdue_debt_ratio    0.414411\n",
              "44             deterioration_count__mn__maturity_ratio    0.414228\n",
              "195          overdue_ratio__mx__next_payment_sum_ratio    0.413745\n",
              "338           overdue_ratio__m__next_payment_sum_ratio    0.410448"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_imp = pd.DataFrame({\n",
        "        'feature': x_train.columns,\n",
        "        'importance': model_p.feature_importances_\n",
        "    }).sort_values('importance', key=abs, ascending=False)\n",
        "feature_imp[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb7c575",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CatBoostClassifier().load_model('catboost_model.cbm')\n",
        "model.load_model('catboost_model.cbm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "686e5df6",
      "metadata": {},
      "outputs": [],
      "source": [
        "oof_blend = model_p.predict_proba(x_train)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "d344de7f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True, False,  True], shape=(1827385,))"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oof_blend >= t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "28309f08",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OOF F1(best): 0.2412 @ threshold=0.631\n"
          ]
        }
      ],
      "source": [
        "best_t, best_f1 = 0.5, 0.0\n",
        "for t in np.linspace(0.01, 0.8, 99):\n",
        "    f1 = f1_score(y_train, (oof_blend >= t).astype(int))\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_t = f1, t\n",
        "print(f\"OOF F1(best): {best_f1:.4f} @ threshold={best_t:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "bf77d75d",
      "metadata": {},
      "outputs": [],
      "source": [
        "baza = (model_p.predict_proba(X_te)[:,1] >=0.623).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "e07d2a20",
      "metadata": {},
      "outputs": [],
      "source": [
        "g = pd.read_csv('submission_soq_final_blend.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "e28094f6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8547827341294307)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roc_auc_score(g['flag'], baza)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "0fed7592",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>days_since_confirmed_risk</th>\n",
              "      <th>credit_limit_risk</th>\n",
              "      <th>full_credit_cost_risk</th>\n",
              "      <th>sum_left_to_pay_risk</th>\n",
              "      <th>maturity_fact_risk</th>\n",
              "      <th>credit_type_te</th>\n",
              "      <th>maturity_plan_risk</th>\n",
              "      <th>credit_type</th>\n",
              "      <th>max_25</th>\n",
              "      <th>std_25</th>\n",
              "      <th>...</th>\n",
              "      <th>deterioration_count</th>\n",
              "      <th>overdue_severity_score__mx__maturity_ratio</th>\n",
              "      <th>deterioration_count__d__has_clean_history</th>\n",
              "      <th>h12_16</th>\n",
              "      <th>h12_15</th>\n",
              "      <th>h12_14</th>\n",
              "      <th>h12_13</th>\n",
              "      <th>h25_6</th>\n",
              "      <th>h25_7</th>\n",
              "      <th>h25_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>268646</th>\n",
              "      <td>0.028799</td>\n",
              "      <td>0.022817</td>\n",
              "      <td>0.024520</td>\n",
              "      <td>0.033441</td>\n",
              "      <td>0.031848</td>\n",
              "      <td>0.031867</td>\n",
              "      <td>0.032476</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.035877</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1075397</th>\n",
              "      <td>0.034983</td>\n",
              "      <td>0.033305</td>\n",
              "      <td>0.025237</td>\n",
              "      <td>0.031667</td>\n",
              "      <td>0.030653</td>\n",
              "      <td>0.031396</td>\n",
              "      <td>0.030285</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.046564</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833234</th>\n",
              "      <td>0.037793</td>\n",
              "      <td>0.035948</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.038332</td>\n",
              "      <td>0.034675</td>\n",
              "      <td>0.031916</td>\n",
              "      <td>0.031658</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.048503</td>\n",
              "      <td>0.004062</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238404</th>\n",
              "      <td>0.035731</td>\n",
              "      <td>0.035327</td>\n",
              "      <td>0.029981</td>\n",
              "      <td>0.031592</td>\n",
              "      <td>0.031765</td>\n",
              "      <td>0.031867</td>\n",
              "      <td>0.030992</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.043483</td>\n",
              "      <td>0.003036</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724757</th>\n",
              "      <td>0.037409</td>\n",
              "      <td>0.033130</td>\n",
              "      <td>0.029329</td>\n",
              "      <td>0.031562</td>\n",
              "      <td>0.039055</td>\n",
              "      <td>0.031380</td>\n",
              "      <td>0.025411</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.048503</td>\n",
              "      <td>0.004062</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719040</th>\n",
              "      <td>0.036269</td>\n",
              "      <td>0.022919</td>\n",
              "      <td>0.025238</td>\n",
              "      <td>0.033156</td>\n",
              "      <td>0.034640</td>\n",
              "      <td>0.019914</td>\n",
              "      <td>0.024937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034098</td>\n",
              "      <td>0.001811</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1636739</th>\n",
              "      <td>0.037744</td>\n",
              "      <td>0.034624</td>\n",
              "      <td>0.033788</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>0.029812</td>\n",
              "      <td>0.031518</td>\n",
              "      <td>0.024937</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.031210</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719281</th>\n",
              "      <td>0.034821</td>\n",
              "      <td>0.022919</td>\n",
              "      <td>0.030317</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>0.039202</td>\n",
              "      <td>0.021153</td>\n",
              "      <td>0.035653</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.034886</td>\n",
              "      <td>0.002766</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556439</th>\n",
              "      <td>0.026359</td>\n",
              "      <td>0.033203</td>\n",
              "      <td>0.025398</td>\n",
              "      <td>0.031592</td>\n",
              "      <td>0.029112</td>\n",
              "      <td>0.031867</td>\n",
              "      <td>0.030261</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.035486</td>\n",
              "      <td>0.002737</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294564</th>\n",
              "      <td>0.036577</td>\n",
              "      <td>0.022919</td>\n",
              "      <td>0.025571</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>0.031726</td>\n",
              "      <td>0.019914</td>\n",
              "      <td>0.032202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031210</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91371 rows × 378 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         days_since_confirmed_risk  credit_limit_risk  full_credit_cost_risk  \\\n",
              "268646                    0.028799           0.022817               0.024520   \n",
              "1075397                   0.034983           0.033305               0.025237   \n",
              "833234                    0.037793           0.035948               0.034146   \n",
              "238404                    0.035731           0.035327               0.029981   \n",
              "1724757                   0.037409           0.033130               0.029329   \n",
              "...                            ...                ...                    ...   \n",
              "1719040                   0.036269           0.022919               0.025238   \n",
              "1636739                   0.037744           0.034624               0.033788   \n",
              "1719281                   0.034821           0.022919               0.030317   \n",
              "556439                    0.026359           0.033203               0.025398   \n",
              "294564                    0.036577           0.022919               0.025571   \n",
              "\n",
              "         sum_left_to_pay_risk  maturity_fact_risk  credit_type_te  \\\n",
              "268646               0.033441            0.031848        0.031867   \n",
              "1075397              0.031667            0.030653        0.031396   \n",
              "833234               0.038332            0.034675        0.031916   \n",
              "238404               0.031592            0.031765        0.031867   \n",
              "1724757              0.031562            0.039055        0.031380   \n",
              "...                       ...                 ...             ...   \n",
              "1719040              0.033156            0.034640        0.019914   \n",
              "1636739              0.031600            0.029812        0.031518   \n",
              "1719281              0.031600            0.039202        0.021153   \n",
              "556439               0.031592            0.029112        0.031867   \n",
              "294564               0.031600            0.031726        0.019914   \n",
              "\n",
              "         maturity_plan_risk  credit_type    max_25    std_25  ...  \\\n",
              "268646             0.032476          4.0  0.035877  0.002728  ...   \n",
              "1075397            0.030285          7.0  0.046564  0.003921  ...   \n",
              "833234             0.031658          4.0  0.048503  0.004062  ...   \n",
              "238404             0.030992          4.0  0.043483  0.003036  ...   \n",
              "1724757            0.025411          3.0  0.048503  0.004062  ...   \n",
              "...                     ...          ...       ...       ...  ...   \n",
              "1719040            0.024937          0.0  0.034098  0.001811  ...   \n",
              "1636739            0.024937          3.0  0.031210  0.001032  ...   \n",
              "1719281            0.035653          2.0  0.034886  0.002766  ...   \n",
              "556439             0.030261          4.0  0.035486  0.002737  ...   \n",
              "294564             0.032202          0.0  0.031210  0.001032  ...   \n",
              "\n",
              "         deterioration_count  overdue_severity_score__mx__maturity_ratio  \\\n",
              "268646                   1.0                                       162.0   \n",
              "1075397                  1.0                                       162.0   \n",
              "833234                   1.0                                       162.0   \n",
              "238404                   1.0                                       162.0   \n",
              "1724757                  1.0                                       162.0   \n",
              "...                      ...                                         ...   \n",
              "1719040                  1.0                                       162.0   \n",
              "1636739                  0.0                                       162.0   \n",
              "1719281                  1.0                                       162.0   \n",
              "556439                   1.0                                       162.0   \n",
              "294564                   0.0                                       162.0   \n",
              "\n",
              "         deterioration_count__d__has_clean_history  h12_16  h12_15  h12_14  \\\n",
              "268646                                         1.0     0.0     0.0     0.0   \n",
              "1075397                                        0.0     0.0     0.0     0.0   \n",
              "833234                                         1.0     0.0     0.0     0.0   \n",
              "238404                                         1.0     0.0     0.0     0.0   \n",
              "1724757                                        1.0     0.0     0.0     0.0   \n",
              "...                                            ...     ...     ...     ...   \n",
              "1719040                                        1.0     0.0     0.0     0.0   \n",
              "1636739                                        0.0     0.0     0.0     0.0   \n",
              "1719281                                        1.0     0.0     0.0     0.0   \n",
              "556439                                         1.0     0.0     0.0     0.0   \n",
              "294564                                         0.0     0.0     0.0     0.0   \n",
              "\n",
              "         h12_13  h25_6  h25_7  h25_8  \n",
              "268646      0.0    0.0    0.0    0.0  \n",
              "1075397     0.0    0.0    0.0    0.0  \n",
              "833234      0.0    0.0    0.0    0.0  \n",
              "238404      0.0    0.0    0.0    0.0  \n",
              "1724757     0.0    0.0    0.0    0.0  \n",
              "...         ...    ...    ...    ...  \n",
              "1719040     0.0    0.0    0.0    0.0  \n",
              "1636739     0.0    0.0    0.0    0.0  \n",
              "1719281     0.0    0.0    0.0    0.0  \n",
              "556439      0.0    0.0    0.0    0.0  \n",
              "294564      0.0    0.0    0.0    0.0  \n",
              "\n",
              "[91371 rows x 378 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b844a301",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "МЕТРИКИ КАЧЕСТВА МОДЕЛИ\n",
            "==================================================\n",
            "Accuracy:  0.7488\n",
            "Precision: 0.0826\n",
            "Recall:    0.6584\n",
            "F1-score:  0.1468\n",
            "ROC-AUC:   0.7857\n",
            "Avg Precision: 0.1418\n",
            "\n",
            "------------------------------\n",
            "MATRIXA SOWMESHENIY (CONFUSION MATRIX)\n",
            "------------------------------\n",
            "True Negative (TN):  1262375\n",
            "False Positive (FP): 416679\n",
            "False Negative (FN): 19464\n",
            "True Positive (TP):  37515\n",
            "\n",
            "Матрица в виде таблицы:\n",
            "[[TN 1262375   FP 416679]\n",
            " [FN 19464   TP 37515]]\n",
            "\n",
            "Specificity (TNR): 0.7518\n",
            "False Positive Rate (FPR): 0.2482\n",
            "False Negative Rate (FNR): 0.3416\n",
            "\n",
            "------------------------------\n",
            "DETALNY OTCHET (CLASSIFICATION REPORT)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.98      0.75      0.85   1679054\n",
            "     Class 1       0.08      0.66      0.15     56979\n",
            "\n",
            "    accuracy                           0.75   1736033\n",
            "   macro avg       0.53      0.71      0.50   1736033\n",
            "weighted avg       0.96      0.75      0.83   1736033\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.7487703286746278,\n",
              " 'precision': 0.08259686389516374,\n",
              " 'recall': 0.6584004633285947,\n",
              " 'f1': 0.14678005293706828,\n",
              " 'roc_auc': np.float64(0.7857371198737821),\n",
              " 'confusion_matrix': array([[1262375,  416679],\n",
              "        [  19464,   37515]]),\n",
              " 'tn': np.int64(1262375),\n",
              " 'fp': np.int64(416679),\n",
              " 'fn': np.int64(19464),\n",
              " 'tp': np.int64(37515)}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model(y_train, model_p.predict(x_train), model_p.predict_proba(x_train)[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f47aa504",
      "metadata": {},
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 4.50 GiB for an array with shape (441, 1370553) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      6\u001b[39m lgb_params = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m      7\u001b[39m     objective=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     metric=\u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     seed=\u001b[32m42\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold, (tr_idx, vl_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(folds, \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     Xtr, Xvl = \u001b[43mX_tr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr_idx\u001b[49m\u001b[43m]\u001b[49m, X_tr.iloc[vl_idx]\n\u001b[32m     26\u001b[39m     ytr_, yvl_ = y_tr[tr_idx], y_tr[vl_idx]\n\u001b[32m     28\u001b[39m     dtr = lgb.Dataset(Xtr, label=ytr_)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\indexing.py:1743\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1747\u001b[39m     key = item_from_zerodim(key)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\indexing.py:1714\u001b[39m, in \u001b[36m_iLocIndexer._get_list_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1697\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[33;03mReturn Series values by list or array of integers.\u001b[39;00m\n\u001b[32m   1699\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1711\u001b[39m \u001b[33;03m`axis` can only be zero.\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[32m   1717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpositional indexers are out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[39m, in \u001b[36mNDFrame._take_with_is_copy\u001b[39m\u001b[34m(self, indices, axis)\u001b[39m\n\u001b[32m   4142\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   4143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis = \u001b[32m0\u001b[39m) -> Self:\n\u001b[32m   4144\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4145\u001b[39m \u001b[33;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[32m   4146\u001b[39m \u001b[33;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4151\u001b[39m \u001b[33;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[32m   4152\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4153\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4154\u001b[39m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[32m   4155\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result._get_axis(axis).equals(\u001b[38;5;28mself\u001b[39m._get_axis(axis)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4128\u001b[39m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[32m   4129\u001b[39m     indices = np.arange(\n\u001b[32m   4130\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4131\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4133\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4135\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4139\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4140\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    891\u001b[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001b[32m    893\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     new_blocks = \u001b[43m[\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    687\u001b[39m     new_blocks = [\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    696\u001b[39m     ]\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1304\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1306\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1312\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1314\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1315\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    155\u001b[39m     out = np.empty(out_shape, dtype=dtype, order=\u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     out = np.empty(out_shape, dtype=dtype)\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m    162\u001b[39m func(arr, indexer, out, fill_value)\n",
            "\u001b[31mMemoryError\u001b[39m: Unable to allocate 4.50 GiB for an array with shape (441, 1370553) and data type float64"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "oof_lgb  = np.zeros(len(X_tr), dtype=np.float32)\n",
        "test_lgb = np.zeros(len(X_te), dtype=np.float32)\n",
        "\n",
        "lgb_params = dict(\n",
        "    objective='binary',\n",
        "    metric='auc',\n",
        "    boosting_type='gbdt',\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=255,\n",
        "    max_depth=-1,\n",
        "    min_data_in_leaf=50,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    bagging_freq=1,\n",
        "    lambda_l1=0.0,\n",
        "    lambda_l2=1.0,\n",
        "    scale_pos_weight=( (y_tr==0).sum() / max(1,(y_tr==1).sum()) ),  # ~30\n",
        "    verbose=-1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "for fold, (tr_idx, vl_idx) in enumerate(folds, 1):\n",
        "    Xtr, Xvl = X_tr.iloc[tr_idx], X_tr.iloc[vl_idx]\n",
        "    ytr_, yvl_ = y_tr[tr_idx], y_tr[vl_idx]\n",
        "\n",
        "    dtr = lgb.Dataset(Xtr, label=ytr_)\n",
        "    dvl = lgb.Dataset(Xvl, label=yvl_, reference=dtr)\n",
        "\n",
        "    model_lgb = lgb.train(\n",
        "        lgb_params, dtr,\n",
        "        num_boost_round=8000,\n",
        "        valid_sets=[dtr, dvl],\n",
        "        valid_names=['train','valid'],\n",
        "        verbose_eval=20\n",
        "    )\n",
        "    oof_lgb[vl_idx] = model_lgb.predict(Xvl, num_iteration=model_lgb.best_iteration)\n",
        "    test_lgb       += model_lgb.predict(X_te, num_iteration=model_lgb.best_iteration) / skf.n_splits\n",
        "\n",
        "auc_lgb = roc_auc_score(y_tr, oof_lgb)\n",
        "print(f\"LightGBM OOF AUC: {auc_lgb:.5f}\")\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "e76a52e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "del target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e29c1c2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d074b489",
      "metadata": {},
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 2.85 GiB for an array with shape (441, 1736033) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x_tr, x_val, y_tr_, y_val_ = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Очищаем названия признаков от специальных символов\u001b[39;00m\n\u001b[32m      4\u001b[39m x_tr_clean = x_tr\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2876\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2872\u001b[39m     train, test = \u001b[38;5;28mnext\u001b[39m(cv.split(X=arrays[\u001b[32m0\u001b[39m], y=stratify))\n\u001b[32m   2874\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m-> \u001b[39m\u001b[32m2876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2877\u001b[39m     chain.from_iterable(\n\u001b[32m   2878\u001b[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2879\u001b[39m     )\n\u001b[32m   2880\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2878\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   2872\u001b[39m     train, test = \u001b[38;5;28mnext\u001b[39m(cv.split(X=arrays[\u001b[32m0\u001b[39m], y=stratify))\n\u001b[32m   2874\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m   2876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2877\u001b[39m     chain.from_iterable(\n\u001b[32m-> \u001b[39m\u001b[32m2878\u001b[39m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2879\u001b[39m     )\n\u001b[32m   2880\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:266\u001b[39m, in \u001b[36m_safe_indexing\u001b[39m\u001b[34m(X, indices, axis)\u001b[39m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    260\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    261\u001b[39m     )\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33miloc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# TODO: we should probably use _is_pandas_df_or_series(X) instead but this\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;66;03m# would require updating some tests such as test_train_test_split_mock_pandas.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pandas_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_polars_df_or_series(X):\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis=axis)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:47\u001b[39m, in \u001b[36m_pandas_indexing\u001b[39m\u001b[34m(X, key, key_dtype, axis)\u001b[39m\n\u001b[32m     42\u001b[39m     key = np.asarray(key)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key_dtype == \u001b[33m\"\u001b[39m\u001b[33mint\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m np.isscalar(key)):\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# using take() instead of iloc[] ensures the return value is a \"proper\"\u001b[39;00m\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# copy that will not raise SettingWithCopyWarning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[32m     50\u001b[39m     indexer = X.iloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype == \u001b[33m\"\u001b[39m\u001b[33mint\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X.loc\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4128\u001b[39m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[32m   4129\u001b[39m     indices = np.arange(\n\u001b[32m   4130\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4131\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4133\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4135\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4139\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4140\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    891\u001b[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001b[32m    893\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     new_blocks = \u001b[43m[\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    687\u001b[39m     new_blocks = [\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    696\u001b[39m     ]\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1304\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1306\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1312\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1314\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1315\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\work\\programs\\lang\\python\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    155\u001b[39m     out = np.empty(out_shape, dtype=dtype, order=\u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     out = np.empty(out_shape, dtype=dtype)\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m    162\u001b[39m func(arr, indexer, out, fill_value)\n",
            "\u001b[31mMemoryError\u001b[39m: Unable to allocate 2.85 GiB for an array with shape (441, 1736033) and data type float32"
          ]
        }
      ],
      "source": [
        "x_tr, x_val, y_tr_, y_val_ = train_test_split(X_tr, y_tr, test_size=0.05, stratify=y_tr)\n",
        "\n",
        "# Очищаем названия признаков от специальных символов\n",
        "x_tr_clean = x_tr\n",
        "x_val_clean = x_val\n",
        "\n",
        "if hasattr(x_tr, 'columns'):\n",
        "    x_tr.columns = [str(col).replace('\"', '').replace(\"'\", \"\").replace(\"{\", \"\").replace(\"}\", \"\").replace(\"[\", \"\").replace(\"]\", \"\") \n",
        "                         for col in x_tr.columns]\n",
        "    x_val.columns = [str(col).replace('\"', '').replace(\"'\", \"\").replace(\"{\", \"\").replace(\"}\", \"\").replace(\"[\", \"\").replace(\"]\", \"\") \n",
        "                          for col in x_val.columns]\n",
        "\n",
        "# Создаем датасеты с очищенными признаками\n",
        "train_data = lgb.Dataset(x_tr, label=y_tr_)\n",
        "valid_data = lgb.Dataset(x_val, label=y_val_, reference=train_data)\n",
        "\n",
        "# Параметры\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'learning_rate': 0.1,\n",
        "    'num_leaves': 255,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 1,\n",
        "    'min_data_in_leaf': 50,\n",
        "    'lambda_l2': 1.0,\n",
        "    'scale_pos_weight': (y_tr == 0).sum() / max(1, (y_tr == 1).sum()),\n",
        "    'seed': 42,\n",
        "    'verbosity': 2\n",
        "}\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    lgb.early_stopping(stopping_rounds=30),\n",
        "    lgb.log_evaluation(period=200)\n",
        "]\n",
        "\n",
        "# Обучение\n",
        "model_ligh = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=4000,\n",
        "    valid_sets=[train_data, valid_data],\n",
        "    valid_names=['train', 'valid'],\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cef4217",
      "metadata": {},
      "outputs": [],
      "source": [
        "imp_gain = pd.Series(model_ligh.feature_importance(importance_type='gain'),\n",
        "                        index=x_tr.columns, name=f'lgb_imp_seed{42}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "2a25236a",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model_li, ip_g = \u001b[43mtrain_lgb_and_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_lgb_and_importance\u001b[39m\u001b[34m(X, y, seed, categorical_cols)\u001b[39m\n\u001b[32m      5\u001b[39m dvl = lgb.Dataset(x_val, label=y_val_, reference=dtr, categorical_feature=categorical_cols)\n\u001b[32m      7\u001b[39m params = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m      8\u001b[39m     objective=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     metric=\u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     verbose=-\u001b[32m1\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdvl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m imp_gain = pd.Series(model.feature_importance(importance_type=\u001b[33m'\u001b[39m\u001b[33mgain\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     32\u001b[39m                      index=x_tr.columns, name=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlgb_imp_seed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, imp_gain\n",
            "\u001b[31mTypeError\u001b[39m: train() got an unexpected keyword argument 'early_stopping_rounds'"
          ]
        }
      ],
      "source": [
        "model_li, ip_g = train_lgb_and_importance(X_tr, y_tr, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a2dabc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# делим полный train на train/val для скорой оценки и тюнинга порога\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    X_tr_sel, y_tr, test_size=0.15, random_state=RANDOM_STATE, stratify=y_tr\n",
        ")\n",
        "\n",
        "# --- CatBoost финальный ---\n",
        "final_cb = CatBoostClassifier(\n",
        "    iterations=3000,\n",
        "    depth=8,\n",
        "    learning_rate=0.04,\n",
        "    l2_leaf_reg=12,\n",
        "    bagging_temperature=0.5,\n",
        "    auto_class_weights='Balanced',\n",
        "    eval_metric='AUC',\n",
        "    random_seed=RANDOM_STATE,\n",
        "    verbose=200,\n",
        "    early_stopping_rounds=200\n",
        ")\n",
        "final_cb.fit(x_train, y_train, eval_set=(x_val, y_val), use_best_model=True, cat_features=[c for c in present_cats if c in X_tr_sel.columns])\n",
        "\n",
        "val_cb_proba = final_cb.predict_proba(x_val)[:,1]\n",
        "\n",
        "# --- LightGBM финальный ---\n",
        "dtr_f = lgb.Dataset(x_train, label=y_train, categorical_feature=[c for c in present_cats if c in X_tr_sel.columns])\n",
        "dvl_f = lgb.Dataset(x_val, label=y_val, reference=dtr_f, categorical_feature=[c for c in present_cats if c in X_tr_sel.columns])\n",
        "\n",
        "params_f = dict(\n",
        "    objective='binary', metric='auc',\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=255, feature_fraction=0.8, bagging_fraction=0.8, bagging_freq=1,\n",
        "    min_data_in_leaf=50, lambda_l2=1.0,\n",
        "    scale_pos_weight=((y_tr==0).sum()/max(1,(y_tr==1).sum())),\n",
        "    seed=RANDOM_STATE, verbose=-1\n",
        ")\n",
        "final_lgb = lgb.train(\n",
        "    params_f, dtr_f,\n",
        "    num_boost_round=8000,\n",
        "    valid_sets=[dtr_f, dvl_f],\n",
        "    early_stopping_rounds=300,\n",
        "    verbose_eval=200\n",
        ")\n",
        "val_lgb_proba = final_lgb.predict(x_val, num_iteration=final_lgb.best_iteration)\n",
        "\n",
        "# сохраним финальные модели\n",
        "final_cb.save_model(\"final_cb_topk.cbm\")\n",
        "final_lgb.save_model(\"final_lgb_topk.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4c69e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# стек из двух вероятностей\n",
        "val_stack = np.vstack([val_cb_proba, val_lgb_proba]).T\n",
        "meta = LogisticRegression(\n",
        "    penalty='l2', C=1.0, solver='lbfgs', max_iter=2000,\n",
        "    class_weight={0:1.0, 1: ((y_tr==0).sum()/max(1,(y_tr==1).sum()))}\n",
        ")\n",
        "meta.fit(val_stack, y_val)\n",
        "val_meta = meta.predict_proba(val_stack)[:,1]\n",
        "\n",
        "# тюнинг порога под F1\n",
        "best_t, best_f1 = 0.5, 0.0\n",
        "for t in np.linspace(0.01, 0.6, 60):\n",
        "    f1 = f1_score(y_val, (val_meta>=t).astype(int))\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_t = f1, t\n",
        "\n",
        "auc_cb  = roc_auc_score(y_val, val_cb_proba)\n",
        "auc_lgb = roc_auc_score(y_val, val_lgb_proba)\n",
        "auc_meta= roc_auc_score(y_val, val_meta)\n",
        "\n",
        "print(f\"Val AUC: CB={auc_cb:.4f} | LGB={auc_lgb:.4f} | STACK={auc_meta:.4f}\")\n",
        "print(f\"Val F1(best threshold): {best_f1:.4f} @ thr={best_t:.3f}\")\n",
        "\n",
        "# инференс на тесте\n",
        "test_cb_proba  = final_cb.predict_proba(X_te_sel)[:,1]\n",
        "test_lgb_proba = final_lgb.predict(X_te_sel, num_iteration=final_lgb.best_iteration)\n",
        "test_stack = np.vstack([test_cb_proba, test_lgb_proba]).T\n",
        "test_meta = meta.predict_proba(test_stack)[:,1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': X_test['id'],\n",
        "    'flag': (test_meta >= best_t).astype(int)\n",
        "})\n",
        "submission.to_csv(\"submission_topk_stack.csv\", index=False)\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54cc0647",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Собираем стек-фичи из OOF предсказаний базовых моделей\n",
        "stack_tr = np.vstack([oof_cb, oof_lgb]).T  # [N, 2]\n",
        "stack_te = np.vstack([test_cb, test_lgb]).T\n",
        "\n",
        "# 2) Логрег как мета-модель (учим на OOF → безопасно; на тест — применяем сразу)\n",
        "meta = LogisticRegression(\n",
        "    penalty='l2', C=1.0,\n",
        "    solver='lbfgs',\n",
        "    max_iter=1000,\n",
        "    class_weight={0:1.0, 1: ( (y_tr==0).sum()/max(1,(y_tr==1).sum()) )}  # сбалансировать\n",
        ")\n",
        "meta.fit(stack_tr, y_tr)\n",
        "oof_meta  = meta.predict_proba(stack_tr)[:,1]\n",
        "test_meta = meta.predict_proba(stack_te)[:,1]\n",
        "\n",
        "# 3) Тюним порог по F1 на OOF\n",
        "best_t, best_f1 = 0.5, 0.0\n",
        "for t in np.linspace(0.01, 0.7, 60):\n",
        "    f1 = f1_score(y_tr, (oof_meta>=t).astype(int))\n",
        "    if f1 > best_f1: best_f1, best_t = f1, t\n",
        "\n",
        "auc_meta = roc_auc_score(y_tr, oof_meta)\n",
        "print(f\"STACK OOF AUC: {auc_meta:.5f}\")\n",
        "print(f\"OOF F1(best): {best_f1:.5f} @ thr={best_t:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "0a5745cc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>532674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1048835</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1075748</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2034965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  flag\n",
              "0   532674     0\n",
              "1  1048835     0\n",
              "2   184294     0\n",
              "3  1075748     0\n",
              "4  2034965     0"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission = pd.DataFrame({\n",
        "    'id': X_test['id'].values,\n",
        "    'flag': baza\n",
        "})\n",
        "submission.to_csv(\"submission_blend_stack_max.csv\", index=False)\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "22058295",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1 (baseline): 0.6647 at threshold 0.325\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Very small slice to fit strict time limit\n",
        "ROWS = 200000\n",
        "\n",
        "X_part = X_train[:ROWS]\n",
        "y_df = y_train\n",
        "\n",
        "df = X_part.merge(y_df, on=\"id\", how=\"inner\")\n",
        "df[\"flag\"] = df[\"flag\"].astype(int)\n",
        "\n",
        "# Balanced sample up to ~8k\n",
        "pos = df[df.flag == 1]\n",
        "neg = df[df.flag == 0]\n",
        "n_pos = min(len(pos), 4000)\n",
        "pos_sample = pos.sample(n=n_pos, random_state=42) if len(pos) > n_pos else pos\n",
        "neg_sample = neg.sample(n=len(pos_sample), random_state=42)\n",
        "\n",
        "sample = pd.concat([pos_sample, neg_sample], axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "y = sample[\"flag\"].values\n",
        "X_sample = sample.drop(columns=[\"flag\"])\n",
        "feature_cols = [c for c in X_sample.columns if c != \"id\"]\n",
        "X_feat = X_sample[feature_cols]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_feat, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Fast LR\n",
        "lr = LogisticRegression(max_iter=200, class_weight=\"balanced\", solver=\"liblinear\")\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Подбираем порог на тренировочных данных\n",
        "train_proba = lr.predict_proba(X_train)[:, 1]\n",
        "thresholds = np.linspace(0.05, 0.95, 181)\n",
        "f1s_train = [f1_score(y_train, (train_proba >= t).astype(int)) for t in thresholds]\n",
        "best_idx = int(np.argmax(f1s_train))\n",
        "best_t = float(thresholds[best_idx])\n",
        "\n",
        "# Применяем лучший порог на валидационных данных\n",
        "val_proba = lr.predict_proba(X_val)[:, 1]\n",
        "val_preds = (val_proba >= best_t).astype(int)\n",
        "best_f1 = float(f1_score(y_val, val_preds))\n",
        "\n",
        "res = pd.DataFrame({\n",
        "    \"model\": [\"LogReg (very small slice)\"],\n",
        "    \"best_F1\": [best_f1],\n",
        "    \"best_threshold\": [best_t],\n",
        "    \"train_rows\": [len(X_train)],\n",
        "    \"val_rows\": [len(X_val)],\n",
        "    \"X_rows_loaded\": [ROWS]\n",
        "})\n",
        "\n",
        "print(\"Best F1 (baseline):\", round(best_f1, 4), \"at threshold\", round(best_t, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "c37e0852",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер тренировочной выборки: 1461923\n",
            "Размер валидационной выборки: 365481\n",
            "Баланс классов в тренировочной: [1413952   47971]\n",
            "Баланс классов в валидационной: [353488  11993]\n",
            "\n",
            "Лучший порог на тренировочной выборке: 0.585\n",
            "F1-score на тренировочной выборке: 0.0911\n",
            "\n",
            "==================================================\n",
            "РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\n",
            "==================================================\n",
            "F1-score: 0.0932\n",
            "Accuracy: 0.8727\n",
            "Precision: 0.0608\n",
            "Recall: 0.1995\n",
            "\n",
            "Матрица ошибок:\n",
            "[[316548  36940]\n",
            " [  9600   2393]]\n",
            "TN: 316548, FP: 36940\n",
            "FN: 9600, TP: 2393\n",
            "\n",
            "Сравнение с порогом 0.5:\n",
            "F1-score с порогом 0.5: 0.0820\n",
            "Улучшение: 0.0112\n",
            "\n",
            "Сравнение результатов:\n",
            "      metric     train  validation\n",
            "0   F1-score  0.091055    0.093247\n",
            "1   Accuracy  0.871643    0.872661\n",
            "2  Precision  0.059309    0.060839\n",
            "3     Recall  0.195931    0.199533\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Объединяем признаки и целевую переменную\n",
        "df = X_train.merge(y_train, on=\"id\", how=\"inner\")\n",
        "df[\"flag\"] = df[\"flag\"].astype(int)\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop(columns=[\"flag\", \"id\"])\n",
        "y = df[\"flag\"].values\n",
        "\n",
        "# Разделяем на тренировочную и валидационную выборки\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Размер тренировочной выборки: {len(X_train_split)}\")\n",
        "print(f\"Размер валидационной выборки: {len(X_val)}\")\n",
        "print(f\"Баланс классов в тренировочной: {np.bincount(y_train_split)}\")\n",
        "print(f\"Баланс классов в валидационной: {np.bincount(y_val)}\")\n",
        "\n",
        "# Обучаем модель на тренировочной выборке\n",
        "lr = LogisticRegression(\n",
        "    max_iter=1000, \n",
        "    class_weight=\"balanced\", \n",
        "    solver=\"liblinear\",\n",
        "    random_state=42\n",
        ")\n",
        "lr.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Подбираем порог на тренировочной выборке\n",
        "train_proba = lr.predict_proba(X_train_split)[:, 1]\n",
        "thresholds = np.linspace(0.05, 0.95, 181)\n",
        "f1s_train = [f1_score(y_train_split, (train_proba >= t).astype(int)) for t in thresholds]\n",
        "best_idx = int(np.argmax(f1s_train))\n",
        "best_threshold = float(thresholds[best_idx])\n",
        "best_f1_train = float(f1s_train[best_idx])\n",
        "\n",
        "print(f\"\\nЛучший порог на тренировочной выборке: {best_threshold:.3f}\")\n",
        "print(f\"F1-score на тренировочной выборке: {best_f1_train:.4f}\")\n",
        "\n",
        "# Делаем предсказания на валидационной выборке (без подглядывания!)\n",
        "val_proba = lr.predict_proba(X_val)[:, 1]\n",
        "val_preds = (val_proba >= best_threshold).astype(int)\n",
        "\n",
        "# Оцениваем реальную точность на валидационной выборке\n",
        "val_f1 = f1_score(y_val, val_preds)\n",
        "val_accuracy = accuracy_score(y_val, val_preds)\n",
        "val_precision = precision_score(y_val, val_preds)\n",
        "val_recall = recall_score(y_val, val_preds)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"F1-score: {val_f1:.4f}\")\n",
        "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Precision: {val_precision:.4f}\")\n",
        "print(f\"Recall: {val_recall:.4f}\")\n",
        "\n",
        "# Матрица ошибок\n",
        "cm = confusion_matrix(y_val, val_preds)\n",
        "print(f\"\\nМатрица ошибок:\")\n",
        "print(cm)\n",
        "print(f\"TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
        "print(f\"FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
        "\n",
        "# Сравнение с дефолтным порогом 0.5\n",
        "default_preds = (val_proba >= 0.5).astype(int)\n",
        "default_f1 = f1_score(y_val, default_preds)\n",
        "\n",
        "print(f\"\\nСравнение с порогом 0.5:\")\n",
        "print(f\"F1-score с порогом 0.5: {default_f1:.4f}\")\n",
        "print(f\"Улучшение: {val_f1 - default_f1:.4f}\")\n",
        "\n",
        "# Результаты\n",
        "results = pd.DataFrame({\n",
        "    'metric': ['F1-score', 'Accuracy', 'Precision', 'Recall'],\n",
        "    'train': [best_f1_train, accuracy_score(y_train_split, (train_proba >= best_threshold).astype(int)), \n",
        "             precision_score(y_train_split, (train_proba >= best_threshold).astype(int)),\n",
        "             recall_score(y_train_split, (train_proba >= best_threshold).astype(int))],\n",
        "    'validation': [val_f1, val_accuracy, val_precision, val_recall]\n",
        "})\n",
        "\n",
        "print(f\"\\nСравнение результатов:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "36596621",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер тренировочной выборки: 1461923\n",
            "Размер валидационной выборки: 365481\n",
            "Баланс классов в тренировочной: [1413952   47971]\n",
            "Баланс классов в валидационной: [353488  11993]\n",
            "\n",
            "После балансировки тренировочной выборки:\n",
            "Размер сбалансированной тренировочной: 2827904\n",
            "Баланс классов: [1413952 1413952]\n",
            "\n",
            "Лучший порог на тренировочной выборке: 0.360\n",
            "F1-score на тренировочной выборке: 0.6676\n",
            "\n",
            "==================================================\n",
            "РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА НЕСБАЛАНСИРОВАННОЙ ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\n",
            "==================================================\n",
            "F1-score: 0.0646\n",
            "Accuracy: 0.0637\n",
            "Precision: 0.0334\n",
            "Recall: 0.9851\n",
            "\n",
            "Матрица ошибок:\n",
            "[[ 11455 342033]\n",
            " [   179  11814]]\n",
            "TN: 11455, FP: 342033\n",
            "FN: 179, TP: 11814\n",
            "\n",
            "Сравнение с порогом 0.5:\n",
            "F1-score с порогом 0.5: 0.0821\n",
            "Улучшение: -0.0175\n",
            "\n",
            "Сравнение результатов:\n",
            "      metric  train_balanced  validation_original\n",
            "0   F1-score          0.6676               0.0646\n",
            "1   Accuracy          0.5091               0.0637\n",
            "2  Precision          0.5047               0.0334\n",
            "3     Recall          0.9858               0.9851\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Объединяем признаки и целевую переменную\n",
        "df = X_train.merge(y_train, on=\"id\", how=\"inner\")\n",
        "df[\"flag\"] = df[\"flag\"].astype(int)\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop(columns=[\"flag\", \"id\"])\n",
        "y = df[\"flag\"].values\n",
        "\n",
        "# Разделяем на тренировочную и валидационную выборки\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Размер тренировочной выборки: {len(X_train_split)}\")\n",
        "print(f\"Размер валидационной выборки: {len(X_val)}\")\n",
        "print(f\"Баланс классов в тренировочной: {np.bincount(y_train_split)}\")\n",
        "print(f\"Баланс классов в валидационной: {np.bincount(y_val)}\")\n",
        "\n",
        "# Балансируем только тренировочную выборку\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_balanced, y_train_balanced = ros.fit_resample(X_train_split, y_train_split)\n",
        "\n",
        "# # Вместо oversampling можно использовать undersampling\n",
        "# rus = RandomUnderSampler(random_state=42)\n",
        "# X_train_balanced, y_train_balanced = rus.fit_resample(X_train_split, y_train_split)\n",
        "\n",
        "# print(f\"\\nПосле undersampling тренировочной выборки:\")\n",
        "# print(f\"Размер сбалансированной тренировочной: {len(X_train_balanced)}\")\n",
        "# print(f\"Баланс классов: {np.bincount(y_train_balanced)}\")\n",
        "\n",
        "\n",
        "print(f\"\\nПосле балансировки тренировочной выборки:\")\n",
        "print(f\"Размер сбалансированной тренировочной: {len(X_train_balanced)}\")\n",
        "print(f\"Баланс классов: {np.bincount(y_train_balanced)}\")\n",
        "\n",
        "# Обучаем модель на сбалансированной тренировочной выборке\n",
        "lr = LogisticRegression(\n",
        "    max_iter=1000, \n",
        "    class_weight=None,  # Не используем class_weight т.к. уже сбалансировали\n",
        "    solver=\"liblinear\",\n",
        "    random_state=42\n",
        ")\n",
        "lr.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Подбираем порог на сбалансированной тренировочной выборке\n",
        "train_proba = lr.predict_proba(X_train_balanced)[:, 1]\n",
        "thresholds = np.linspace(0.05, 0.95, 181)\n",
        "f1s_train = [f1_score(y_train_balanced, (train_proba >= t).astype(int)) for t in thresholds]\n",
        "best_idx = int(np.argmax(f1s_train))\n",
        "best_threshold = float(thresholds[best_idx])\n",
        "best_f1_train = float(f1s_train[best_idx])\n",
        "\n",
        "print(f\"\\nЛучший порог на тренировочной выборке: {best_threshold:.3f}\")\n",
        "print(f\"F1-score на тренировочной выборке: {best_f1_train:.4f}\")\n",
        "\n",
        "# Делаем предсказания на валидационной выборке (без балансировки!)\n",
        "val_proba = lr.predict_proba(X_val)[:, 1]\n",
        "val_preds = (val_proba >= best_threshold).astype(int)\n",
        "\n",
        "# Оцениваем реальную точность на несбалансированной валидационной выборке\n",
        "val_f1 = f1_score(y_val, val_preds)\n",
        "val_accuracy = accuracy_score(y_val, val_preds)\n",
        "val_precision = precision_score(y_val, val_preds)\n",
        "val_recall = recall_score(y_val, val_preds)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА НЕСБАЛАНСИРОВАННОЙ ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"F1-score: {val_f1:.4f}\")\n",
        "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Precision: {val_precision:.4f}\")\n",
        "print(f\"Recall: {val_recall:.4f}\")\n",
        "\n",
        "# Матрица ошибок\n",
        "cm = confusion_matrix(y_val, val_preds)\n",
        "print(f\"\\nМатрица ошибок:\")\n",
        "print(cm)\n",
        "print(f\"TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
        "print(f\"FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
        "\n",
        "# Сравнение с дефолтным порогом 0.5\n",
        "default_preds = (val_proba >= 0.5).astype(int)\n",
        "default_f1 = f1_score(y_val, default_preds)\n",
        "\n",
        "print(f\"\\nСравнение с порогом 0.5:\")\n",
        "print(f\"F1-score с порогом 0.5: {default_f1:.4f}\")\n",
        "print(f\"Улучшение: {val_f1 - default_f1:.4f}\")\n",
        "\n",
        "# Результаты\n",
        "results = pd.DataFrame({\n",
        "    'metric': ['F1-score', 'Accuracy', 'Precision', 'Recall'],\n",
        "    'train_balanced': [best_f1_train, \n",
        "                      accuracy_score(y_train_balanced, (train_proba >= best_threshold).astype(int)), \n",
        "                      precision_score(y_train_balanced, (train_proba >= best_threshold).astype(int)),\n",
        "                      recall_score(y_train_balanced, (train_proba >= best_threshold).astype(int))],\n",
        "    'validation_original': [val_f1, val_accuracy, val_precision, val_recall]\n",
        "})\n",
        "\n",
        "print(f\"\\nСравнение результатов:\")\n",
        "print(results.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552f2966",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер тренировочной выборки: 1461923\n",
            "Размер валидационной выборки: 365481\n",
            "Баланс классов в тренировочной: [1413952   47971]\n",
            "Баланс классов в валидационной: [353488  11993]\n",
            "\n",
            "После undersampling тренировочной выборки:\n",
            "Размер сбалансированной тренировочной: 95942\n",
            "Баланс классов: [47971 47971]\n",
            "\n",
            "После балансировки тренировочной выборки:\n",
            "Размер сбалансированной тренировочной: 95942\n",
            "Баланс классов: [47971 47971]\n",
            "0:\ttotal: 49.2ms\tremaining: 24.6s\n",
            "200:\ttotal: 6.13s\tremaining: 9.12s\n",
            "400:\ttotal: 12.5s\tremaining: 3.09s\n",
            "499:\ttotal: 15.8s\tremaining: 0us\n",
            "\n",
            "Лучший порог на тренировочной выборке: 0.400\n",
            "F1-score на тренировочной выборке: 0.6893\n",
            "\n",
            "==================================================\n",
            "РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА НЕСБАЛАНСИРОВАННОЙ ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\n",
            "==================================================\n",
            "F1-score: 0.0714\n",
            "Accuracy: 0.2553\n",
            "Precision: 0.0372\n",
            "Recall: 0.8731\n",
            "\n",
            "Матрица ошибок:\n",
            "[[ 82833 270655]\n",
            " [  1522  10471]]\n",
            "TN: 82833, FP: 270655\n",
            "FN: 1522, TP: 10471\n",
            "\n",
            "Сравнение с порогом 0.5:\n",
            "F1-score с порогом 0.5: 0.0886\n",
            "Улучшение: -0.0172\n",
            "\n",
            "Сравнение результатов:\n",
            "      metric  train_balanced  validation_original\n",
            "0   F1-score          0.6893               0.0714\n",
            "1   Accuracy          0.5927               0.2553\n",
            "2  Precision          0.5572               0.0372\n",
            "3     Recall          0.9034               0.8731\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Объединяем признаки и целевую переменную\n",
        "df = X_train.merge(y_train, on=\"id\", how=\"inner\")\n",
        "df[\"flag\"] = df[\"flag\"].astype(int)\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop(columns=[\"flag\", \"id\"])\n",
        "y = df[\"flag\"].values\n",
        "\n",
        "# Разделяем на тренировочную и валидационную выборки\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Размер тренировочной выборки: {len(X_train_split)}\")\n",
        "print(f\"Размер валидационной выборки: {len(X_val)}\")\n",
        "print(f\"Баланс классов в тренировочной: {np.bincount(y_train_split)}\")\n",
        "print(f\"Баланс классов в валидационной: {np.bincount(y_val)}\")\n",
        "\n",
        "# # Балансируем только тренировочную выборку\n",
        "# ros = RandomOverSampler(random_state=42)\n",
        "# X_train_balanced, y_train_balanced = ros.fit_resample(X_train_split, y_train_split)\n",
        "\n",
        "# Вместо oversampling можно использовать undersampling\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_balanced, y_train_balanced = rus.fit_resample(X_train_split, y_train_split)\n",
        "\n",
        "print(f\"\\nПосле undersampling тренировочной выборки:\")\n",
        "print(f\"Размер сбалансированной тренировочной: {len(X_train_balanced)}\")\n",
        "print(f\"Баланс классов: {np.bincount(y_train_balanced)}\")\n",
        "\n",
        "\n",
        "print(f\"\\nПосле балансировки тренировочной выборки:\")\n",
        "print(f\"Размер сбалансированной тренировочной: {len(X_train_balanced)}\")\n",
        "print(f\"Баланс классов: {np.bincount(y_train_balanced)}\")\n",
        "\n",
        "# Обучаем модель на сбалансированной тренировочной выборке\n",
        "lr = CatBoostClassifier(\n",
        "    iterations=500,\n",
        "    depth=9,\n",
        "    learning_rate=0.04,\n",
        "    l2_leaf_reg=12,\n",
        "    bagging_temperature=0.5,\n",
        "    auto_class_weights='Balanced',\n",
        "    eval_metric='AUC',\n",
        "    verbose=200,\n",
        "    early_stopping_rounds=200\n",
        ")\n",
        "lr.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Подбираем порог на сбалансированной тренировочной выборке\n",
        "train_proba = lr.predict_proba(X_train_balanced)[:, 1]\n",
        "thresholds = np.linspace(0.05, 0.95, 181)\n",
        "f1s_train = [f1_score(y_train_balanced, (train_proba >= t).astype(int)) for t in thresholds]\n",
        "best_idx = int(np.argmax(f1s_train))\n",
        "best_threshold = float(thresholds[best_idx])\n",
        "best_f1_train = float(f1s_train[best_idx])\n",
        "\n",
        "print(f\"\\nЛучший порог на тренировочной выборке: {best_threshold:.3f}\")\n",
        "print(f\"F1-score на тренировочной выборке: {best_f1_train:.4f}\")\n",
        "\n",
        "# Делаем предсказания на валидационной выборке (без балансировки!)\n",
        "val_proba = lr.predict_proba(X_val)[:, 1]\n",
        "val_preds = (val_proba >= best_threshold).astype(int)\n",
        "\n",
        "# Оцениваем реальную точность на несбалансированной валидационной выборке\n",
        "val_f1 = f1_score(y_val, val_preds)\n",
        "val_accuracy = accuracy_score(y_val, val_preds)\n",
        "val_precision = precision_score(y_val, val_preds)\n",
        "val_recall = recall_score(y_val, val_preds)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА НЕСБАЛАНСИРОВАННОЙ ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"F1-score: {val_f1:.4f}\")\n",
        "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Precision: {val_precision:.4f}\")\n",
        "print(f\"Recall: {val_recall:.4f}\")\n",
        "\n",
        "# Матрица ошибок\n",
        "cm = confusion_matrix(y_val, val_preds)\n",
        "print(f\"\\nМатрица ошибок:\")\n",
        "print(cm)\n",
        "print(f\"TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
        "print(f\"FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
        "\n",
        "# Сравнение с дефолтным порогом 0.5\n",
        "default_preds = (val_proba >= 0.62).astype(int)\n",
        "default_f1 = f1_score(y_val, default_preds)\n",
        "\n",
        "print(f\"\\nСравнение с порогом 0.5:\")\n",
        "print(f\"F1-score с порогом 0.5: {default_f1:.4f}\")\n",
        "print(f\"Улучшение: {val_f1 - default_f1:.4f}\")\n",
        "\n",
        "# Результаты\n",
        "results = pd.DataFrame({\n",
        "    'metric': ['F1-score', 'Accuracy', 'Precision', 'Recall'],\n",
        "    'train_balanced': [best_f1_train, \n",
        "                      accuracy_score(y_train_balanced, (train_proba >= best_threshold).astype(int)), \n",
        "                      precision_score(y_train_balanced, (train_proba >= best_threshold).astype(int)),\n",
        "                      recall_score(y_train_balanced, (train_proba >= best_threshold).astype(int))],\n",
        "    'validation_original': [val_f1, val_accuracy, val_precision, val_recall]\n",
        "})\n",
        "\n",
        "print(f\"\\nСравнение результатов:\")\n",
        "print(results.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0742e564",
      "metadata": {},
      "outputs": [],
      "source": [
        "default_preds = (val_proba >= 0.62).astype(int)\n",
        "default_f1 = f1_score(y_val, default_preds)\n",
        "\n",
        "print(f\"\\nСравнение с порогом 0.5:\")\n",
        "print(f\"F1-score с порогом 0.5: {default_f1:.4f}\")\n",
        "print(f\"Улучшение: {val_f1 - default_f1:.4f}\")\n",
        "\n",
        "# Результаты\n",
        "results = pd.DataFrame({\n",
        "    'metric': ['F1-score', 'Accuracy', 'Precision', 'Recall'],\n",
        "    'train_balanced': [best_f1_train, \n",
        "                      accuracy_score(y_train_balanced, (train_proba >= best_threshold).astype(int)), \n",
        "                      precision_score(y_train_balanced, (train_proba >= best_threshold).astype(int)),\n",
        "                      recall_score(y_train_balanced, (train_proba >= best_threshold).astype(int))],\n",
        "    'validation_original': [val_f1, val_accuracy, val_precision, val_recall]\n",
        "})\n",
        "\n",
        "print(f\"\\nСравнение результатов:\")\n",
        "print(results.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "d7ea0d23",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА НЕСБАЛАНСИРОВАННОЙ ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\n",
            "==================================================\n",
            "F1-score: 0.1079\n",
            "Accuracy: 0.8805\n",
            "Precision: 0.0714\n",
            "Recall: 0.2202\n",
            "\n",
            "Матрица ошибок:\n",
            "[[319155  34333]\n",
            " [  9352   2641]]\n",
            "TN: 319155, FP: 34333\n",
            "FN: 9352, TP: 2641\n",
            "\n",
            "Сравнение с порогом 0.5:\n",
            "F1-score с порогом 0.5: 0.0886\n",
            "Улучшение: 0.0193\n",
            "\n",
            "Сравнение результатов:\n",
            "      metric  train_balanced  validation_original\n",
            "0   F1-score          0.6893               0.1079\n",
            "1   Accuracy          0.5927               0.8805\n",
            "2  Precision          0.5572               0.0714\n",
            "3     Recall          0.9034               0.2202\n"
          ]
        }
      ],
      "source": [
        "# Делаем предсказания на валидационной выборке (без балансировки!)\n",
        "val_proba = lr.predict_proba(X_val)[:, 1]\n",
        "val_preds = (val_proba >= 0.62).astype(int)\n",
        "\n",
        "# Оцениваем реальную точность на несбалансированной валидационной выборке\n",
        "val_f1 = f1_score(y_val, val_preds)\n",
        "val_accuracy = accuracy_score(y_val, val_preds)\n",
        "val_precision = precision_score(y_val, val_preds)\n",
        "val_recall = recall_score(y_val, val_preds)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ НА НЕСБАЛАНСИРОВАННОЙ ВАЛИДАЦИОННОЙ ВЫБОРКЕ:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"F1-score: {val_f1:.4f}\")\n",
        "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Precision: {val_precision:.4f}\")\n",
        "print(f\"Recall: {val_recall:.4f}\")\n",
        "\n",
        "# Матрица ошибок\n",
        "cm = confusion_matrix(y_val, val_preds)\n",
        "print(f\"\\nМатрица ошибок:\")\n",
        "print(cm)\n",
        "print(f\"TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
        "print(f\"FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
        "\n",
        "# Сравнение с дефолтным порогом 0.5\n",
        "default_preds = (val_proba >= 0.5).astype(int)\n",
        "default_f1 = f1_score(y_val, default_preds)\n",
        "\n",
        "print(f\"\\nСравнение с порогом 0.5:\")\n",
        "print(f\"F1-score с порогом 0.5: {default_f1:.4f}\")\n",
        "print(f\"Улучшение: {val_f1 - default_f1:.4f}\")\n",
        "\n",
        "# Результаты\n",
        "results = pd.DataFrame({\n",
        "    'metric': ['F1-score', 'Accuracy', 'Precision', 'Recall'],\n",
        "    'train_balanced': [best_f1_train, \n",
        "                      accuracy_score(y_train_balanced, (train_proba >= best_threshold).astype(int)), \n",
        "                      precision_score(y_train_balanced, (train_proba >= best_threshold).astype(int)),\n",
        "                      recall_score(y_train_balanced, (train_proba >= best_threshold).astype(int))],\n",
        "    'validation_original': [val_f1, val_accuracy, val_precision, val_recall]\n",
        "})\n",
        "\n",
        "print(f\"\\nСравнение результатов:\")\n",
        "print(results.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "f1ad24d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "submission_boosted = pd.read_csv('submission_soft_strong.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "9b67b2fa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15076.116"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "456852*0.033"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "34b401b0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8704889971235463"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(submission_boosted['flag'], submission['flag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "2ac5297d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>532674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1048835</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1075748</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2034965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456847</th>\n",
              "      <td>1502480</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456848</th>\n",
              "      <td>1469413</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456849</th>\n",
              "      <td>263710</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456850</th>\n",
              "      <td>1119056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456851</th>\n",
              "      <td>1694598</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>456852 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  flag\n",
              "0        532674     0\n",
              "1       1048835     0\n",
              "2        184294     0\n",
              "3       1075748     0\n",
              "4       2034965     0\n",
              "...         ...   ...\n",
              "456847  1502480     0\n",
              "456848  1469413     0\n",
              "456849   263710     0\n",
              "456850  1119056     0\n",
              "456851  1694598     0\n",
              "\n",
              "[456852 rows x 2 columns]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission_boosted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "d2d349ef",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>532674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1048835</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1075748</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2034965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456847</th>\n",
              "      <td>1502480</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456848</th>\n",
              "      <td>1469413</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456849</th>\n",
              "      <td>263710</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456850</th>\n",
              "      <td>1119056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456851</th>\n",
              "      <td>1694598</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>456852 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  flag\n",
              "0        532674     0\n",
              "1       1048835     0\n",
              "2        184294     0\n",
              "3       1075748     0\n",
              "4       2034965     0\n",
              "...         ...   ...\n",
              "456847  1502480     0\n",
              "456848  1469413     0\n",
              "456849   263710     0\n",
              "456850  1119056     0\n",
              "456851  1694598     0\n",
              "\n",
              "[456852 rows x 2 columns]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4d32d546",
        "b88c139b",
        "f0563cf6",
        "1494f428",
        "beccbcff",
        "d664a528",
        "6d113490",
        "4a361e1a",
        "5c6e97ca",
        "99be9260",
        "14ebfe9c",
        "867fd092",
        "021eb852",
        "a7642acc",
        "67256e55",
        "e9dbb701",
        "19119141",
        "14fcc25b",
        "dc8ee51a",
        "6bd6cbcf",
        "dbf0c139",
        "cf2ef163"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
